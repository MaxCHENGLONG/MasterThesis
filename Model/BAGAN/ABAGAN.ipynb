{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# 检查GPU可用性\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建不平衡的MNIST数据集\n",
    "class ImbalancedMNIST(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, download=True, imbalance_ratio=0.005, num_classes = 2):\n",
    "        \"\"\"\n",
    "        创建一个只包含数字3和4的不平衡MNIST数据集\n",
    "        数字3映射为标签1,数字4映射为标签0\n",
    "        imbalance_ratio: 少数类相对于多数类的样本比例\n",
    "        \"\"\"\n",
    "        self.mnist = datasets.MNIST(root=root, train=train, transform=transform, download=download)\n",
    "        self.num_classes = 2  # 只有两个类别: 0(数字4)和 1 (数字3)\n",
    "        \n",
    "        # 创建不平衡数据集\n",
    "        self.indices = self._create_imbalanced_indices(imbalance_ratio)\n",
    "        \n",
    "    def _create_imbalanced_indices(self, imbalance_ratio):\n",
    "        # 获取数字3和4的索引\n",
    "        class_3_indices = []\n",
    "        class_4_indices = []\n",
    "        \n",
    "        for idx, (_, label) in enumerate(self.mnist):\n",
    "            if label == 3:\n",
    "                class_3_indices.append(idx)\n",
    "            elif label == 4:\n",
    "                class_4_indices.append(idx)\n",
    "        \n",
    "        # 创建不平衡数据集索引\n",
    "        selected_indices = []\n",
    "        \n",
    "        # 多数类(数字3-> 标签1)保持原样\n",
    "        selected_indices.extend(class_3_indices)\n",
    "        \n",
    "        # 少数类(数字4 -> 标签0)减少样本\n",
    "        n_samples = int(len(class_4_indices) * imbalance_ratio)\n",
    "        selected_indices.extend(class_4_indices[:n_samples])\n",
    "        \n",
    "        return selected_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.mnist[self.indices[idx]]\n",
    "        \n",
    "        # 将原始标签映射为新标签: 3 -> 1, 4 -> 0\n",
    "        if label == 3:\n",
    "            new_label = 1\n",
    "        elif label == 4:\n",
    "            new_label = 0\n",
    "        else:\n",
    "            raise ValueError(f\"意外的标签: {label}\")\n",
    "        \n",
    "        return img, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器网络 - 适用于MNIST\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 嵌入层处理类别标签\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        \n",
    "        # 初始线性层\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, 128 * 7 * 7)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 嵌入标签\n",
    "        label_embedding = self.label_emb(labels)\n",
    "        # 将噪声和标签嵌入连接起来\n",
    "        x = torch.cat([noise, label_embedding], dim=1)\n",
    "        # 线性层\n",
    "        x = self.linear(x)\n",
    "        # 重塑为卷积特征图\n",
    "        x = x.view(x.shape[0], 128, 7, 7)\n",
    "        # 卷积层\n",
    "        img = self.conv_blocks(x)\n",
    "        return img\n",
    "\n",
    "# 定义判别器网络 - 适用于MNIST\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 特征提取器\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # 正确计算展平后的尺寸\n",
    "        self.flatten_size = 64 * 4 * 4  # 修改前为 64*3*3\n",
    "        \n",
    "        # 真假判别器\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 类别分类器\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        features = self.features(img)\n",
    "        features = features.view(features.shape[0], -1)\n",
    "        validity = self.adv_layer(features)\n",
    "        label = self.aux_layer(features)\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义带有注意力机制的自动编码器网络 - 适用于MNIST\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        \n",
    "        # 平均池化特征\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        # 最大池化特征\n",
    "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
    "        \n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out).view(b, c, 1, 1) * x\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), '空间注意力核大小必须为3或7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        \n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        \n",
    "        # 沿着通道维度计算平均值和最大值\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        \n",
    "        # 拼接特征\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        \n",
    "        # 应用卷积和激活函数\n",
    "        out = self.conv(x_cat)\n",
    "        \n",
    "        return self.sigmoid(out) * x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28x28 -> 14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca1 = ChannelAttention(16)\n",
    "        self.sa1 = SpatialAttention()\n",
    "        \n",
    "        self.encoder_block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 14x14 -> 7x7\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca2 = ChannelAttention(32)\n",
    "        self.sa2 = SpatialAttention()\n",
    "        \n",
    "        self.encoder_block3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 7x7 -> 7x7\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca3 = ChannelAttention(64)\n",
    "        self.sa3 = SpatialAttention()\n",
    "        \n",
    "        # 将特征图展平并映射到潜在空间\n",
    "        self.fc = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        \n",
    "        # 解码器输入层\n",
    "        self.decoder_input = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        \n",
    "        # 解码器\n",
    "        self.decoder_block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca4 = ChannelAttention(32)\n",
    "        self.sa4 = SpatialAttention()\n",
    "        \n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)  # 7x7 -> 14x14\n",
    "        \n",
    "        self.decoder_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca5 = ChannelAttention(16)\n",
    "        self.sa5 = SpatialAttention()\n",
    "        \n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)  # 14x14 -> 28x28\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(16, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def encode(self, img):\n",
    "        # 编码器前向传播，应用注意力机制\n",
    "        x = self.encoder_block1(img)\n",
    "        x = self.ca1(x)\n",
    "        x = self.sa1(x)\n",
    "        \n",
    "        x = self.encoder_block2(x)\n",
    "        x = self.ca2(x)\n",
    "        x = self.sa2(x)\n",
    "        \n",
    "        x = self.encoder_block3(x)\n",
    "        x = self.ca3(x)\n",
    "        x = self.sa3(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        z = self.fc(x)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # 解码器前向传播，应用注意力机制\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.shape[0], 64, 7, 7)\n",
    "        \n",
    "        x = self.decoder_block1(x)\n",
    "        x = self.ca4(x)\n",
    "        x = self.sa4(x)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        \n",
    "        x = self.decoder_block2(x)\n",
    "        x = self.ca5(x)\n",
    "        x = self.sa5(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        img = self.output_layer(x)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def forward(self, img):\n",
    "        z = self.encode(img)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_mini_batches(dataset, batch_size, num_classes):\n",
    "    samples_by_class = [[] for _ in range(num_classes)]\n",
    "    for idx, (img, label) in enumerate(dataset):\n",
    "        samples_by_class[label].append((img, label, idx))\n",
    "    \n",
    "    # Count samples per class\n",
    "    samples_count = [len(samples) for samples in samples_by_class]\n",
    "    \n",
    "    # Determine maximum class size\n",
    "    max_class_size = max(samples_count)\n",
    "    \n",
    "    # Calculate samples per class per batch (M/N)\n",
    "    samples_per_class_per_batch = batch_size // num_classes\n",
    "    \n",
    "    # Calculate number of mini-batches (K)\n",
    "    num_batches = max_class_size // samples_per_class_per_batch\n",
    "    \n",
    "    # Initialize empty mini-batches\n",
    "    balanced_batches = [[] for _ in range(num_batches)]\n",
    "    \n",
    "    # For each mini-batch\n",
    "    for i in range(num_batches):\n",
    "        # For each class\n",
    "        for j in range(num_classes):\n",
    "            # Randomly choose M/N samples from class j\n",
    "            class_samples = samples_by_class[j]\n",
    "            if len(class_samples) < samples_per_class_per_batch:\n",
    "                # For smaller classes, sample with replacement\n",
    "                selected_samples = random.choices(class_samples, k=samples_per_class_per_batch)\n",
    "            else:\n",
    "                # For larger classes, sample without replacement\n",
    "                selected_indices = random.sample(range(len(class_samples)), samples_per_class_per_batch)\n",
    "                selected_samples = [class_samples[idx] for idx in selected_indices]\n",
    "                \n",
    "                # If this class is the largest, remove the selected samples\n",
    "                if samples_count[j] == max_class_size:\n",
    "                    # Remove in reverse order to avoid index shifting issues\n",
    "                    for idx in sorted(selected_indices, reverse=True):\n",
    "                        class_samples.pop(idx)\n",
    "            \n",
    "            # Add selected samples to current mini-batch\n",
    "            balanced_batches[i].extend(selected_samples)\n",
    "    return balanced_batches\n",
    "# 定义BAGAN类\n",
    "class BAGAN:\n",
    "    def __init__(self, latent_dim=100, batch_size=64, root='./data', imbalance_ratio=0.005, num_classes=2):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.imbalance_ratio = imbalance_ratio\n",
    "        self.num_classes = 2  # 修改为2个类别：0(原数字4)和1(原数字3)\n",
    "        \n",
    "        # 数据转换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # MNIST是单通道，所以只需一个值\n",
    "        ])\n",
    "        \n",
    "        # 创建不平衡的MNIST数据集（只包含数字3和4）\n",
    "        self.dataset = ImbalancedMNIST(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            transform=self.transform,\n",
    "            download=True,\n",
    "            imbalance_ratio=imbalance_ratio,\n",
    "            num_classes= 2,\n",
    "        )\n",
    "        \n",
    "        # 初始化网络\n",
    "        self.autoencoder = Autoencoder(latent_dim).to(device)\n",
    "        self.generator = Generator(latent_dim, self.num_classes).to(device)\n",
    "        self.discriminator = Discriminator(self.num_classes).to(device)\n",
    "        \n",
    "        # 分析类别分布\n",
    "        self.class_counts = self._get_class_distribution()\n",
    "        print(f\"Class Distribution: {self.class_counts}\")\n",
    "        \n",
    "        # 计算类别权重以进行平衡采样\n",
    "        self.weights = self._compute_weights()\n",
    "        \n",
    "    def _get_class_distribution(self):\n",
    "        counts = Counter()\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            if hasattr(label, 'item'):\n",
    "                counts[label.item()] += 1\n",
    "            else:\n",
    "                counts[label] += 1\n",
    "        return counts\n",
    "    \n",
    "    def _compute_weights(self):\n",
    "        max_count = max(self.class_counts.values())\n",
    "        weights = []\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            label_idx = label.item() if torch.is_tensor(label) else label\n",
    "            count = self.class_counts[label_idx]\n",
    "            weight = max_count / count if count > 0 else 0\n",
    "            weights.append(weight)\n",
    "        return weights\n",
    "    \n",
    "    def _create_dataloaders(self):\n",
    "        # 为整个数据集创建加载器\n",
    "        dataloader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        # 为每个类别创建单独的加载器\n",
    "        class_loaders = {}\n",
    "        for class_idx in range(self.num_classes):\n",
    "            # 筛选该类别的样本\n",
    "            indices = [i for i, (_, y) in enumerate(self.dataset) if \n",
    "                      (y.item() if torch.is_tensor(y) else y) == class_idx]\n",
    "            if indices:  # 确保该类别有样本\n",
    "                class_subset = Subset(self.dataset, indices)\n",
    "                class_loaders[class_idx] = DataLoader(\n",
    "                    class_subset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4\n",
    "                )\n",
    "        \n",
    "        return dataloader, class_loaders\n",
    "    \n",
    "    def pretrain_autoencoder(self, epochs=50, lr=0.0002):\n",
    "        \"\"\"预训练自动编码器\"\"\"\n",
    "        print(\"预训练自动编码器...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        _, class_loaders = self._create_dataloaders()\n",
    "        \n",
    "        # 为自动编码器设置优化器\n",
    "        optimizer = optim.Adam(self.autoencoder.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 为每个类别存储潜在表示的均值和方差\n",
    "        self.latent_means = torch.zeros(self.num_classes, self.latent_dim).to(device)\n",
    "        self.latent_vars = torch.ones(self.num_classes, self.latent_dim).to(device)\n",
    "        \n",
    "        self.autoencoder.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            samples_count = 0\n",
    "            \n",
    "            # 每个类别的数据加载器\n",
    "            for class_idx, loader in class_loaders.items():\n",
    "                class_latent_vectors = []\n",
    "                \n",
    "                for i, (imgs, _) in enumerate(loader):\n",
    "                    imgs = imgs.to(device)\n",
    "                    \n",
    "                    # 重置梯度\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # 自动编码器前向传播\n",
    "                    latent = self.autoencoder.encode(imgs)\n",
    "                    reconstructed = self.autoencoder.decode(latent)\n",
    "                    \n",
    "                    # 记录潜在向量\n",
    "                    class_latent_vectors.append(latent.detach())\n",
    "                    \n",
    "                    # 计算损失\n",
    "                    loss = criterion(reconstructed, imgs)\n",
    "                    \n",
    "                    # 反向传播和优化\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item() * imgs.size(0)\n",
    "                    samples_count += imgs.size(0)\n",
    "                \n",
    "                # 计算该类别的潜在向量的均值和方差\n",
    "                if class_latent_vectors:\n",
    "                    class_latent = torch.cat(class_latent_vectors, dim=0)\n",
    "                    self.latent_means[class_idx] = class_latent.mean(dim=0)\n",
    "                    self.latent_vars[class_idx] = class_latent.var(dim=0)\n",
    "            \n",
    "            avg_loss = total_loss / samples_count if samples_count > 0 else 0\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Autoencoder Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # 将预训练的解码器权重初始化生成器对应层\n",
    "        print(\"将自动编码器知识转移到生成器...\")\n",
    "        self._init_generator_from_autoencoder()\n",
    "    \n",
    "    def _init_generator_from_autoencoder(self):\n",
    "        \"\"\"将自动编码器知识转移到生成器\"\"\"\n",
    "        # 设置嵌入层来表示潜在空间中的类别均值\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                self.generator.label_emb.weight.data[class_idx] = self.latent_means[class_idx]\n",
    "    ########################################\n",
    "\n",
    "    # Incorporating the balanced mini-batch approach into training\n",
    "    def train_gan_with_balanced_batches(self, epochs = 100, sample_interval=200):\n",
    "        # Define losses\n",
    "        adversarial_loss = torch.nn.BCELoss()\n",
    "        auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Setup optimizers\n",
    "        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Parameters for balanced batching\n",
    "        batch_size = 64  # Total batch size (M)\n",
    "        samples_per_class = batch_size // self.num_classes  # Samples per class per batch (M/N)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Create balanced mini-batches for this epoch\n",
    "            balanced_batches = create_balanced_mini_batches(self.dataset, batch_size, self.num_classes)\n",
    "            \n",
    "            for i, batch in enumerate(balanced_batches):\n",
    "                # Extract images and labels from the batch\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "                for img, label, _ in batch:\n",
    "                    batch_imgs.append(img)\n",
    "                    batch_labels.append(label)\n",
    "                \n",
    "                real_imgs = torch.stack(batch_imgs).to(device)\n",
    "                labels = torch.tensor(batch_labels).to(device)\n",
    "                \n",
    "                batch_size = real_imgs.size(0)\n",
    "                \n",
    "                # Create labels\n",
    "                valid = torch.ones(batch_size, 1).to(device)\n",
    "                fake = torch.zeros(batch_size, 1).to(device)\n",
    "                \n",
    "                # Add label smoothing for stability\n",
    "                valid = valid - 0.1 * torch.rand(valid.shape).to(device)\n",
    "                fake = fake + 0.1 * torch.rand(fake.shape).to(device)\n",
    "                \n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # Real images loss\n",
    "                real_pred, real_aux = self.discriminator(real_imgs)\n",
    "                d_real_loss = 0.5 * (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels))\n",
    "                \n",
    "                # Generate fake images\n",
    "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "                gen_labels = torch.randint(0, self.num_classes, (batch_size,)).to(device)\n",
    "                \n",
    "                # Add class-specific statistics to noise\n",
    "                for idx in range(batch_size):\n",
    "                    class_idx = gen_labels[idx].item()\n",
    "                    z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                gen_imgs = self.generator(z, gen_labels)\n",
    "                \n",
    "                # Fake images loss\n",
    "                fake_pred, fake_aux = self.discriminator(gen_imgs.detach())\n",
    "                d_fake_loss = 0.5 * (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels))\n",
    "                \n",
    "                # Total discriminator loss\n",
    "                d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # Generate new batch of images\n",
    "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "                gen_labels = torch.randint(0, self.num_classes, (batch_size,)).to(device)\n",
    "                \n",
    "                # Add class-specific statistics\n",
    "                for idx in range(batch_size):\n",
    "                    class_idx = gen_labels[idx].item()\n",
    "                    z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                gen_imgs = self.generator(z, gen_labels)\n",
    "                \n",
    "                # Generator loss\n",
    "                validity, pred_label = self.discriminator(gen_imgs)\n",
    "                g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "                \n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                \n",
    "                # Print progress\n",
    "                if i % 20 == 0:\n",
    "                    print(\n",
    "                        f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(balanced_batches)}] \"\n",
    "                        f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "                    )\n",
    "                \n",
    "                batches_done = epoch * len(balanced_batches) + i\n",
    "                if batches_done % sample_interval == 0:\n",
    "                    self.sample_images(batches_done)\n",
    "    #########################################\n",
    "    def train(self, epochs=200, lr=0.0002, b1=0.5, b2=0.999, sample_interval=200):\n",
    "        \"\"\"训练BAGAN\"\"\"\n",
    "        print(\"开始训练BAGAN...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        dataloader, _ = self._create_dataloaders()\n",
    "        \n",
    "        # 损失函数\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "        auxiliary_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 优化器\n",
    "        optimizer_G = optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "                batch_size = real_imgs.size(0)\n",
    "                \n",
    "                # 配置输入\n",
    "                real_imgs = real_imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 创建标签\n",
    "                valid = torch.ones(batch_size, 1).to(device)\n",
    "                fake = torch.zeros(batch_size, 1).to(device)\n",
    "                \n",
    "                # -----------------\n",
    "                #  训练生成器\n",
    "                # -----------------\n",
    "                \n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # 采样噪声和标签作为生成器输入\n",
    "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "                gen_labels = torch.randint(0, self.num_classes, (batch_size,)).to(device)\n",
    "                \n",
    "                # 为生成的噪声添加类别特定的统计信息\n",
    "                for idx in range(batch_size):\n",
    "                    class_idx = gen_labels[idx].item()\n",
    "                    z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成一批假图像\n",
    "                gen_imgs = self.generator(z, gen_labels)\n",
    "                \n",
    "                # 计算生成器的损失\n",
    "                validity, pred_label = self.discriminator(gen_imgs)\n",
    "                g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "                \n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                \n",
    "                # ---------------------\n",
    "                #  训练判别器\n",
    "                # ---------------------\n",
    "                \n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # 真实图像的损失\n",
    "                real_pred, real_aux = self.discriminator(real_imgs)\n",
    "                d_real_loss = 0.5 * (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels))\n",
    "                \n",
    "                # 生成图像的损失\n",
    "                fake_pred, fake_aux = self.discriminator(gen_imgs.detach())\n",
    "                d_fake_loss = 0.5 * (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels))\n",
    "                \n",
    "                # 总判别器损失\n",
    "                d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "                \n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # 打印训练进度\n",
    "                if i % 50 == 0:\n",
    "                    print(\n",
    "                        f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                        f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "                    )\n",
    "                \n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                if batches_done % sample_interval == 0:\n",
    "                    self.sample_images(batches_done)\n",
    "    \n",
    "    def sample_images(self, batches_done):\n",
    "        \"\"\"保存采样的图像\"\"\"\n",
    "        # 为每个类别生成样本\n",
    "        n_row, n_col = 1, 2  # 1行，2个类别\n",
    "        fig, axs = plt.subplots(n_row, n_col, figsize=(n_col * 2, n_row * 2))\n",
    "        \n",
    "        # 生成每个类别的样本\n",
    "        with torch.no_grad():\n",
    "            for i, class_idx in enumerate(range(self.num_classes)):\n",
    "                # 生成该类别的噪声和标签\n",
    "                z = torch.randn(1, self.latent_dim).to(device)\n",
    "                label = torch.tensor([class_idx], device=device)\n",
    "                \n",
    "                # 为噪声添加类别特定的统计信息\n",
    "                z = z * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成图像\n",
    "                gen_img = self.generator(z, label)\n",
    "                \n",
    "                # 显示图像\n",
    "                img = gen_img[0].cpu().detach().numpy()\n",
    "                img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                img = img.reshape(28, 28)\n",
    "                \n",
    "                # 原始类别映射\n",
    "                if class_idx == 0:\n",
    "                    original_digit = \"4\"\n",
    "                else:\n",
    "                    original_digit = \"3\"\n",
    "                #original_digit = \"4\" if class_idx == 0 else \"3\"\n",
    "                axs[i].imshow(img, cmap='gray')\n",
    "                axs[i].set_title(f\"Class {class_idx} (Original Digit {original_digit})\")\n",
    "                axs[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 创建保存目录\n",
    "        save_dir = \"bagan_mnist_binary_samples\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 保存图像\n",
    "        plt.savefig(f\"{save_dir}/sample_{batches_done}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_balanced_dataset(self, samples_per_class=1000, output_dir=\"./augmented_mnist_binary\"):\n",
    "        \"\"\"生成平衡数据集 - 针对二分类场景(数字3和4)\"\"\"\n",
    "        print(f\"为每个类别生成 {samples_per_class} 个样本...\")\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for class_idx in range(self.num_classes):  # 应该只有2个类别\n",
    "            os.makedirs(os.path.join(output_dir, str(class_idx)), exist_ok=True)\n",
    "        \n",
    "        # 类别名称映射（用于更清晰的输出信息）\n",
    "        class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "        \n",
    "        # 确认是二分类模式\n",
    "        if self.num_classes != 2:\n",
    "            print(f\"警告: 当前设置为{self.num_classes}个类别,而不是预期的2个类别\")\n",
    "        \n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                if class_idx >= 2:  # 确保只处理0和1两个类别\n",
    "                    print(f\"跳过类别 {class_idx}，因为当前是二分类模式\")\n",
    "                    continue\n",
    "                    \n",
    "                # 计算需要生成的额外样本数\n",
    "                real_samples = self.class_counts.get(class_idx, 0)\n",
    "                if real_samples >= samples_per_class:\n",
    "                    print(f\"{class_name[class_idx]} 已经有 {real_samples} 个样本，不需要增强\")\n",
    "                    continue\n",
    "                \n",
    "                to_generate = samples_per_class - real_samples\n",
    "                print(f\"为{class_name[class_idx]}生成 {to_generate} 个额外样本\")\n",
    "                \n",
    "                # 批次生成\n",
    "                batch_size = min(self.batch_size, to_generate)\n",
    "                num_batches = to_generate // batch_size + (1 if to_generate % batch_size != 0 else 0)\n",
    "                \n",
    "                for batch in range(num_batches):\n",
    "                    current_batch_size = min(batch_size, to_generate - batch * batch_size)\n",
    "                    \n",
    "                    # 生成噪声和标签\n",
    "                    z = torch.randn(current_batch_size, self.latent_dim).to(device)\n",
    "                    labels = torch.full((current_batch_size,), class_idx, dtype=torch.long).to(device)\n",
    "                    \n",
    "                    # 为噪声添加类别特定的统计信息\n",
    "                    for idx in range(current_batch_size):\n",
    "                        z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                    \n",
    "                    # 生成图像\n",
    "                    gen_imgs = self.generator(z, labels)\n",
    "                    \n",
    "                    # 保存生成的图像\n",
    "                    for idx, img in enumerate(gen_imgs):\n",
    "                        img_idx = batch * batch_size + idx\n",
    "                        img = img.cpu().detach().numpy()\n",
    "                        img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                        img = img.reshape(28, 28) * 255\n",
    "                        img = img.astype(np.uint8)\n",
    "                        img = Image.fromarray(img, mode='L')  # 灰度图像\n",
    "                        img.save(os.path.join(output_dir, str(class_idx), f\"gen_{img_idx}.png\"))\n",
    "        \n",
    "        # 统计生成后的数据集大小\n",
    "        total_samples = {0: 0, 1: 0}\n",
    "        for class_idx in range(2):  # 只计算二分类\n",
    "            class_dir = os.path.join(output_dir, str(class_idx))\n",
    "            if os.path.exists(class_dir):\n",
    "                files = [f for f in os.listdir(class_dir) if f.endswith('.png')]\n",
    "                total_samples[class_idx] = len(files)\n",
    "        \n",
    "        print(f\"数据增强完成！增强后的数据集保存在 {output_dir}\")\n",
    "        print(f\"最终数据集统计：\")\n",
    "        print(f\"- {class_name[0]}: {total_samples[0]} 个样本\")\n",
    "        print(f\"- {class_name[1]}: {total_samples[1]} 个样本\")\n",
    "\n",
    "    def evaluate_model(self, test_loader):\n",
    "        \"\"\"评估模型在测试集上的性能\"\"\"\n",
    "        self.discriminator.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "        class_correct = {0: 0, 1: 0}\n",
    "        class_total = {0: 0, 1: 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                validity, pred_labels = self.discriminator(imgs)\n",
    "                _, predicted = torch.max(pred_labels.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # 计算每个类别的准确率\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    if predicted[i] == label:\n",
    "                        class_correct[label] += 1\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"在测试集上的总体准确率: {accuracy:.2f}%\")\n",
    "        \n",
    "        # 打印每个类别的准确率\n",
    "        for class_idx in range(self.num_classes):\n",
    "            if class_total[class_idx] > 0:\n",
    "                class_acc = 100 * class_correct[class_idx] / class_total[class_idx]\n",
    "                print(f\"{class_name[class_idx]}准确率: {class_acc:.2f}% ({class_correct[class_idx]}/{class_total[class_idx]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution: Counter({1: 6131, 0: 29})\n",
      "预训练自动编码器...\n",
      "Epoch [1/30] Autoencoder Loss: 0.5766\n",
      "Epoch [2/30] Autoencoder Loss: 0.2345\n",
      "Epoch [3/30] Autoencoder Loss: 0.1143\n",
      "Epoch [4/30] Autoencoder Loss: 0.0723\n",
      "Epoch [5/30] Autoencoder Loss: 0.0527\n",
      "Epoch [6/30] Autoencoder Loss: 0.0416\n",
      "Epoch [7/30] Autoencoder Loss: 0.0346\n",
      "Epoch [8/30] Autoencoder Loss: 0.0299\n",
      "Epoch [9/30] Autoencoder Loss: 0.0262\n",
      "Epoch [10/30] Autoencoder Loss: 0.0239\n",
      "Epoch [11/30] Autoencoder Loss: 0.0218\n",
      "Epoch [12/30] Autoencoder Loss: 0.0200\n",
      "Epoch [13/30] Autoencoder Loss: 0.0191\n",
      "Epoch [14/30] Autoencoder Loss: 0.0180\n",
      "Epoch [15/30] Autoencoder Loss: 0.0168\n",
      "Epoch [16/30] Autoencoder Loss: 0.0160\n",
      "Epoch [17/30] Autoencoder Loss: 0.0155\n",
      "Epoch [18/30] Autoencoder Loss: 0.0148\n",
      "Epoch [19/30] Autoencoder Loss: 0.0145\n",
      "Epoch [20/30] Autoencoder Loss: 0.0138\n",
      "Epoch [21/30] Autoencoder Loss: 0.0137\n",
      "Epoch [22/30] Autoencoder Loss: 0.0130\n",
      "Epoch [23/30] Autoencoder Loss: 0.0129\n",
      "Epoch [24/30] Autoencoder Loss: 0.0127\n",
      "Epoch [25/30] Autoencoder Loss: 0.0121\n",
      "Epoch [26/30] Autoencoder Loss: 0.0118\n",
      "Epoch [27/30] Autoencoder Loss: 0.0114\n",
      "Epoch [28/30] Autoencoder Loss: 0.0112\n",
      "Epoch [29/30] Autoencoder Loss: 0.0111\n",
      "Epoch [30/30] Autoencoder Loss: 0.0108\n",
      "将自动编码器知识转移到生成器...\n",
      "[Epoch 0/50] [Batch 0/191] [D loss: 0.6937] [G loss: 0.6859]\n",
      "[Epoch 0/50] [Batch 20/191] [D loss: 0.6482] [G loss: 0.5906]\n",
      "[Epoch 0/50] [Batch 40/191] [D loss: 0.5897] [G loss: 0.5147]\n",
      "[Epoch 0/50] [Batch 60/191] [D loss: 0.5461] [G loss: 0.5177]\n",
      "[Epoch 0/50] [Batch 80/191] [D loss: 0.5448] [G loss: 0.5192]\n",
      "[Epoch 0/50] [Batch 100/191] [D loss: 0.5244] [G loss: 0.5509]\n",
      "[Epoch 0/50] [Batch 120/191] [D loss: 0.5402] [G loss: 0.4942]\n",
      "[Epoch 0/50] [Batch 140/191] [D loss: 0.5109] [G loss: 0.5146]\n",
      "[Epoch 0/50] [Batch 160/191] [D loss: 0.5238] [G loss: 0.5102]\n",
      "[Epoch 0/50] [Batch 180/191] [D loss: 0.5054] [G loss: 0.5338]\n",
      "[Epoch 1/50] [Batch 0/191] [D loss: 0.5206] [G loss: 0.5058]\n",
      "[Epoch 1/50] [Batch 20/191] [D loss: 0.5234] [G loss: 0.5234]\n",
      "[Epoch 1/50] [Batch 40/191] [D loss: 0.5033] [G loss: 0.5212]\n",
      "[Epoch 1/50] [Batch 60/191] [D loss: 0.4928] [G loss: 0.5438]\n",
      "[Epoch 1/50] [Batch 80/191] [D loss: 0.5179] [G loss: 0.5210]\n",
      "[Epoch 1/50] [Batch 100/191] [D loss: 0.5031] [G loss: 0.5241]\n",
      "[Epoch 1/50] [Batch 120/191] [D loss: 0.5029] [G loss: 0.5302]\n",
      "[Epoch 1/50] [Batch 140/191] [D loss: 0.5172] [G loss: 0.4943]\n",
      "[Epoch 1/50] [Batch 160/191] [D loss: 0.5081] [G loss: 0.5046]\n",
      "[Epoch 1/50] [Batch 180/191] [D loss: 0.5126] [G loss: 0.5175]\n",
      "[Epoch 2/50] [Batch 0/191] [D loss: 0.5097] [G loss: 0.5155]\n",
      "[Epoch 2/50] [Batch 20/191] [D loss: 0.5028] [G loss: 0.5322]\n",
      "[Epoch 2/50] [Batch 40/191] [D loss: 0.4983] [G loss: 0.5342]\n",
      "[Epoch 2/50] [Batch 60/191] [D loss: 0.5167] [G loss: 0.5092]\n",
      "[Epoch 2/50] [Batch 80/191] [D loss: 0.5003] [G loss: 0.5276]\n",
      "[Epoch 2/50] [Batch 100/191] [D loss: 0.4971] [G loss: 0.5337]\n",
      "[Epoch 2/50] [Batch 120/191] [D loss: 0.5119] [G loss: 0.5133]\n",
      "[Epoch 2/50] [Batch 140/191] [D loss: 0.5233] [G loss: 0.5081]\n",
      "[Epoch 2/50] [Batch 160/191] [D loss: 0.5098] [G loss: 0.5204]\n",
      "[Epoch 2/50] [Batch 180/191] [D loss: 0.5060] [G loss: 0.5255]\n",
      "[Epoch 3/50] [Batch 0/191] [D loss: 0.5095] [G loss: 0.5152]\n",
      "[Epoch 3/50] [Batch 20/191] [D loss: 0.5033] [G loss: 0.5349]\n",
      "[Epoch 3/50] [Batch 40/191] [D loss: 0.5283] [G loss: 0.5184]\n",
      "[Epoch 3/50] [Batch 60/191] [D loss: 0.5106] [G loss: 0.4951]\n",
      "[Epoch 3/50] [Batch 80/191] [D loss: 0.4972] [G loss: 0.5324]\n",
      "[Epoch 3/50] [Batch 100/191] [D loss: 0.4833] [G loss: 0.5388]\n",
      "[Epoch 3/50] [Batch 120/191] [D loss: 0.4971] [G loss: 0.5387]\n",
      "[Epoch 3/50] [Batch 140/191] [D loss: 0.5007] [G loss: 0.5380]\n",
      "[Epoch 3/50] [Batch 160/191] [D loss: 0.4991] [G loss: 0.5334]\n",
      "[Epoch 3/50] [Batch 180/191] [D loss: 0.5017] [G loss: 0.5456]\n",
      "[Epoch 4/50] [Batch 0/191] [D loss: 0.5006] [G loss: 0.5144]\n",
      "[Epoch 4/50] [Batch 20/191] [D loss: 0.5142] [G loss: 0.5129]\n",
      "[Epoch 4/50] [Batch 40/191] [D loss: 0.5098] [G loss: 0.5099]\n",
      "[Epoch 4/50] [Batch 60/191] [D loss: 0.5045] [G loss: 0.5224]\n",
      "[Epoch 4/50] [Batch 80/191] [D loss: 0.4993] [G loss: 0.5206]\n",
      "[Epoch 4/50] [Batch 100/191] [D loss: 0.4939] [G loss: 0.5710]\n",
      "[Epoch 4/50] [Batch 120/191] [D loss: 0.5043] [G loss: 0.5318]\n",
      "[Epoch 4/50] [Batch 140/191] [D loss: 0.4753] [G loss: 0.5637]\n",
      "[Epoch 4/50] [Batch 160/191] [D loss: 0.5182] [G loss: 0.5233]\n",
      "[Epoch 4/50] [Batch 180/191] [D loss: 0.5110] [G loss: 0.5015]\n",
      "[Epoch 5/50] [Batch 0/191] [D loss: 0.5171] [G loss: 0.5155]\n",
      "[Epoch 5/50] [Batch 20/191] [D loss: 0.5070] [G loss: 0.5193]\n",
      "[Epoch 5/50] [Batch 40/191] [D loss: 0.5132] [G loss: 0.5013]\n",
      "[Epoch 5/50] [Batch 60/191] [D loss: 0.4827] [G loss: 0.5597]\n",
      "[Epoch 5/50] [Batch 80/191] [D loss: 0.4940] [G loss: 0.5364]\n",
      "[Epoch 5/50] [Batch 100/191] [D loss: 0.4968] [G loss: 0.5380]\n",
      "[Epoch 5/50] [Batch 120/191] [D loss: 0.4889] [G loss: 0.5439]\n",
      "[Epoch 5/50] [Batch 140/191] [D loss: 0.4979] [G loss: 0.5349]\n",
      "[Epoch 5/50] [Batch 160/191] [D loss: 0.4454] [G loss: 0.6089]\n",
      "[Epoch 5/50] [Batch 180/191] [D loss: 0.4996] [G loss: 0.5453]\n",
      "[Epoch 6/50] [Batch 0/191] [D loss: 0.4894] [G loss: 0.5598]\n",
      "[Epoch 6/50] [Batch 20/191] [D loss: 0.4887] [G loss: 0.5767]\n",
      "[Epoch 6/50] [Batch 40/191] [D loss: 0.4923] [G loss: 0.5550]\n",
      "[Epoch 6/50] [Batch 60/191] [D loss: 0.5206] [G loss: 0.5582]\n",
      "[Epoch 6/50] [Batch 80/191] [D loss: 0.5016] [G loss: 0.5502]\n",
      "[Epoch 6/50] [Batch 100/191] [D loss: 0.5193] [G loss: 0.5233]\n",
      "[Epoch 6/50] [Batch 120/191] [D loss: 0.4780] [G loss: 0.5525]\n",
      "[Epoch 6/50] [Batch 140/191] [D loss: 0.4660] [G loss: 0.5711]\n",
      "[Epoch 6/50] [Batch 160/191] [D loss: 0.4944] [G loss: 0.5737]\n",
      "[Epoch 6/50] [Batch 180/191] [D loss: 0.5330] [G loss: 0.5068]\n",
      "[Epoch 7/50] [Batch 0/191] [D loss: 0.5072] [G loss: 0.5248]\n",
      "[Epoch 7/50] [Batch 20/191] [D loss: 0.4887] [G loss: 0.5426]\n",
      "[Epoch 7/50] [Batch 40/191] [D loss: 0.4933] [G loss: 0.5421]\n",
      "[Epoch 7/50] [Batch 60/191] [D loss: 0.5066] [G loss: 0.5379]\n",
      "[Epoch 7/50] [Batch 80/191] [D loss: 0.4780] [G loss: 0.5607]\n",
      "[Epoch 7/50] [Batch 100/191] [D loss: 0.4647] [G loss: 0.5513]\n",
      "[Epoch 7/50] [Batch 120/191] [D loss: 0.4765] [G loss: 0.5900]\n",
      "[Epoch 7/50] [Batch 140/191] [D loss: 0.5506] [G loss: 0.5635]\n",
      "[Epoch 7/50] [Batch 160/191] [D loss: 0.4558] [G loss: 0.6137]\n",
      "[Epoch 7/50] [Batch 180/191] [D loss: 0.5824] [G loss: 0.5026]\n",
      "[Epoch 8/50] [Batch 0/191] [D loss: 0.5340] [G loss: 0.5317]\n",
      "[Epoch 8/50] [Batch 20/191] [D loss: 0.4696] [G loss: 0.5306]\n",
      "[Epoch 8/50] [Batch 40/191] [D loss: 0.5104] [G loss: 0.5267]\n",
      "[Epoch 8/50] [Batch 60/191] [D loss: 0.4473] [G loss: 0.5744]\n",
      "[Epoch 8/50] [Batch 80/191] [D loss: 0.4604] [G loss: 0.5889]\n",
      "[Epoch 8/50] [Batch 100/191] [D loss: 0.4613] [G loss: 0.5855]\n",
      "[Epoch 8/50] [Batch 120/191] [D loss: 0.4639] [G loss: 0.5827]\n",
      "[Epoch 8/50] [Batch 140/191] [D loss: 0.5068] [G loss: 0.5725]\n",
      "[Epoch 8/50] [Batch 160/191] [D loss: 0.5245] [G loss: 0.5518]\n",
      "[Epoch 8/50] [Batch 180/191] [D loss: 0.4223] [G loss: 0.6659]\n",
      "[Epoch 9/50] [Batch 0/191] [D loss: 0.5111] [G loss: 0.5716]\n",
      "[Epoch 9/50] [Batch 20/191] [D loss: 0.4681] [G loss: 0.6000]\n",
      "[Epoch 9/50] [Batch 40/191] [D loss: 0.4828] [G loss: 0.5829]\n",
      "[Epoch 9/50] [Batch 60/191] [D loss: 0.4692] [G loss: 0.5836]\n",
      "[Epoch 9/50] [Batch 80/191] [D loss: 0.5032] [G loss: 0.5633]\n",
      "[Epoch 9/50] [Batch 100/191] [D loss: 0.4912] [G loss: 0.6048]\n",
      "[Epoch 9/50] [Batch 120/191] [D loss: 0.4988] [G loss: 0.5362]\n",
      "[Epoch 9/50] [Batch 140/191] [D loss: 0.4866] [G loss: 0.5523]\n",
      "[Epoch 9/50] [Batch 160/191] [D loss: 0.4516] [G loss: 0.5964]\n",
      "[Epoch 9/50] [Batch 180/191] [D loss: 0.5170] [G loss: 0.5495]\n",
      "[Epoch 10/50] [Batch 0/191] [D loss: 0.5134] [G loss: 0.5512]\n",
      "[Epoch 10/50] [Batch 20/191] [D loss: 0.4810] [G loss: 0.5602]\n",
      "[Epoch 10/50] [Batch 40/191] [D loss: 0.4785] [G loss: 0.5705]\n",
      "[Epoch 10/50] [Batch 60/191] [D loss: 0.4799] [G loss: 0.6319]\n",
      "[Epoch 10/50] [Batch 80/191] [D loss: 0.4938] [G loss: 0.5430]\n",
      "[Epoch 10/50] [Batch 100/191] [D loss: 0.5239] [G loss: 0.5537]\n",
      "[Epoch 10/50] [Batch 120/191] [D loss: 0.4834] [G loss: 0.5869]\n",
      "[Epoch 10/50] [Batch 140/191] [D loss: 0.4605] [G loss: 0.6017]\n",
      "[Epoch 10/50] [Batch 160/191] [D loss: 0.4519] [G loss: 0.5961]\n",
      "[Epoch 10/50] [Batch 180/191] [D loss: 0.4448] [G loss: 0.6353]\n",
      "[Epoch 11/50] [Batch 0/191] [D loss: 0.5002] [G loss: 0.5380]\n",
      "[Epoch 11/50] [Batch 20/191] [D loss: 0.4573] [G loss: 0.6051]\n",
      "[Epoch 11/50] [Batch 40/191] [D loss: 0.4555] [G loss: 0.5931]\n",
      "[Epoch 11/50] [Batch 60/191] [D loss: 0.4392] [G loss: 0.6129]\n",
      "[Epoch 11/50] [Batch 80/191] [D loss: 0.4419] [G loss: 0.6820]\n",
      "[Epoch 11/50] [Batch 100/191] [D loss: 0.5247] [G loss: 0.5708]\n",
      "[Epoch 11/50] [Batch 120/191] [D loss: 0.4446] [G loss: 0.6406]\n",
      "[Epoch 11/50] [Batch 140/191] [D loss: 0.4730] [G loss: 0.6366]\n",
      "[Epoch 11/50] [Batch 160/191] [D loss: 0.4452] [G loss: 0.6502]\n",
      "[Epoch 11/50] [Batch 180/191] [D loss: 0.4389] [G loss: 0.7009]\n",
      "[Epoch 12/50] [Batch 0/191] [D loss: 0.4074] [G loss: 0.7733]\n",
      "[Epoch 12/50] [Batch 20/191] [D loss: 0.4822] [G loss: 0.6768]\n",
      "[Epoch 12/50] [Batch 40/191] [D loss: 0.4849] [G loss: 0.6191]\n",
      "[Epoch 12/50] [Batch 60/191] [D loss: 0.4858] [G loss: 0.5904]\n",
      "[Epoch 12/50] [Batch 80/191] [D loss: 0.4363] [G loss: 0.6495]\n",
      "[Epoch 12/50] [Batch 100/191] [D loss: 0.4983] [G loss: 0.6353]\n",
      "[Epoch 12/50] [Batch 120/191] [D loss: 0.4995] [G loss: 0.5918]\n",
      "[Epoch 12/50] [Batch 140/191] [D loss: 0.4605] [G loss: 0.6119]\n",
      "[Epoch 12/50] [Batch 160/191] [D loss: 0.4791] [G loss: 0.5864]\n",
      "[Epoch 12/50] [Batch 180/191] [D loss: 0.4616] [G loss: 0.6182]\n",
      "[Epoch 13/50] [Batch 0/191] [D loss: 0.5007] [G loss: 0.5823]\n",
      "[Epoch 13/50] [Batch 20/191] [D loss: 0.4546] [G loss: 0.6208]\n",
      "[Epoch 13/50] [Batch 40/191] [D loss: 0.4604] [G loss: 0.6200]\n",
      "[Epoch 13/50] [Batch 60/191] [D loss: 0.4482] [G loss: 0.6522]\n",
      "[Epoch 13/50] [Batch 80/191] [D loss: 0.3897] [G loss: 0.8071]\n",
      "[Epoch 13/50] [Batch 100/191] [D loss: 0.4651] [G loss: 0.6752]\n",
      "[Epoch 13/50] [Batch 120/191] [D loss: 0.4232] [G loss: 0.6773]\n",
      "[Epoch 13/50] [Batch 140/191] [D loss: 0.5206] [G loss: 0.5702]\n",
      "[Epoch 13/50] [Batch 160/191] [D loss: 0.4435] [G loss: 0.6705]\n",
      "[Epoch 13/50] [Batch 180/191] [D loss: 0.4326] [G loss: 0.6380]\n",
      "[Epoch 14/50] [Batch 0/191] [D loss: 0.5021] [G loss: 0.6134]\n",
      "[Epoch 14/50] [Batch 20/191] [D loss: 0.4546] [G loss: 0.6570]\n",
      "[Epoch 14/50] [Batch 40/191] [D loss: 0.4491] [G loss: 0.6552]\n",
      "[Epoch 14/50] [Batch 60/191] [D loss: 0.4639] [G loss: 0.6536]\n",
      "[Epoch 14/50] [Batch 80/191] [D loss: 0.4763] [G loss: 0.6159]\n",
      "[Epoch 14/50] [Batch 100/191] [D loss: 0.4314] [G loss: 0.6631]\n",
      "[Epoch 14/50] [Batch 120/191] [D loss: 0.5092] [G loss: 0.5843]\n",
      "[Epoch 14/50] [Batch 140/191] [D loss: 0.4841] [G loss: 0.6575]\n",
      "[Epoch 14/50] [Batch 160/191] [D loss: 0.4858] [G loss: 0.6039]\n",
      "[Epoch 14/50] [Batch 180/191] [D loss: 0.4593] [G loss: 0.6366]\n",
      "[Epoch 15/50] [Batch 0/191] [D loss: 0.4757] [G loss: 0.5971]\n",
      "[Epoch 15/50] [Batch 20/191] [D loss: 0.3920] [G loss: 0.7570]\n",
      "[Epoch 15/50] [Batch 40/191] [D loss: 0.4642] [G loss: 0.6784]\n",
      "[Epoch 15/50] [Batch 60/191] [D loss: 0.3973] [G loss: 0.7304]\n",
      "[Epoch 15/50] [Batch 80/191] [D loss: 0.4223] [G loss: 0.7195]\n",
      "[Epoch 15/50] [Batch 100/191] [D loss: 0.3721] [G loss: 0.8448]\n",
      "[Epoch 15/50] [Batch 120/191] [D loss: 0.4783] [G loss: 0.7320]\n",
      "[Epoch 15/50] [Batch 140/191] [D loss: 0.4187] [G loss: 0.7164]\n",
      "[Epoch 15/50] [Batch 160/191] [D loss: 0.4736] [G loss: 0.7209]\n",
      "[Epoch 15/50] [Batch 180/191] [D loss: 0.4840] [G loss: 0.6536]\n",
      "[Epoch 16/50] [Batch 0/191] [D loss: 0.4774] [G loss: 0.6217]\n",
      "[Epoch 16/50] [Batch 20/191] [D loss: 0.5119] [G loss: 0.5396]\n",
      "[Epoch 16/50] [Batch 40/191] [D loss: 0.4746] [G loss: 0.6061]\n",
      "[Epoch 16/50] [Batch 60/191] [D loss: 0.4356] [G loss: 0.6530]\n",
      "[Epoch 16/50] [Batch 80/191] [D loss: 0.4170] [G loss: 0.6608]\n",
      "[Epoch 16/50] [Batch 100/191] [D loss: 0.4083] [G loss: 0.7104]\n",
      "[Epoch 16/50] [Batch 120/191] [D loss: 0.4877] [G loss: 0.6440]\n",
      "[Epoch 16/50] [Batch 140/191] [D loss: 0.4058] [G loss: 0.7551]\n",
      "[Epoch 16/50] [Batch 160/191] [D loss: 0.4339] [G loss: 0.7081]\n",
      "[Epoch 16/50] [Batch 180/191] [D loss: 0.4268] [G loss: 0.7711]\n",
      "[Epoch 17/50] [Batch 0/191] [D loss: 0.3886] [G loss: 0.7981]\n",
      "[Epoch 17/50] [Batch 20/191] [D loss: 0.4750] [G loss: 0.6521]\n",
      "[Epoch 17/50] [Batch 40/191] [D loss: 0.4382] [G loss: 0.6796]\n",
      "[Epoch 17/50] [Batch 60/191] [D loss: 0.4047] [G loss: 0.7386]\n",
      "[Epoch 17/50] [Batch 80/191] [D loss: 0.4540] [G loss: 0.7251]\n",
      "[Epoch 17/50] [Batch 100/191] [D loss: 0.4766] [G loss: 0.6609]\n",
      "[Epoch 17/50] [Batch 120/191] [D loss: 0.4552] [G loss: 0.6521]\n",
      "[Epoch 17/50] [Batch 140/191] [D loss: 0.4649] [G loss: 0.6986]\n",
      "[Epoch 17/50] [Batch 160/191] [D loss: 0.4456] [G loss: 0.6784]\n",
      "[Epoch 17/50] [Batch 180/191] [D loss: 0.4945] [G loss: 0.6730]\n",
      "[Epoch 18/50] [Batch 0/191] [D loss: 0.4663] [G loss: 0.6712]\n",
      "[Epoch 18/50] [Batch 20/191] [D loss: 0.4452] [G loss: 0.6550]\n",
      "[Epoch 18/50] [Batch 40/191] [D loss: 0.4507] [G loss: 0.6824]\n",
      "[Epoch 18/50] [Batch 60/191] [D loss: 0.4127] [G loss: 0.8055]\n",
      "[Epoch 18/50] [Batch 80/191] [D loss: 0.3698] [G loss: 0.8145]\n",
      "[Epoch 18/50] [Batch 100/191] [D loss: 0.4770] [G loss: 0.6702]\n",
      "[Epoch 18/50] [Batch 120/191] [D loss: 0.4387] [G loss: 0.6394]\n",
      "[Epoch 18/50] [Batch 140/191] [D loss: 0.4142] [G loss: 0.7427]\n",
      "[Epoch 18/50] [Batch 160/191] [D loss: 0.4645] [G loss: 0.6679]\n",
      "[Epoch 18/50] [Batch 180/191] [D loss: 0.4392] [G loss: 0.6337]\n",
      "[Epoch 19/50] [Batch 0/191] [D loss: 0.4984] [G loss: 0.6510]\n",
      "[Epoch 19/50] [Batch 20/191] [D loss: 0.4172] [G loss: 0.7165]\n",
      "[Epoch 19/50] [Batch 40/191] [D loss: 0.4229] [G loss: 0.7981]\n",
      "[Epoch 19/50] [Batch 60/191] [D loss: 0.4031] [G loss: 0.8435]\n",
      "[Epoch 19/50] [Batch 80/191] [D loss: 0.4097] [G loss: 0.8133]\n",
      "[Epoch 19/50] [Batch 100/191] [D loss: 0.4762] [G loss: 0.7192]\n",
      "[Epoch 19/50] [Batch 120/191] [D loss: 0.3984] [G loss: 0.7774]\n",
      "[Epoch 19/50] [Batch 140/191] [D loss: 0.3636] [G loss: 0.8406]\n",
      "[Epoch 19/50] [Batch 160/191] [D loss: 0.3982] [G loss: 0.9119]\n",
      "[Epoch 19/50] [Batch 180/191] [D loss: 0.4245] [G loss: 0.8439]\n",
      "[Epoch 20/50] [Batch 0/191] [D loss: 0.3982] [G loss: 0.9697]\n",
      "[Epoch 20/50] [Batch 20/191] [D loss: 0.4442] [G loss: 0.7296]\n",
      "[Epoch 20/50] [Batch 40/191] [D loss: 0.4798] [G loss: 0.6766]\n",
      "[Epoch 20/50] [Batch 60/191] [D loss: 0.4919] [G loss: 0.6542]\n",
      "[Epoch 20/50] [Batch 80/191] [D loss: 0.4217] [G loss: 0.7879]\n",
      "[Epoch 20/50] [Batch 100/191] [D loss: 0.4419] [G loss: 0.7599]\n",
      "[Epoch 20/50] [Batch 120/191] [D loss: 0.4304] [G loss: 0.7490]\n",
      "[Epoch 20/50] [Batch 140/191] [D loss: 0.4240] [G loss: 0.6744]\n",
      "[Epoch 20/50] [Batch 160/191] [D loss: 0.4176] [G loss: 0.8097]\n",
      "[Epoch 20/50] [Batch 180/191] [D loss: 0.3874] [G loss: 0.7844]\n",
      "[Epoch 21/50] [Batch 0/191] [D loss: 0.4477] [G loss: 0.8389]\n",
      "[Epoch 21/50] [Batch 20/191] [D loss: 0.3855] [G loss: 0.8606]\n",
      "[Epoch 21/50] [Batch 40/191] [D loss: 0.4111] [G loss: 0.8166]\n",
      "[Epoch 21/50] [Batch 60/191] [D loss: 0.4035] [G loss: 0.8539]\n",
      "[Epoch 21/50] [Batch 80/191] [D loss: 0.5000] [G loss: 0.7140]\n",
      "[Epoch 21/50] [Batch 100/191] [D loss: 0.3673] [G loss: 0.8476]\n",
      "[Epoch 21/50] [Batch 120/191] [D loss: 0.3625] [G loss: 0.8427]\n",
      "[Epoch 21/50] [Batch 140/191] [D loss: 0.3922] [G loss: 0.8392]\n",
      "[Epoch 21/50] [Batch 160/191] [D loss: 0.4701] [G loss: 0.7411]\n",
      "[Epoch 21/50] [Batch 180/191] [D loss: 0.4537] [G loss: 0.7163]\n",
      "[Epoch 22/50] [Batch 0/191] [D loss: 0.3857] [G loss: 0.8327]\n",
      "[Epoch 22/50] [Batch 20/191] [D loss: 0.4230] [G loss: 0.8462]\n",
      "[Epoch 22/50] [Batch 40/191] [D loss: 0.4379] [G loss: 0.7326]\n",
      "[Epoch 22/50] [Batch 60/191] [D loss: 0.4225] [G loss: 0.7261]\n",
      "[Epoch 22/50] [Batch 80/191] [D loss: 0.4043] [G loss: 0.7696]\n",
      "[Epoch 22/50] [Batch 100/191] [D loss: 0.4596] [G loss: 0.7131]\n",
      "[Epoch 22/50] [Batch 120/191] [D loss: 0.3892] [G loss: 0.8176]\n",
      "[Epoch 22/50] [Batch 140/191] [D loss: 0.4643] [G loss: 0.7120]\n",
      "[Epoch 22/50] [Batch 160/191] [D loss: 0.4539] [G loss: 0.6892]\n",
      "[Epoch 22/50] [Batch 180/191] [D loss: 0.4339] [G loss: 0.7153]\n",
      "[Epoch 23/50] [Batch 0/191] [D loss: 0.4276] [G loss: 0.7973]\n",
      "[Epoch 23/50] [Batch 20/191] [D loss: 0.3907] [G loss: 0.8438]\n",
      "[Epoch 23/50] [Batch 40/191] [D loss: 0.4390] [G loss: 0.8217]\n",
      "[Epoch 23/50] [Batch 60/191] [D loss: 0.4666] [G loss: 0.7269]\n",
      "[Epoch 23/50] [Batch 80/191] [D loss: 0.3814] [G loss: 0.9350]\n",
      "[Epoch 23/50] [Batch 100/191] [D loss: 0.4228] [G loss: 0.7589]\n",
      "[Epoch 23/50] [Batch 120/191] [D loss: 0.5472] [G loss: 0.6855]\n",
      "[Epoch 23/50] [Batch 140/191] [D loss: 0.4730] [G loss: 0.6991]\n",
      "[Epoch 23/50] [Batch 160/191] [D loss: 0.4954] [G loss: 0.6520]\n",
      "[Epoch 23/50] [Batch 180/191] [D loss: 0.4298] [G loss: 0.8157]\n",
      "[Epoch 24/50] [Batch 0/191] [D loss: 0.4658] [G loss: 0.7498]\n",
      "[Epoch 24/50] [Batch 20/191] [D loss: 0.4837] [G loss: 0.6969]\n",
      "[Epoch 24/50] [Batch 40/191] [D loss: 0.4315] [G loss: 0.8234]\n",
      "[Epoch 24/50] [Batch 60/191] [D loss: 0.4006] [G loss: 0.7898]\n",
      "[Epoch 24/50] [Batch 80/191] [D loss: 0.4825] [G loss: 0.6707]\n",
      "[Epoch 24/50] [Batch 100/191] [D loss: 0.4000] [G loss: 0.8020]\n",
      "[Epoch 24/50] [Batch 120/191] [D loss: 0.4554] [G loss: 0.7284]\n",
      "[Epoch 24/50] [Batch 140/191] [D loss: 0.4193] [G loss: 0.7936]\n",
      "[Epoch 24/50] [Batch 160/191] [D loss: 0.4197] [G loss: 0.7420]\n",
      "[Epoch 24/50] [Batch 180/191] [D loss: 0.4279] [G loss: 0.9198]\n",
      "[Epoch 25/50] [Batch 0/191] [D loss: 0.4070] [G loss: 0.8485]\n",
      "[Epoch 25/50] [Batch 20/191] [D loss: 0.4301] [G loss: 0.7797]\n",
      "[Epoch 25/50] [Batch 40/191] [D loss: 0.3657] [G loss: 0.8944]\n",
      "[Epoch 25/50] [Batch 60/191] [D loss: 0.4316] [G loss: 0.7741]\n",
      "[Epoch 25/50] [Batch 80/191] [D loss: 0.4719] [G loss: 0.6513]\n",
      "[Epoch 25/50] [Batch 100/191] [D loss: 0.4138] [G loss: 0.7596]\n",
      "[Epoch 25/50] [Batch 120/191] [D loss: 0.4187] [G loss: 0.7771]\n",
      "[Epoch 25/50] [Batch 140/191] [D loss: 0.3524] [G loss: 0.8767]\n",
      "[Epoch 25/50] [Batch 160/191] [D loss: 0.3729] [G loss: 0.9009]\n",
      "[Epoch 25/50] [Batch 180/191] [D loss: 0.4309] [G loss: 0.7493]\n",
      "[Epoch 26/50] [Batch 0/191] [D loss: 0.4574] [G loss: 0.7502]\n",
      "[Epoch 26/50] [Batch 20/191] [D loss: 0.4097] [G loss: 0.7757]\n",
      "[Epoch 26/50] [Batch 40/191] [D loss: 0.4415] [G loss: 0.7361]\n",
      "[Epoch 26/50] [Batch 60/191] [D loss: 0.3617] [G loss: 0.9507]\n",
      "[Epoch 26/50] [Batch 80/191] [D loss: 0.3795] [G loss: 0.9676]\n",
      "[Epoch 26/50] [Batch 100/191] [D loss: 0.4912] [G loss: 0.6124]\n",
      "[Epoch 26/50] [Batch 120/191] [D loss: 0.4363] [G loss: 0.7255]\n",
      "[Epoch 26/50] [Batch 140/191] [D loss: 0.3541] [G loss: 0.8900]\n",
      "[Epoch 26/50] [Batch 160/191] [D loss: 0.3692] [G loss: 0.9326]\n",
      "[Epoch 26/50] [Batch 180/191] [D loss: 0.3923] [G loss: 0.8786]\n",
      "[Epoch 27/50] [Batch 0/191] [D loss: 0.5215] [G loss: 0.6396]\n",
      "[Epoch 27/50] [Batch 20/191] [D loss: 0.4166] [G loss: 0.8728]\n",
      "[Epoch 27/50] [Batch 40/191] [D loss: 0.3986] [G loss: 0.7605]\n",
      "[Epoch 27/50] [Batch 60/191] [D loss: 0.3869] [G loss: 0.8063]\n",
      "[Epoch 27/50] [Batch 80/191] [D loss: 0.3458] [G loss: 0.9400]\n",
      "[Epoch 27/50] [Batch 100/191] [D loss: 0.4540] [G loss: 0.8501]\n",
      "[Epoch 27/50] [Batch 120/191] [D loss: 0.3797] [G loss: 0.8371]\n",
      "[Epoch 27/50] [Batch 140/191] [D loss: 0.5542] [G loss: 0.7691]\n",
      "[Epoch 27/50] [Batch 160/191] [D loss: 0.4349] [G loss: 0.7734]\n",
      "[Epoch 27/50] [Batch 180/191] [D loss: 0.4513] [G loss: 0.7200]\n",
      "[Epoch 28/50] [Batch 0/191] [D loss: 0.3788] [G loss: 0.7782]\n",
      "[Epoch 28/50] [Batch 20/191] [D loss: 0.3727] [G loss: 0.9158]\n",
      "[Epoch 28/50] [Batch 40/191] [D loss: 0.3926] [G loss: 0.9209]\n",
      "[Epoch 28/50] [Batch 60/191] [D loss: 0.4563] [G loss: 0.8095]\n",
      "[Epoch 28/50] [Batch 80/191] [D loss: 0.4123] [G loss: 0.8222]\n",
      "[Epoch 28/50] [Batch 100/191] [D loss: 0.3883] [G loss: 0.8728]\n",
      "[Epoch 28/50] [Batch 120/191] [D loss: 0.4276] [G loss: 0.8061]\n",
      "[Epoch 28/50] [Batch 140/191] [D loss: 0.4114] [G loss: 0.8383]\n",
      "[Epoch 28/50] [Batch 160/191] [D loss: 0.4555] [G loss: 0.7514]\n",
      "[Epoch 28/50] [Batch 180/191] [D loss: 0.4305] [G loss: 0.8260]\n",
      "[Epoch 29/50] [Batch 0/191] [D loss: 0.4073] [G loss: 0.8611]\n",
      "[Epoch 29/50] [Batch 20/191] [D loss: 0.3677] [G loss: 0.9805]\n",
      "[Epoch 29/50] [Batch 40/191] [D loss: 0.4003] [G loss: 0.9373]\n",
      "[Epoch 29/50] [Batch 60/191] [D loss: 0.3753] [G loss: 0.9496]\n",
      "[Epoch 29/50] [Batch 80/191] [D loss: 0.3727] [G loss: 0.9884]\n",
      "[Epoch 29/50] [Batch 100/191] [D loss: 0.3981] [G loss: 0.9209]\n",
      "[Epoch 29/50] [Batch 120/191] [D loss: 0.3955] [G loss: 0.9235]\n",
      "[Epoch 29/50] [Batch 140/191] [D loss: 0.3445] [G loss: 0.8716]\n",
      "[Epoch 29/50] [Batch 160/191] [D loss: 0.4200] [G loss: 0.8495]\n",
      "[Epoch 29/50] [Batch 180/191] [D loss: 0.4305] [G loss: 0.8876]\n",
      "[Epoch 30/50] [Batch 0/191] [D loss: 0.3871] [G loss: 0.9136]\n",
      "[Epoch 30/50] [Batch 20/191] [D loss: 0.4410] [G loss: 0.8348]\n",
      "[Epoch 30/50] [Batch 40/191] [D loss: 0.4114] [G loss: 1.0950]\n",
      "[Epoch 30/50] [Batch 60/191] [D loss: 0.3720] [G loss: 0.9902]\n",
      "[Epoch 30/50] [Batch 80/191] [D loss: 0.3614] [G loss: 1.0218]\n",
      "[Epoch 30/50] [Batch 100/191] [D loss: 0.3910] [G loss: 0.9353]\n",
      "[Epoch 30/50] [Batch 120/191] [D loss: 0.3726] [G loss: 0.9275]\n",
      "[Epoch 30/50] [Batch 140/191] [D loss: 0.4647] [G loss: 0.8665]\n",
      "[Epoch 30/50] [Batch 160/191] [D loss: 0.4072] [G loss: 0.9558]\n",
      "[Epoch 30/50] [Batch 180/191] [D loss: 0.4404] [G loss: 0.8564]\n",
      "[Epoch 31/50] [Batch 0/191] [D loss: 0.4019] [G loss: 0.7938]\n",
      "[Epoch 31/50] [Batch 20/191] [D loss: 0.3605] [G loss: 0.9883]\n",
      "[Epoch 31/50] [Batch 40/191] [D loss: 0.4356] [G loss: 0.7083]\n",
      "[Epoch 31/50] [Batch 60/191] [D loss: 0.4278] [G loss: 0.8577]\n",
      "[Epoch 31/50] [Batch 80/191] [D loss: 0.3769] [G loss: 0.8853]\n",
      "[Epoch 31/50] [Batch 100/191] [D loss: 0.4205] [G loss: 0.8880]\n",
      "[Epoch 31/50] [Batch 120/191] [D loss: 0.4061] [G loss: 0.8267]\n",
      "[Epoch 31/50] [Batch 140/191] [D loss: 0.3913] [G loss: 0.8700]\n",
      "[Epoch 31/50] [Batch 160/191] [D loss: 0.3944] [G loss: 0.7530]\n",
      "[Epoch 31/50] [Batch 180/191] [D loss: 0.3825] [G loss: 0.8229]\n",
      "[Epoch 32/50] [Batch 0/191] [D loss: 0.3798] [G loss: 0.8460]\n",
      "[Epoch 32/50] [Batch 20/191] [D loss: 0.4000] [G loss: 0.9807]\n",
      "[Epoch 32/50] [Batch 40/191] [D loss: 0.3779] [G loss: 0.9401]\n",
      "[Epoch 32/50] [Batch 60/191] [D loss: 0.3677] [G loss: 0.9165]\n",
      "[Epoch 32/50] [Batch 80/191] [D loss: 0.3695] [G loss: 0.8048]\n",
      "[Epoch 32/50] [Batch 100/191] [D loss: 0.3962] [G loss: 0.7954]\n",
      "[Epoch 32/50] [Batch 120/191] [D loss: 0.4108] [G loss: 0.8490]\n",
      "[Epoch 32/50] [Batch 140/191] [D loss: 0.3860] [G loss: 0.9330]\n",
      "[Epoch 32/50] [Batch 160/191] [D loss: 0.3910] [G loss: 1.0434]\n",
      "[Epoch 32/50] [Batch 180/191] [D loss: 0.4402] [G loss: 0.9502]\n",
      "[Epoch 33/50] [Batch 0/191] [D loss: 0.4079] [G loss: 1.0543]\n",
      "[Epoch 33/50] [Batch 20/191] [D loss: 0.3356] [G loss: 1.1679]\n",
      "[Epoch 33/50] [Batch 40/191] [D loss: 0.4124] [G loss: 0.8842]\n",
      "[Epoch 33/50] [Batch 60/191] [D loss: 0.4148] [G loss: 0.9241]\n",
      "[Epoch 33/50] [Batch 80/191] [D loss: 0.3890] [G loss: 0.9340]\n",
      "[Epoch 33/50] [Batch 100/191] [D loss: 0.3498] [G loss: 0.9768]\n",
      "[Epoch 33/50] [Batch 120/191] [D loss: 0.3942] [G loss: 0.8702]\n",
      "[Epoch 33/50] [Batch 140/191] [D loss: 0.3540] [G loss: 0.9121]\n",
      "[Epoch 33/50] [Batch 160/191] [D loss: 0.4032] [G loss: 0.9159]\n",
      "[Epoch 33/50] [Batch 180/191] [D loss: 0.3910] [G loss: 0.9274]\n",
      "[Epoch 34/50] [Batch 0/191] [D loss: 0.3557] [G loss: 1.0311]\n",
      "[Epoch 34/50] [Batch 20/191] [D loss: 0.3227] [G loss: 1.1840]\n",
      "[Epoch 34/50] [Batch 40/191] [D loss: 0.3222] [G loss: 1.0748]\n",
      "[Epoch 34/50] [Batch 60/191] [D loss: 0.3536] [G loss: 0.9663]\n",
      "[Epoch 34/50] [Batch 80/191] [D loss: 0.3937] [G loss: 1.0477]\n",
      "[Epoch 34/50] [Batch 100/191] [D loss: 0.3867] [G loss: 1.0581]\n",
      "[Epoch 34/50] [Batch 120/191] [D loss: 0.3905] [G loss: 1.0205]\n",
      "[Epoch 34/50] [Batch 140/191] [D loss: 0.3790] [G loss: 0.8472]\n",
      "[Epoch 34/50] [Batch 160/191] [D loss: 0.4684] [G loss: 0.7542]\n",
      "[Epoch 34/50] [Batch 180/191] [D loss: 0.3871] [G loss: 0.8756]\n",
      "[Epoch 35/50] [Batch 0/191] [D loss: 0.3915] [G loss: 0.9136]\n",
      "[Epoch 35/50] [Batch 20/191] [D loss: 0.3936] [G loss: 0.8750]\n",
      "[Epoch 35/50] [Batch 40/191] [D loss: 0.3935] [G loss: 0.8516]\n",
      "[Epoch 35/50] [Batch 60/191] [D loss: 0.4078] [G loss: 0.7889]\n",
      "[Epoch 35/50] [Batch 80/191] [D loss: 0.3784] [G loss: 0.8094]\n",
      "[Epoch 35/50] [Batch 100/191] [D loss: 0.4102] [G loss: 0.8362]\n",
      "[Epoch 35/50] [Batch 120/191] [D loss: 0.3631] [G loss: 0.9071]\n",
      "[Epoch 35/50] [Batch 140/191] [D loss: 0.3855] [G loss: 0.8894]\n",
      "[Epoch 35/50] [Batch 160/191] [D loss: 0.3761] [G loss: 0.8856]\n",
      "[Epoch 35/50] [Batch 180/191] [D loss: 0.3717] [G loss: 1.0479]\n",
      "[Epoch 36/50] [Batch 0/191] [D loss: 0.3917] [G loss: 1.0886]\n",
      "[Epoch 36/50] [Batch 20/191] [D loss: 0.4141] [G loss: 0.8702]\n",
      "[Epoch 36/50] [Batch 40/191] [D loss: 0.3715] [G loss: 0.9001]\n",
      "[Epoch 36/50] [Batch 60/191] [D loss: 0.3445] [G loss: 1.0914]\n",
      "[Epoch 36/50] [Batch 80/191] [D loss: 0.3056] [G loss: 1.1754]\n",
      "[Epoch 36/50] [Batch 100/191] [D loss: 0.3369] [G loss: 1.0546]\n",
      "[Epoch 36/50] [Batch 120/191] [D loss: 0.3827] [G loss: 0.9520]\n",
      "[Epoch 36/50] [Batch 140/191] [D loss: 0.3525] [G loss: 0.9927]\n",
      "[Epoch 36/50] [Batch 160/191] [D loss: 0.3610] [G loss: 1.0023]\n",
      "[Epoch 36/50] [Batch 180/191] [D loss: 0.3313] [G loss: 1.1338]\n",
      "[Epoch 37/50] [Batch 0/191] [D loss: 0.3482] [G loss: 1.1113]\n",
      "[Epoch 37/50] [Batch 20/191] [D loss: 0.3398] [G loss: 0.9717]\n",
      "[Epoch 37/50] [Batch 40/191] [D loss: 0.3446] [G loss: 1.1905]\n",
      "[Epoch 37/50] [Batch 60/191] [D loss: 0.3178] [G loss: 1.1606]\n",
      "[Epoch 37/50] [Batch 80/191] [D loss: 0.3059] [G loss: 1.2104]\n",
      "[Epoch 37/50] [Batch 100/191] [D loss: 0.3434] [G loss: 1.1132]\n",
      "[Epoch 37/50] [Batch 120/191] [D loss: 0.3828] [G loss: 1.0042]\n",
      "[Epoch 37/50] [Batch 140/191] [D loss: 0.3455] [G loss: 1.1738]\n",
      "[Epoch 37/50] [Batch 160/191] [D loss: 0.3308] [G loss: 1.1516]\n",
      "[Epoch 37/50] [Batch 180/191] [D loss: 0.3336] [G loss: 1.2003]\n",
      "[Epoch 38/50] [Batch 0/191] [D loss: 0.3702] [G loss: 1.1101]\n",
      "[Epoch 38/50] [Batch 20/191] [D loss: 0.3292] [G loss: 1.1911]\n",
      "[Epoch 38/50] [Batch 40/191] [D loss: 0.3834] [G loss: 0.8424]\n",
      "[Epoch 38/50] [Batch 60/191] [D loss: 0.3508] [G loss: 1.0751]\n",
      "[Epoch 38/50] [Batch 80/191] [D loss: 0.3277] [G loss: 0.9432]\n",
      "[Epoch 38/50] [Batch 100/191] [D loss: 0.4647] [G loss: 0.8001]\n",
      "[Epoch 38/50] [Batch 120/191] [D loss: 0.3680] [G loss: 1.0348]\n",
      "[Epoch 38/50] [Batch 140/191] [D loss: 0.4340] [G loss: 0.8520]\n",
      "[Epoch 38/50] [Batch 160/191] [D loss: 0.3566] [G loss: 1.0214]\n",
      "[Epoch 38/50] [Batch 180/191] [D loss: 0.3806] [G loss: 0.9638]\n",
      "[Epoch 39/50] [Batch 0/191] [D loss: 0.3884] [G loss: 0.9524]\n",
      "[Epoch 39/50] [Batch 20/191] [D loss: 0.3927] [G loss: 1.0505]\n",
      "[Epoch 39/50] [Batch 40/191] [D loss: 0.3687] [G loss: 1.0420]\n",
      "[Epoch 39/50] [Batch 60/191] [D loss: 0.3891] [G loss: 0.9036]\n",
      "[Epoch 39/50] [Batch 80/191] [D loss: 0.3777] [G loss: 0.9495]\n",
      "[Epoch 39/50] [Batch 100/191] [D loss: 0.3489] [G loss: 0.9487]\n",
      "[Epoch 39/50] [Batch 120/191] [D loss: 0.3834] [G loss: 0.9127]\n",
      "[Epoch 39/50] [Batch 140/191] [D loss: 0.3556] [G loss: 0.9897]\n",
      "[Epoch 39/50] [Batch 160/191] [D loss: 0.4027] [G loss: 1.0861]\n",
      "[Epoch 39/50] [Batch 180/191] [D loss: 0.3580] [G loss: 1.0226]\n",
      "[Epoch 40/50] [Batch 0/191] [D loss: 0.3588] [G loss: 1.1244]\n",
      "[Epoch 40/50] [Batch 20/191] [D loss: 0.4421] [G loss: 0.9891]\n",
      "[Epoch 40/50] [Batch 40/191] [D loss: 0.3790] [G loss: 1.0602]\n",
      "[Epoch 40/50] [Batch 60/191] [D loss: 0.3604] [G loss: 0.8625]\n",
      "[Epoch 40/50] [Batch 80/191] [D loss: 0.3870] [G loss: 0.9457]\n",
      "[Epoch 40/50] [Batch 100/191] [D loss: 0.3761] [G loss: 0.9071]\n",
      "[Epoch 40/50] [Batch 120/191] [D loss: 0.3876] [G loss: 0.8623]\n",
      "[Epoch 40/50] [Batch 140/191] [D loss: 0.3922] [G loss: 1.0020]\n",
      "[Epoch 40/50] [Batch 160/191] [D loss: 0.4173] [G loss: 0.9643]\n",
      "[Epoch 40/50] [Batch 180/191] [D loss: 0.3658] [G loss: 0.9194]\n",
      "[Epoch 41/50] [Batch 0/191] [D loss: 0.3630] [G loss: 0.9752]\n",
      "[Epoch 41/50] [Batch 20/191] [D loss: 0.3732] [G loss: 0.9580]\n",
      "[Epoch 41/50] [Batch 40/191] [D loss: 0.3607] [G loss: 1.0417]\n",
      "[Epoch 41/50] [Batch 60/191] [D loss: 0.3488] [G loss: 0.9976]\n",
      "[Epoch 41/50] [Batch 80/191] [D loss: 0.3986] [G loss: 0.8483]\n",
      "[Epoch 41/50] [Batch 100/191] [D loss: 0.4123] [G loss: 0.8817]\n",
      "[Epoch 41/50] [Batch 120/191] [D loss: 0.3651] [G loss: 0.9619]\n",
      "[Epoch 41/50] [Batch 140/191] [D loss: 0.3570] [G loss: 1.0944]\n",
      "[Epoch 41/50] [Batch 160/191] [D loss: 0.3741] [G loss: 0.9995]\n",
      "[Epoch 41/50] [Batch 180/191] [D loss: 0.4186] [G loss: 0.8970]\n",
      "[Epoch 42/50] [Batch 0/191] [D loss: 0.3458] [G loss: 1.0453]\n",
      "[Epoch 42/50] [Batch 20/191] [D loss: 0.3589] [G loss: 1.0399]\n",
      "[Epoch 42/50] [Batch 40/191] [D loss: 0.3487] [G loss: 1.0058]\n",
      "[Epoch 42/50] [Batch 60/191] [D loss: 0.3472] [G loss: 0.9598]\n",
      "[Epoch 42/50] [Batch 80/191] [D loss: 0.3381] [G loss: 0.9970]\n",
      "[Epoch 42/50] [Batch 100/191] [D loss: 0.3676] [G loss: 1.0347]\n",
      "[Epoch 42/50] [Batch 120/191] [D loss: 0.3618] [G loss: 0.9775]\n",
      "[Epoch 42/50] [Batch 140/191] [D loss: 0.3666] [G loss: 1.0155]\n",
      "[Epoch 42/50] [Batch 160/191] [D loss: 0.3863] [G loss: 1.0780]\n",
      "[Epoch 42/50] [Batch 180/191] [D loss: 0.3879] [G loss: 1.1235]\n",
      "[Epoch 43/50] [Batch 0/191] [D loss: 0.3504] [G loss: 1.3104]\n",
      "[Epoch 43/50] [Batch 20/191] [D loss: 0.3267] [G loss: 1.3323]\n",
      "[Epoch 43/50] [Batch 40/191] [D loss: 0.4199] [G loss: 0.9525]\n",
      "[Epoch 43/50] [Batch 60/191] [D loss: 0.3455] [G loss: 1.2025]\n",
      "[Epoch 43/50] [Batch 80/191] [D loss: 0.3711] [G loss: 1.1661]\n",
      "[Epoch 43/50] [Batch 100/191] [D loss: 0.3801] [G loss: 1.0565]\n",
      "[Epoch 43/50] [Batch 120/191] [D loss: 0.3590] [G loss: 1.0271]\n",
      "[Epoch 43/50] [Batch 140/191] [D loss: 0.3258] [G loss: 1.1254]\n",
      "[Epoch 43/50] [Batch 160/191] [D loss: 0.3690] [G loss: 1.1255]\n",
      "[Epoch 43/50] [Batch 180/191] [D loss: 0.3265] [G loss: 1.1252]\n",
      "[Epoch 44/50] [Batch 0/191] [D loss: 0.3829] [G loss: 1.0842]\n",
      "[Epoch 44/50] [Batch 20/191] [D loss: 0.3600] [G loss: 1.0041]\n",
      "[Epoch 44/50] [Batch 40/191] [D loss: 0.3630] [G loss: 1.0365]\n",
      "[Epoch 44/50] [Batch 60/191] [D loss: 0.3901] [G loss: 0.9838]\n",
      "[Epoch 44/50] [Batch 80/191] [D loss: 0.3883] [G loss: 0.9429]\n",
      "[Epoch 44/50] [Batch 100/191] [D loss: 0.3429] [G loss: 1.0476]\n",
      "[Epoch 44/50] [Batch 120/191] [D loss: 0.3975] [G loss: 0.8812]\n",
      "[Epoch 44/50] [Batch 140/191] [D loss: 0.3067] [G loss: 1.1363]\n",
      "[Epoch 44/50] [Batch 160/191] [D loss: 0.3386] [G loss: 1.0721]\n",
      "[Epoch 44/50] [Batch 180/191] [D loss: 0.3308] [G loss: 1.3441]\n",
      "[Epoch 45/50] [Batch 0/191] [D loss: 0.3197] [G loss: 1.0982]\n",
      "[Epoch 45/50] [Batch 20/191] [D loss: 0.3516] [G loss: 1.1340]\n",
      "[Epoch 45/50] [Batch 40/191] [D loss: 0.4098] [G loss: 1.0833]\n",
      "[Epoch 45/50] [Batch 60/191] [D loss: 0.3991] [G loss: 0.9633]\n",
      "[Epoch 45/50] [Batch 80/191] [D loss: 0.3973] [G loss: 1.0686]\n",
      "[Epoch 45/50] [Batch 100/191] [D loss: 0.3566] [G loss: 1.0922]\n",
      "[Epoch 45/50] [Batch 120/191] [D loss: 0.3292] [G loss: 1.1022]\n",
      "[Epoch 45/50] [Batch 140/191] [D loss: 0.2975] [G loss: 1.2887]\n",
      "[Epoch 45/50] [Batch 160/191] [D loss: 0.3321] [G loss: 1.1319]\n",
      "[Epoch 45/50] [Batch 180/191] [D loss: 0.3504] [G loss: 1.2019]\n",
      "[Epoch 46/50] [Batch 0/191] [D loss: 0.3647] [G loss: 0.9605]\n",
      "[Epoch 46/50] [Batch 20/191] [D loss: 0.4457] [G loss: 0.8976]\n",
      "[Epoch 46/50] [Batch 40/191] [D loss: 0.4072] [G loss: 1.0341]\n",
      "[Epoch 46/50] [Batch 60/191] [D loss: 0.3785] [G loss: 1.0277]\n",
      "[Epoch 46/50] [Batch 80/191] [D loss: 0.3528] [G loss: 1.0812]\n",
      "[Epoch 46/50] [Batch 100/191] [D loss: 0.3498] [G loss: 0.9882]\n",
      "[Epoch 46/50] [Batch 120/191] [D loss: 0.3463] [G loss: 1.0252]\n",
      "[Epoch 46/50] [Batch 140/191] [D loss: 0.3863] [G loss: 1.1142]\n",
      "[Epoch 46/50] [Batch 160/191] [D loss: 0.3371] [G loss: 1.1557]\n",
      "[Epoch 46/50] [Batch 180/191] [D loss: 0.3853] [G loss: 0.8256]\n",
      "[Epoch 47/50] [Batch 0/191] [D loss: 0.3793] [G loss: 0.9789]\n",
      "[Epoch 47/50] [Batch 20/191] [D loss: 0.3523] [G loss: 1.1463]\n",
      "[Epoch 47/50] [Batch 40/191] [D loss: 0.3283] [G loss: 1.2877]\n",
      "[Epoch 47/50] [Batch 60/191] [D loss: 0.3879] [G loss: 1.1133]\n",
      "[Epoch 47/50] [Batch 80/191] [D loss: 0.4891] [G loss: 0.9279]\n",
      "[Epoch 47/50] [Batch 100/191] [D loss: 0.3661] [G loss: 1.1420]\n",
      "[Epoch 47/50] [Batch 120/191] [D loss: 0.3950] [G loss: 1.1404]\n",
      "[Epoch 47/50] [Batch 140/191] [D loss: 0.4164] [G loss: 0.9047]\n",
      "[Epoch 47/50] [Batch 160/191] [D loss: 0.3744] [G loss: 0.9341]\n",
      "[Epoch 47/50] [Batch 180/191] [D loss: 0.3655] [G loss: 1.0194]\n",
      "[Epoch 48/50] [Batch 0/191] [D loss: 0.3941] [G loss: 0.9457]\n",
      "[Epoch 48/50] [Batch 20/191] [D loss: 0.3809] [G loss: 1.1718]\n",
      "[Epoch 48/50] [Batch 40/191] [D loss: 0.3727] [G loss: 1.0731]\n",
      "[Epoch 48/50] [Batch 60/191] [D loss: 0.3808] [G loss: 0.9885]\n",
      "[Epoch 48/50] [Batch 80/191] [D loss: 0.3693] [G loss: 1.0456]\n",
      "[Epoch 48/50] [Batch 100/191] [D loss: 0.3751] [G loss: 1.0463]\n",
      "[Epoch 48/50] [Batch 120/191] [D loss: 0.4401] [G loss: 0.7772]\n",
      "[Epoch 48/50] [Batch 140/191] [D loss: 0.4439] [G loss: 0.8243]\n",
      "[Epoch 48/50] [Batch 160/191] [D loss: 0.3464] [G loss: 1.0116]\n",
      "[Epoch 48/50] [Batch 180/191] [D loss: 0.3325] [G loss: 1.1020]\n",
      "[Epoch 49/50] [Batch 0/191] [D loss: 0.3214] [G loss: 1.0211]\n",
      "[Epoch 49/50] [Batch 20/191] [D loss: 0.3196] [G loss: 1.1845]\n",
      "[Epoch 49/50] [Batch 40/191] [D loss: 0.3205] [G loss: 1.1236]\n",
      "[Epoch 49/50] [Batch 60/191] [D loss: 0.2970] [G loss: 1.1883]\n",
      "[Epoch 49/50] [Batch 80/191] [D loss: 0.3228] [G loss: 1.1997]\n",
      "[Epoch 49/50] [Batch 100/191] [D loss: 0.3092] [G loss: 1.2514]\n",
      "[Epoch 49/50] [Batch 120/191] [D loss: 0.3097] [G loss: 1.2126]\n",
      "[Epoch 49/50] [Batch 140/191] [D loss: 0.3074] [G loss: 1.2179]\n",
      "[Epoch 49/50] [Batch 160/191] [D loss: 0.3864] [G loss: 0.9872]\n",
      "[Epoch 49/50] [Batch 180/191] [D loss: 0.3158] [G loss: 1.1143]\n",
      "为每个类别生成 1000 个样本...\n",
      "为Number 4(Class 0)生成 971 个额外样本\n",
      "Number 3(Class 1) 已经有 6131 个样本，不需要增强\n",
      "数据增强完成！增强后的数据集保存在 ./augmented_mnist_binary\n",
      "最终数据集统计：\n",
      "- Number 4(Class 0): 971 个样本\n",
      "- Number 3(Class 1): 0 个样本\n",
      "在测试集上的总体准确率: 96.64%\n",
      "Number 4(Class 0)准确率: 93.99% (923/982)\n",
      "Number 3(Class 1)准确率: 99.21% (1002/1010)\n"
     ]
    }
   ],
   "source": [
    "# 示例用法\n",
    "def main():\n",
    "    # 设置参数\n",
    "    latent_dim = 100\n",
    "    batch_size = 64\n",
    "    imbalance_ratio = 0.005  # 少数类样本数量为多数类的10%\n",
    "    \n",
    "    # 创建BAGAN实例\n",
    "    bagan = BAGAN(\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        root='./data',\n",
    "        imbalance_ratio=imbalance_ratio,\n",
    "        num_classes=2  # 明确指定二分类\n",
    "    )\n",
    "    \n",
    "    # 预训练自动编码器\n",
    "    bagan.pretrain_autoencoder(epochs=30)\n",
    "    \n",
    "    # 训练BAGAN\n",
    "    #bagan.train(epochs=50, sample_interval=500)\n",
    "    bagan.train_gan_with_balanced_batches(epochs=50, sample_interval=500)\n",
    "    # 生成平衡数据集\n",
    "    bagan.generate_balanced_dataset(samples_per_class=1000)\n",
    "    \n",
    "    # 创建只包含数字3和4的MNIST测试集\n",
    "    mnist_test = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=bagan.transform,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    # 筛选出数字3和4，并重新映射标签：数字4->类别0，数字3->类别1\n",
    "    idx = (mnist_test.targets == 3) | (mnist_test.targets == 4)\n",
    "    mnist_test.data = mnist_test.data[idx]\n",
    "    mnist_test.targets = mnist_test.targets[idx]\n",
    "    # 重新映射标签\n",
    "    mnist_test.targets = (mnist_test.targets == 3).long()\n",
    "    \n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 评估模型\n",
    "    bagan.evaluate_model(test_loader)\n",
    "    \n",
    "    # 可视化二分类的生成结果\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(2):  # 只有2个类别\n",
    "            # 生成噪声和标签\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            label = torch.tensor([i], device=device)\n",
    "            \n",
    "            # 使用类别特定的统计信息\n",
    "            z = z * torch.sqrt(bagan.latent_vars[i]) + bagan.latent_means[i]\n",
    "            \n",
    "            # 生成图像\n",
    "            gen_img = bagan.generator(z, label)\n",
    "            \n",
    "            # 显示图像\n",
    "            img = gen_img[0].cpu().detach().numpy()\n",
    "            img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "            img = img.reshape(28, 28)\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f\"{class_name[i]}\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mnist_binary_bagan_samples.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 额外：为每个类别生成多个样本并展示\n",
    "    n_samples = 5\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(n_samples*2, 4))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for class_idx in range(2):\n",
    "            for j in range(n_samples):\n",
    "                # 生成噪声和标签\n",
    "                z = torch.randn(1, latent_dim).to(device)\n",
    "                label = torch.tensor([class_idx], device=device)\n",
    "                \n",
    "                # 使用类别特定的统计信息\n",
    "                z = z * torch.sqrt(bagan.latent_vars[class_idx]) + bagan.latent_means[class_idx]\n",
    "                \n",
    "                # 生成图像\n",
    "                gen_img = bagan.generator(z, label)\n",
    "                \n",
    "                # 显示图像\n",
    "                img = gen_img[0].cpu().detach().numpy()\n",
    "                img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                img = img.reshape(28, 28)\n",
    "                axes[class_idx, j].imshow(img, cmap='gray')\n",
    "                axes[class_idx, j].axis('off')\n",
    "                \n",
    "            # 为每一行添加类别标签\n",
    "            axes[class_idx, 0].set_ylabel(class_name[class_idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mnist_binary_bagan_multiple_samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
