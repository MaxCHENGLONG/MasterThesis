{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4.69M/9.91M [02:37<02:55, 29.7kB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 614\u001b[0m\n\u001b[1;32m    611\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 614\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 557\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    554\u001b[0m imbalance_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# 少数类样本数量为多数类的10%\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# 创建BAGAN实例\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m bagan \u001b[38;5;241m=\u001b[39m \u001b[43mBAGAN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimbalance_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimbalance_ratio\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# 预训练自动编码器\u001b[39;00m\n\u001b[1;32m    565\u001b[0m bagan\u001b[38;5;241m.\u001b[39mpretrain_autoencoder(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 224\u001b[0m, in \u001b[0;36mBAGAN.__init__\u001b[0;34m(self, latent_dim, batch_size, root, imbalance_ratio)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    219\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m    220\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.5\u001b[39m], [\u001b[38;5;241m0.5\u001b[39m])  \u001b[38;5;66;03m# MNIST是单通道，所以只需一个值\u001b[39;00m\n\u001b[1;32m    221\u001b[0m ])\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# 创建不平衡的MNIST数据集\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mImbalancedMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimbalance_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimbalance_ratio\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# 初始化网络\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder \u001b[38;5;241m=\u001b[39m Autoencoder(latent_dim)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m, in \u001b[0;36mImbalancedMNIST.__init__\u001b[0;34m(self, root, train, transform, download, imbalance_ratio)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, imbalance_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    创建一个不平衡的MNIST数据集\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    imbalance_ratio: 少数类相对于多数类的样本比例\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmnist \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# 创建不平衡数据集\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/site-packages/torchvision/datasets/mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/site-packages/torchvision/datasets/mnist.py:188\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/site-packages/torchvision/datasets/utils.py:391\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    389\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 391\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    394\u001b[0m extract_archive(archive, extract_root, remove_finished)\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/site-packages/torchvision/datasets/utils.py:130\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/site-packages/torchvision/datasets/utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/Thesis/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# 检查GPU可用性\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 创建不平衡的MNIST数据集\n",
    "class ImbalancedMNIST(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, download=True, imbalance_ratio=0.1):\n",
    "        \"\"\"\n",
    "        创建一个不平衡的MNIST数据集\n",
    "        imbalance_ratio: 少数类相对于多数类的样本比例\n",
    "        \"\"\"\n",
    "        self.mnist = datasets.MNIST(root=root, train=train, transform=transform, download=download)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # 创建不平衡数据集\n",
    "        self.indices = self._create_imbalanced_indices(imbalance_ratio)\n",
    "        \n",
    "    def _create_imbalanced_indices(self, imbalance_ratio):\n",
    "        # 获取每个类别的索引\n",
    "        class_indices = [[] for _ in range(self.num_classes)]\n",
    "        for idx, (_, label) in enumerate(self.mnist):\n",
    "            class_indices[label].append(idx)\n",
    "        \n",
    "        # 创建不平衡数据集索引\n",
    "        selected_indices = []\n",
    "        # 多数类(数字0-4)保持原样\n",
    "        for i in range(0, 5):\n",
    "            selected_indices.extend(class_indices[i])\n",
    "        \n",
    "        # 少数类(数字5-9)减少样本\n",
    "        for i in range(5, 10):\n",
    "            n_samples = int(len(class_indices[i]) * imbalance_ratio)\n",
    "            selected_indices.extend(class_indices[i][:n_samples])\n",
    "        \n",
    "        return selected_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.mnist[self.indices[idx]]\n",
    "\n",
    "# 定义生成器网络 - 适用于MNIST\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 嵌入层处理类别标签\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        \n",
    "        # 初始线性层\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, 128 * 7 * 7)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 嵌入标签\n",
    "        label_embedding = self.label_emb(labels)\n",
    "        # 将噪声和标签嵌入连接起来\n",
    "        x = torch.cat([noise, label_embedding], dim=1)\n",
    "        # 线性层\n",
    "        x = self.linear(x)\n",
    "        # 重塑为卷积特征图\n",
    "        x = x.view(x.shape[0], 128, 7, 7)\n",
    "        # 卷积层\n",
    "        img = self.conv_blocks(x)\n",
    "        return img\n",
    "\n",
    "# 定义判别器网络 - 适用于MNIST\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 特征提取器\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # 展平特征\n",
    "        self.flatten_size = 64 * 3 * 3\n",
    "        \n",
    "        # 真假判别器\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 类别分类器\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        # 提取特征\n",
    "        features = self.features(img)\n",
    "        # 展平特征\n",
    "        features = features.view(features.shape[0], -1)\n",
    "        # 真假判别\n",
    "        validity = self.adv_layer(features)\n",
    "        # 类别判别\n",
    "        label = self.aux_layer(features)\n",
    "        \n",
    "        return validity, label\n",
    "\n",
    "# 定义自动编码器网络 - 适用于MNIST\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28x28 -> 14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 14x14 -> 7x7\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 7x7 -> 7x7\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 将特征图展平并映射到潜在空间\n",
    "        self.fc = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        \n",
    "        # 解码器输入层\n",
    "        self.decoder_input = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        \n",
    "        # 解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),  # 7x7 -> 14x14\n",
    "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),  # 14x14 -> 28x28\n",
    "            nn.Conv2d(16, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def encode(self, img):\n",
    "        x = self.encoder(img)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        z = self.fc(x)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.shape[0], 64, 7, 7)\n",
    "        img = self.decoder(x)\n",
    "        return img\n",
    "    \n",
    "    def forward(self, img):\n",
    "        z = self.encode(img)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed\n",
    "\n",
    "# 定义BAGAN类\n",
    "class BAGAN:\n",
    "    def __init__(self, latent_dim=100, batch_size=64, root='./data', imbalance_ratio=0.1):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.imbalance_ratio = imbalance_ratio\n",
    "        self.num_classes = 10  # MNIST有10个类别\n",
    "        \n",
    "        # 数据转换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # MNIST是单通道，所以只需一个值\n",
    "        ])\n",
    "        \n",
    "        # 创建不平衡的MNIST数据集\n",
    "        self.dataset = ImbalancedMNIST(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            transform=self.transform,\n",
    "            download=True,\n",
    "            imbalance_ratio=imbalance_ratio\n",
    "        )\n",
    "        \n",
    "        # 初始化网络\n",
    "        self.autoencoder = Autoencoder(latent_dim).to(device)\n",
    "        self.generator = Generator(latent_dim, self.num_classes).to(device)\n",
    "        self.discriminator = Discriminator(self.num_classes).to(device)\n",
    "        \n",
    "        # 分析类别分布\n",
    "        self.class_counts = self._get_class_distribution()\n",
    "        print(f\"类别分布: {self.class_counts}\")\n",
    "        \n",
    "        # 计算类别权重以进行平衡采样\n",
    "        self.weights = self._compute_weights()\n",
    "        \n",
    "    def _get_class_distribution(self):\n",
    "        counts = Counter()\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            if hasattr(label, 'item'):\n",
    "                counts[label.item()] += 1\n",
    "            else:\n",
    "                counts[label] += 1\n",
    "        return counts\n",
    "    \n",
    "    def _compute_weights(self):\n",
    "        max_count = max(self.class_counts.values())\n",
    "        weights = []\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            label_idx = label.item() if torch.is_tensor(label) else label\n",
    "            count = self.class_counts[label_idx]\n",
    "            weight = max_count / count if count > 0 else 0\n",
    "            weights.append(weight)\n",
    "        return weights\n",
    "    \n",
    "    def _create_dataloaders(self):\n",
    "        # 为整个数据集创建加载器\n",
    "        dataloader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        # 为每个类别创建单独的加载器\n",
    "        class_loaders = {}\n",
    "        for class_idx in range(self.num_classes):\n",
    "            # 筛选该类别的样本\n",
    "            indices = [i for i, (_, y) in enumerate(self.dataset) if \n",
    "                      (y.item() if torch.is_tensor(y) else y) == class_idx]\n",
    "            if indices:  # 确保该类别有样本\n",
    "                class_subset = Subset(self.dataset, indices)\n",
    "                class_loaders[class_idx] = DataLoader(\n",
    "                    class_subset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4\n",
    "                )\n",
    "        \n",
    "        return dataloader, class_loaders\n",
    "    \n",
    "    def pretrain_autoencoder(self, epochs=50, lr=0.0002):\n",
    "        \"\"\"预训练自动编码器\"\"\"\n",
    "        print(\"预训练自动编码器...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        _, class_loaders = self._create_dataloaders()\n",
    "        \n",
    "        # 为自动编码器设置优化器\n",
    "        optimizer = optim.Adam(self.autoencoder.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 为每个类别存储潜在表示的均值和方差\n",
    "        self.latent_means = torch.zeros(self.num_classes, self.latent_dim).to(device)\n",
    "        self.latent_vars = torch.ones(self.num_classes, self.latent_dim).to(device)\n",
    "        \n",
    "        self.autoencoder.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            samples_count = 0\n",
    "            \n",
    "            # 每个类别的数据加载器\n",
    "            for class_idx, loader in class_loaders.items():\n",
    "                class_latent_vectors = []\n",
    "                \n",
    "                for i, (imgs, _) in enumerate(loader):\n",
    "                    imgs = imgs.to(device)\n",
    "                    \n",
    "                    # 重置梯度\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # 自动编码器前向传播\n",
    "                    latent = self.autoencoder.encode(imgs)\n",
    "                    reconstructed = self.autoencoder.decode(latent)\n",
    "                    \n",
    "                    # 记录潜在向量\n",
    "                    class_latent_vectors.append(latent.detach())\n",
    "                    \n",
    "                    # 计算损失\n",
    "                    loss = criterion(reconstructed, imgs)\n",
    "                    \n",
    "                    # 反向传播和优化\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item() * imgs.size(0)\n",
    "                    samples_count += imgs.size(0)\n",
    "                \n",
    "                # 计算该类别的潜在向量的均值和方差\n",
    "                if class_latent_vectors:\n",
    "                    class_latent = torch.cat(class_latent_vectors, dim=0)\n",
    "                    self.latent_means[class_idx] = class_latent.mean(dim=0)\n",
    "                    self.latent_vars[class_idx] = class_latent.var(dim=0)\n",
    "            \n",
    "            avg_loss = total_loss / samples_count if samples_count > 0 else 0\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Autoencoder Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # 将预训练的解码器权重初始化生成器对应层\n",
    "        print(\"将自动编码器知识转移到生成器...\")\n",
    "        self._init_generator_from_autoencoder()\n",
    "    \n",
    "    def _init_generator_from_autoencoder(self):\n",
    "        \"\"\"将自动编码器知识转移到生成器\"\"\"\n",
    "        # 设置嵌入层来表示潜在空间中的类别均值\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                self.generator.label_emb.weight.data[class_idx] = self.latent_means[class_idx]\n",
    "    \n",
    "    def train(self, epochs=200, lr=0.0002, b1=0.5, b2=0.999, sample_interval=200):\n",
    "        \"\"\"训练BAGAN\"\"\"\n",
    "        print(\"开始训练BAGAN...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        dataloader, _ = self._create_dataloaders()\n",
    "        \n",
    "        # 损失函数\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "        auxiliary_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 优化器\n",
    "        optimizer_G = optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "                batch_size = real_imgs.size(0)\n",
    "                \n",
    "                # 配置输入\n",
    "                real_imgs = real_imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 创建标签\n",
    "                valid = torch.ones(batch_size, 1).to(device)\n",
    "                fake = torch.zeros(batch_size, 1).to(device)\n",
    "                \n",
    "                # -----------------\n",
    "                #  训练生成器\n",
    "                # -----------------\n",
    "                \n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # 采样噪声和标签作为生成器输入\n",
    "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "                gen_labels = torch.randint(0, self.num_classes, (batch_size,)).to(device)\n",
    "                \n",
    "                # 为生成的噪声添加类别特定的统计信息\n",
    "                for idx in range(batch_size):\n",
    "                    class_idx = gen_labels[idx].item()\n",
    "                    z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成一批假图像\n",
    "                gen_imgs = self.generator(z, gen_labels)\n",
    "                \n",
    "                # 计算生成器的损失\n",
    "                validity, pred_label = self.discriminator(gen_imgs)\n",
    "                g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "                \n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                \n",
    "                # ---------------------\n",
    "                #  训练判别器\n",
    "                # ---------------------\n",
    "                \n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # 真实图像的损失\n",
    "                real_pred, real_aux = self.discriminator(real_imgs)\n",
    "                d_real_loss = 0.5 * (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels))\n",
    "                \n",
    "                # 生成图像的损失\n",
    "                fake_pred, fake_aux = self.discriminator(gen_imgs.detach())\n",
    "                d_fake_loss = 0.5 * (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels))\n",
    "                \n",
    "                # 总判别器损失\n",
    "                d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "                \n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # 打印训练进度\n",
    "                if i % 50 == 0:\n",
    "                    print(\n",
    "                        f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                        f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "                    )\n",
    "                \n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                if batches_done % sample_interval == 0:\n",
    "                    self.sample_images(batches_done)\n",
    "    \n",
    "    def sample_images(self, batches_done):\n",
    "        \"\"\"保存采样的图像\"\"\"\n",
    "        # 为每个类别生成样本\n",
    "        n_row, n_col = 2, 5  # 2行，每行5个类别\n",
    "        fig, axs = plt.subplots(n_row, n_col, figsize=(n_col * 2, n_row * 2))\n",
    "        \n",
    "        # 生成每个类别的样本\n",
    "        with torch.no_grad():\n",
    "            for i, class_idx in enumerate(range(self.num_classes)):\n",
    "                row, col = i // n_col, i % n_col\n",
    "                \n",
    "                # 生成该类别的噪声和标签\n",
    "                z = torch.randn(1, self.latent_dim).to(device)\n",
    "                label = torch.tensor([class_idx], device=device)\n",
    "                \n",
    "                # 为噪声添加类别特定的统计信息\n",
    "                z = z * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成图像\n",
    "                gen_img = self.generator(z, label)\n",
    "                \n",
    "                # 显示图像\n",
    "                img = gen_img[0].cpu().detach().numpy()\n",
    "                img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                img = img.reshape(28, 28)\n",
    "                axs[row, col].imshow(img, cmap='gray')\n",
    "                axs[row, col].set_title(f\"Digit {class_idx}\")\n",
    "                axs[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 创建保存目录\n",
    "        save_dir = \"bagan_mnist_samples\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 保存图像\n",
    "        plt.savefig(f\"{save_dir}/sample_{batches_done}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_balanced_dataset(self, samples_per_class=1000, output_dir=\"./augmented_mnist\"):\n",
    "        \"\"\"生成平衡数据集\"\"\"\n",
    "        print(f\"为每个类别生成 {samples_per_class} 个样本...\")\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for class_idx in range(self.num_classes):\n",
    "            os.makedirs(os.path.join(output_dir, str(class_idx)), exist_ok=True)\n",
    "        \n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                # 计算需要生成的额外样本数\n",
    "                real_samples = self.class_counts.get(class_idx, 0)\n",
    "                if real_samples >= samples_per_class:\n",
    "                    print(f\"类别 {class_idx} 已经有 {real_samples} 个样本，不需要增强\")\n",
    "                    continue\n",
    "                \n",
    "                to_generate = samples_per_class - real_samples\n",
    "                print(f\"为类别 {class_idx} 生成 {to_generate} 个额外样本\")\n",
    "                \n",
    "                # 批次生成\n",
    "                batch_size = min(self.batch_size, to_generate)\n",
    "                num_batches = to_generate // batch_size + (1 if to_generate % batch_size != 0 else 0)\n",
    "                \n",
    "                for batch in range(num_batches):\n",
    "                    current_batch_size = min(batch_size, to_generate - batch * batch_size)\n",
    "                    \n",
    "                    # 生成噪声和标签\n",
    "                    z = torch.randn(current_batch_size, self.latent_dim).to(device)\n",
    "                    labels = torch.full((current_batch_size,), class_idx, dtype=torch.long).to(device)\n",
    "                    \n",
    "                    # 为噪声添加类别特定的统计信息\n",
    "                    for idx in range(current_batch_size):\n",
    "                        z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                    \n",
    "                    # 生成图像\n",
    "                    gen_imgs = self.generator(z, labels)\n",
    "                    \n",
    "                    # 保存生成的图像\n",
    "                    for idx, img in enumerate(gen_imgs):\n",
    "                        img_idx = batch * batch_size + idx\n",
    "                        img = img.cpu().detach().numpy()\n",
    "                        img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                        img = img.reshape(28, 28) * 255\n",
    "                        img = img.astype(np.uint8)\n",
    "                        img = Image.fromarray(img, mode='L')  # 灰度图像\n",
    "                        img.save(os.path.join(output_dir, str(class_idx), f\"gen_{img_idx}.png\"))\n",
    "        \n",
    "        print(f\"数据增强完成！增强后的数据集保存在 {output_dir}\")\n",
    "\n",
    "    def evaluate_model(self, test_loader):\n",
    "        \"\"\"评估模型在测试集上的性能\"\"\"\n",
    "        self.discriminator.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                validity, pred_labels = self.discriminator(imgs)\n",
    "                _, predicted = torch.max(pred_labels.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"在测试集上的准确率: {accuracy:.2f}%\")\n",
    "\n",
    "# 示例用法\n",
    "def main():\n",
    "    # 设置参数\n",
    "    latent_dim = 100\n",
    "    batch_size = 64\n",
    "    imbalance_ratio = 0.1  # 少数类样本数量为多数类的10%\n",
    "    \n",
    "    # 创建BAGAN实例\n",
    "    bagan = BAGAN(\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        root='./data',\n",
    "        imbalance_ratio=imbalance_ratio\n",
    "    )\n",
    "    \n",
    "    # 预训练自动编码器\n",
    "    bagan.pretrain_autoencoder(epochs=30)\n",
    "    \n",
    "    # 训练BAGAN\n",
    "    bagan.train(epochs=100, sample_interval=500)\n",
    "    \n",
    "    # 生成平衡数据集\n",
    "    bagan.generate_balanced_dataset(samples_per_class=1000)\n",
    "    \n",
    "    # 创建MNIST测试集\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=bagan.transform,\n",
    "        download=True\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 评估模型\n",
    "    bagan.evaluate_model(test_loader)\n",
    "    \n",
    "    # 可视化不同类别的生成结果\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            # 生成噪声和标签\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            label = torch.tensor([i], device=device)\n",
    "            \n",
    "            # 使用类别特定的统计信息\n",
    "            z = z * torch.sqrt(bagan.latent_vars[i]) + bagan.latent_means[i]\n",
    "            \n",
    "            # 生成图像\n",
    "            gen_img = bagan.generator(z, label)\n",
    "            \n",
    "            # 显示图像\n",
    "            img = gen_img[0].cpu().numpy()\n",
    "            img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "            img = img.reshape(28, 28)\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f\"Digit {i}\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mnist_bagan_samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
