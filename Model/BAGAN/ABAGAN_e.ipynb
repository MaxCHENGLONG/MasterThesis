{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# 设置随机种子以确保结果可重现\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# 检查GPU可用性\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建不平衡的MNIST数据集\n",
    "class ImbalancedMNIST(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, download=True, imbalance_ratio=0.005, num_classes = 2):\n",
    "        \"\"\"\n",
    "        创建一个只包含数字3和4的不平衡MNIST数据集\n",
    "        数字3映射为标签1,数字4映射为标签0\n",
    "        imbalance_ratio: 少数类相对于多数类的样本比例\n",
    "        \"\"\"\n",
    "        self.mnist = datasets.MNIST(root=root, train=train, transform=transform, download=download)\n",
    "        self.num_classes = 2  # 只有两个类别: 0(数字4)和 1 (数字3)\n",
    "        \n",
    "        # 创建不平衡数据集\n",
    "        self.indices = self._create_imbalanced_indices(imbalance_ratio)\n",
    "        \n",
    "    def _create_imbalanced_indices(self, imbalance_ratio):\n",
    "        # 获取数字3和4的索引\n",
    "        class_3_indices = []\n",
    "        class_4_indices = []\n",
    "        \n",
    "        for idx, (_, label) in enumerate(self.mnist):\n",
    "            if label == 3:\n",
    "                class_3_indices.append(idx)\n",
    "            elif label == 4:\n",
    "                class_4_indices.append(idx)\n",
    "        \n",
    "        # 创建不平衡数据集索引\n",
    "        selected_indices = []\n",
    "        \n",
    "        # 多数类(数字3-> 标签1)保持原样\n",
    "        selected_indices.extend(class_3_indices)\n",
    "        \n",
    "        # 少数类(数字4 -> 标签0)减少样本\n",
    "        n_samples = int(len(class_4_indices) * imbalance_ratio)\n",
    "        selected_indices.extend(class_4_indices[:n_samples])\n",
    "        \n",
    "        return selected_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.mnist[self.indices[idx]]\n",
    "        \n",
    "        # 将原始标签映射为新标签: 3 -> 1, 4 -> 0\n",
    "        if label == 3:\n",
    "            new_label = 1\n",
    "        elif label == 4:\n",
    "            new_label = 0\n",
    "        else:\n",
    "            raise ValueError(f\"意外的标签: {label}\")\n",
    "        \n",
    "        return img, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器网络 - 适用于MNIST\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 嵌入层处理类别标签\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        \n",
    "        # 初始线性层\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, 128 * 7 * 7)\n",
    "        )\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 嵌入标签\n",
    "        label_embedding = self.label_emb(labels)\n",
    "        # 将噪声和标签嵌入连接起来\n",
    "        x = torch.cat([noise, label_embedding], dim=1)\n",
    "        # 线性层\n",
    "        x = self.linear(x)\n",
    "        # 重塑为卷积特征图\n",
    "        x = x.view(x.shape[0], 128, 7, 7)\n",
    "        # 卷积层\n",
    "        img = self.conv_blocks(x)\n",
    "        return img\n",
    "\n",
    "# 定义判别器网络 - 适用于MNIST\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 特征提取器\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # 正确计算展平后的尺寸\n",
    "        self.flatten_size = 64 * 4 * 4  # 修改前为 64*3*3\n",
    "        \n",
    "        # 真假判别器\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 类别分类器\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        features = self.features(img)\n",
    "        features = features.view(features.shape[0], -1)\n",
    "        validity = self.adv_layer(features)\n",
    "        label = self.aux_layer(features)\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义带有注意力机制的自动编码器网络 - 适用于MNIST\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        \n",
    "        # 平均池化特征\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        # 最大池化特征\n",
    "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
    "        \n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out).view(b, c, 1, 1) * x\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), '空间注意力核大小必须为3或7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        \n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        \n",
    "        # 沿着通道维度计算平均值和最大值\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        \n",
    "        # 拼接特征\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        \n",
    "        # 应用卷积和激活函数\n",
    "        out = self.conv(x_cat)\n",
    "        \n",
    "        return self.sigmoid(out) * x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28x28 -> 14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca1 = ChannelAttention(16)\n",
    "        self.sa1 = SpatialAttention()\n",
    "        \n",
    "        self.encoder_block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 14x14 -> 7x7\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca2 = ChannelAttention(32)\n",
    "        self.sa2 = SpatialAttention()\n",
    "        \n",
    "        self.encoder_block3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),  # 7x7 -> 7x7\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca3 = ChannelAttention(64)\n",
    "        self.sa3 = SpatialAttention()\n",
    "        \n",
    "        # 将特征图展平并映射到潜在空间\n",
    "        self.fc = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        \n",
    "        # 解码器输入层\n",
    "        self.decoder_input = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        \n",
    "        # 解码器\n",
    "        self.decoder_block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca4 = ChannelAttention(32)\n",
    "        self.sa4 = SpatialAttention()\n",
    "        \n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)  # 7x7 -> 14x14\n",
    "        \n",
    "        self.decoder_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.ca5 = ChannelAttention(16)\n",
    "        self.sa5 = SpatialAttention()\n",
    "        \n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)  # 14x14 -> 28x28\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(16, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def encode(self, img):\n",
    "        # 编码器前向传播，应用注意力机制\n",
    "        x = self.encoder_block1(img)\n",
    "        x = self.ca1(x)\n",
    "        x = self.sa1(x)\n",
    "        \n",
    "        x = self.encoder_block2(x)\n",
    "        x = self.ca2(x)\n",
    "        x = self.sa2(x)\n",
    "        \n",
    "        x = self.encoder_block3(x)\n",
    "        x = self.ca3(x)\n",
    "        x = self.sa3(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        z = self.fc(x)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # 解码器前向传播，应用注意力机制\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.shape[0], 64, 7, 7)\n",
    "        \n",
    "        x = self.decoder_block1(x)\n",
    "        x = self.ca4(x)\n",
    "        x = self.sa4(x)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        \n",
    "        x = self.decoder_block2(x)\n",
    "        x = self.ca5(x)\n",
    "        x = self.sa5(x)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        img = self.output_layer(x)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def forward(self, img):\n",
    "        z = self.encode(img)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义BAGAN类\n",
    "class BAGAN:\n",
    "    def __init__(self, latent_dim=100, batch_size=64, root='./data', imbalance_ratio=0.005, num_classes=2):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.imbalance_ratio = imbalance_ratio\n",
    "        self.num_classes = 2  # 修改为2个类别：0(原数字4)和1(原数字3)\n",
    "        \n",
    "        # 数据转换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])  # MNIST是单通道，所以只需一个值\n",
    "        ])\n",
    "        \n",
    "        # 创建不平衡的MNIST数据集（只包含数字3和4）\n",
    "        self.dataset = ImbalancedMNIST(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            transform=self.transform,\n",
    "            download=True,\n",
    "            imbalance_ratio=imbalance_ratio\n",
    "            num_classes= 2\n",
    "        )\n",
    "        \n",
    "        # 初始化网络\n",
    "        self.autoencoder = Autoencoder(latent_dim).to(device)\n",
    "        self.generator = Generator(latent_dim, self.num_classes).to(device)\n",
    "        self.discriminator = Discriminator(self.num_classes).to(device)\n",
    "        \n",
    "        # 分析类别分布\n",
    "        self.class_counts = self._get_class_distribution()\n",
    "        print(f\"Class Distribution: {self.class_counts}\")\n",
    "        \n",
    "        # 计算类别权重以进行平衡采样\n",
    "        self.weights = self._compute_weights()\n",
    "        \n",
    "    def _get_class_distribution(self):\n",
    "        counts = Counter()\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            if hasattr(label, 'item'):\n",
    "                counts[label.item()] += 1\n",
    "            else:\n",
    "                counts[label] += 1\n",
    "        return counts\n",
    "    \n",
    "    def _compute_weights(self):\n",
    "        max_count = max(self.class_counts.values())\n",
    "        weights = []\n",
    "        for _, label in self.dataset:\n",
    "            # 检查label是张量还是整数\n",
    "            label_idx = label.item() if torch.is_tensor(label) else label\n",
    "            count = self.class_counts[label_idx]\n",
    "            weight = max_count / count if count > 0 else 0\n",
    "            weights.append(weight)\n",
    "        return weights\n",
    "    \n",
    "    def _create_dataloaders(self):\n",
    "        # 为整个数据集创建加载器\n",
    "        dataloader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        # 为每个类别创建单独的加载器\n",
    "        class_loaders = {}\n",
    "        for class_idx in range(self.num_classes):\n",
    "            # 筛选该类别的样本\n",
    "            indices = [i for i, (_, y) in enumerate(self.dataset) if \n",
    "                      (y.item() if torch.is_tensor(y) else y) == class_idx]\n",
    "            if indices:  # 确保该类别有样本\n",
    "                class_subset = Subset(self.dataset, indices)\n",
    "                class_loaders[class_idx] = DataLoader(\n",
    "                    class_subset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4\n",
    "                )\n",
    "        \n",
    "        return dataloader, class_loaders\n",
    "    \n",
    "    def pretrain_autoencoder(self, epochs=50, lr=0.0002):\n",
    "        \"\"\"预训练自动编码器\"\"\"\n",
    "        print(\"预训练自动编码器...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        _, class_loaders = self._create_dataloaders()\n",
    "        \n",
    "        # 为自动编码器设置优化器\n",
    "        optimizer = optim.Adam(self.autoencoder.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # 为每个类别存储潜在表示的均值和方差\n",
    "        self.latent_means = torch.zeros(self.num_classes, self.latent_dim).to(device)\n",
    "        self.latent_vars = torch.ones(self.num_classes, self.latent_dim).to(device)\n",
    "        \n",
    "        self.autoencoder.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            samples_count = 0\n",
    "            \n",
    "            # 每个类别的数据加载器\n",
    "            for class_idx, loader in class_loaders.items():\n",
    "                class_latent_vectors = []\n",
    "                \n",
    "                for i, (imgs, _) in enumerate(loader):\n",
    "                    imgs = imgs.to(device)\n",
    "                    \n",
    "                    # 重置梯度\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # 自动编码器前向传播\n",
    "                    latent = self.autoencoder.encode(imgs)\n",
    "                    reconstructed = self.autoencoder.decode(latent)\n",
    "                    \n",
    "                    # 记录潜在向量\n",
    "                    class_latent_vectors.append(latent.detach())\n",
    "                    \n",
    "                    # 计算损失\n",
    "                    loss = criterion(reconstructed, imgs)\n",
    "                    \n",
    "                    # 反向传播和优化\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item() * imgs.size(0)\n",
    "                    samples_count += imgs.size(0)\n",
    "                \n",
    "                # 计算该类别的潜在向量的均值和方差\n",
    "                if class_latent_vectors:\n",
    "                    class_latent = torch.cat(class_latent_vectors, dim=0)\n",
    "                    self.latent_means[class_idx] = class_latent.mean(dim=0)\n",
    "                    self.latent_vars[class_idx] = class_latent.var(dim=0)\n",
    "            \n",
    "            avg_loss = total_loss / samples_count if samples_count > 0 else 0\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Autoencoder Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # 将预训练的解码器权重初始化生成器对应层\n",
    "        print(\"将自动编码器知识转移到生成器...\")\n",
    "        self._init_generator_from_autoencoder()\n",
    "    \n",
    "    def _init_generator_from_autoencoder(self):\n",
    "        \"\"\"将自动编码器知识转移到生成器\"\"\"\n",
    "        # 设置嵌入层来表示潜在空间中的类别均值\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                self.generator.label_emb.weight.data[class_idx] = self.latent_means[class_idx]\n",
    "    \n",
    "    def train(self, epochs=200, lr=0.0002, b1=0.5, b2=0.999, sample_interval=200):\n",
    "        \"\"\"训练BAGAN\"\"\"\n",
    "        print(\"开始训练BAGAN...\")\n",
    "        \n",
    "        # 创建数据加载器\n",
    "        dataloader, _ = self._create_dataloaders()\n",
    "        \n",
    "        # 损失函数\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "        auxiliary_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 优化器\n",
    "        optimizer_G = optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "                batch_size = real_imgs.size(0)\n",
    "                \n",
    "                # 配置输入\n",
    "                real_imgs = real_imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 创建标签\n",
    "                valid = torch.ones(batch_size, 1).to(device)\n",
    "                fake = torch.zeros(batch_size, 1).to(device)\n",
    "                \n",
    "                # -----------------\n",
    "                #  训练生成器\n",
    "                # -----------------\n",
    "                \n",
    "                optimizer_G.zero_grad()\n",
    "                \n",
    "                # 采样噪声和标签作为生成器输入\n",
    "                z = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "                gen_labels = torch.randint(0, self.num_classes, (batch_size,)).to(device)\n",
    "                \n",
    "                # 为生成的噪声添加类别特定的统计信息\n",
    "                for idx in range(batch_size):\n",
    "                    class_idx = gen_labels[idx].item()\n",
    "                    z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成一批假图像\n",
    "                gen_imgs = self.generator(z, gen_labels)\n",
    "                \n",
    "                # 计算生成器的损失\n",
    "                validity, pred_label = self.discriminator(gen_imgs)\n",
    "                g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "                \n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                \n",
    "                # ---------------------\n",
    "                #  训练判别器\n",
    "                # ---------------------\n",
    "                \n",
    "                optimizer_D.zero_grad()\n",
    "                \n",
    "                # 真实图像的损失\n",
    "                real_pred, real_aux = self.discriminator(real_imgs)\n",
    "                d_real_loss = 0.5 * (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels))\n",
    "                \n",
    "                # 生成图像的损失\n",
    "                fake_pred, fake_aux = self.discriminator(gen_imgs.detach())\n",
    "                d_fake_loss = 0.5 * (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels))\n",
    "                \n",
    "                # 总判别器损失\n",
    "                d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "                \n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # 打印训练进度\n",
    "                if i % 50 == 0:\n",
    "                    print(\n",
    "                        f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
    "                        f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\"\n",
    "                    )\n",
    "                \n",
    "                batches_done = epoch * len(dataloader) + i\n",
    "                if batches_done % sample_interval == 0:\n",
    "                    self.sample_images(batches_done)\n",
    "    \n",
    "    def sample_images(self, batches_done):\n",
    "        \"\"\"保存采样的图像\"\"\"\n",
    "        # 为每个类别生成样本\n",
    "        n_row, n_col = 1, 2  # 1行，2个类别\n",
    "        fig, axs = plt.subplots(n_row, n_col, figsize=(n_col * 2, n_row * 2))\n",
    "        \n",
    "        # 生成每个类别的样本\n",
    "        with torch.no_grad():\n",
    "            for i, class_idx in enumerate(range(self.num_classes)):\n",
    "                # 生成该类别的噪声和标签\n",
    "                z = torch.randn(1, self.latent_dim).to(device)\n",
    "                label = torch.tensor([class_idx], device=device)\n",
    "                \n",
    "                # 为噪声添加类别特定的统计信息\n",
    "                z = z * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                \n",
    "                # 生成图像\n",
    "                gen_img = self.generator(z, label)\n",
    "                \n",
    "                # 显示图像\n",
    "                img = gen_img[0].cpu().detach().numpy()\n",
    "                img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                img = img.reshape(28, 28)\n",
    "                \n",
    "                # 原始类别映射\n",
    "                if class_idx == 0:\n",
    "                    original_digit = \"4\"\n",
    "                else:\n",
    "                    original_digit = \"3\"\n",
    "                #original_digit = \"4\" if class_idx == 0 else \"3\"\n",
    "                axs[i].imshow(img, cmap='gray')\n",
    "                axs[i].set_title(f\"Class {class_idx} (Original Digit {original_digit})\")\n",
    "                axs[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 创建保存目录\n",
    "        save_dir = \"bagan_mnist_binary_samples\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 保存图像\n",
    "        plt.savefig(f\"{save_dir}/sample_{batches_done}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_balanced_dataset(self, samples_per_class=1000, output_dir=\"./augmented_mnist_binary\"):\n",
    "        \"\"\"生成平衡数据集 - 针对二分类场景(数字3和4)\"\"\"\n",
    "        print(f\"为每个类别生成 {samples_per_class} 个样本...\")\n",
    "        \n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for class_idx in range(self.num_classes):  # 应该只有2个类别\n",
    "            os.makedirs(os.path.join(output_dir, str(class_idx)), exist_ok=True)\n",
    "        \n",
    "        # 类别名称映射（用于更清晰的输出信息）\n",
    "        class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "        \n",
    "        # 确认是二分类模式\n",
    "        if self.num_classes != 2:\n",
    "            print(f\"警告: 当前设置为{self.num_classes}个类别,而不是预期的2个类别\")\n",
    "        \n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            for class_idx in range(self.num_classes):\n",
    "                if class_idx >= 2:  # 确保只处理0和1两个类别\n",
    "                    print(f\"跳过类别 {class_idx}，因为当前是二分类模式\")\n",
    "                    continue\n",
    "                    \n",
    "                # 计算需要生成的额外样本数\n",
    "                real_samples = self.class_counts.get(class_idx, 0)\n",
    "                if real_samples >= samples_per_class:\n",
    "                    print(f\"{class_name[class_idx]} 已经有 {real_samples} 个样本，不需要增强\")\n",
    "                    continue\n",
    "                \n",
    "                to_generate = samples_per_class - real_samples\n",
    "                print(f\"为{class_name[class_idx]}生成 {to_generate} 个额外样本\")\n",
    "                \n",
    "                # 批次生成\n",
    "                batch_size = min(self.batch_size, to_generate)\n",
    "                num_batches = to_generate // batch_size + (1 if to_generate % batch_size != 0 else 0)\n",
    "                \n",
    "                for batch in range(num_batches):\n",
    "                    current_batch_size = min(batch_size, to_generate - batch * batch_size)\n",
    "                    \n",
    "                    # 生成噪声和标签\n",
    "                    z = torch.randn(current_batch_size, self.latent_dim).to(device)\n",
    "                    labels = torch.full((current_batch_size,), class_idx, dtype=torch.long).to(device)\n",
    "                    \n",
    "                    # 为噪声添加类别特定的统计信息\n",
    "                    for idx in range(current_batch_size):\n",
    "                        z[idx] = z[idx] * torch.sqrt(self.latent_vars[class_idx]) + self.latent_means[class_idx]\n",
    "                    \n",
    "                    # 生成图像\n",
    "                    gen_imgs = self.generator(z, labels)\n",
    "                    \n",
    "                    # 保存生成的图像\n",
    "                    for idx, img in enumerate(gen_imgs):\n",
    "                        img_idx = batch * batch_size + idx\n",
    "                        img = img.cpu().detach().numpy()\n",
    "                        img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                        img = img.reshape(28, 28) * 255\n",
    "                        img = img.astype(np.uint8)\n",
    "                        img = Image.fromarray(img, mode='L')  # 灰度图像\n",
    "                        img.save(os.path.join(output_dir, str(class_idx), f\"gen_{img_idx}.png\"))\n",
    "        \n",
    "        # 统计生成后的数据集大小\n",
    "        total_samples = {0: 0, 1: 0}\n",
    "        for class_idx in range(2):  # 只计算二分类\n",
    "            class_dir = os.path.join(output_dir, str(class_idx))\n",
    "            if os.path.exists(class_dir):\n",
    "                files = [f for f in os.listdir(class_dir) if f.endswith('.png')]\n",
    "                total_samples[class_idx] = len(files)\n",
    "        \n",
    "        print(f\"数据增强完成！增强后的数据集保存在 {output_dir}\")\n",
    "        print(f\"最终数据集统计：\")\n",
    "        print(f\"- {class_name[0]}: {total_samples[0]} 个样本\")\n",
    "        print(f\"- {class_name[1]}: {total_samples[1]} 个样本\")\n",
    "\n",
    "    def evaluate_model(self, test_loader):\n",
    "        \"\"\"评估模型在测试集上的性能\"\"\"\n",
    "        self.discriminator.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "        class_correct = {0: 0, 1: 0}\n",
    "        class_total = {0: 0, 1: 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                validity, pred_labels = self.discriminator(imgs)\n",
    "                _, predicted = torch.max(pred_labels.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # 计算每个类别的准确率\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    if predicted[i] == label:\n",
    "                        class_correct[label] += 1\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"在测试集上的总体准确率: {accuracy:.2f}%\")\n",
    "        \n",
    "        # 打印每个类别的准确率\n",
    "        for class_idx in range(self.num_classes):\n",
    "            if class_total[class_idx] > 0:\n",
    "                class_acc = 100 * class_correct[class_idx] / class_total[class_idx]\n",
    "                print(f\"{class_name[class_idx]}准确率: {class_acc:.2f}% ({class_correct[class_idx]}/{class_total[class_idx]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例用法\n",
    "def main():\n",
    "    # 设置参数\n",
    "    latent_dim = 100\n",
    "    batch_size = 64\n",
    "    imbalance_ratio = 0.005  # 少数类样本数量为多数类的10%\n",
    "    \n",
    "    # 创建BAGAN实例\n",
    "    bagan = BAGAN(\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        root='./data',\n",
    "        imbalance_ratio=imbalance_ratio,\n",
    "        num_classes=2  # 明确指定二分类\n",
    "    )\n",
    "    \n",
    "    # 预训练自动编码器\n",
    "    bagan.pretrain_autoencoder(epochs=30)\n",
    "    \n",
    "    # 训练BAGAN\n",
    "    bagan.train(epochs=50, sample_interval=500)\n",
    "    \n",
    "    # 生成平衡数据集\n",
    "    bagan.generate_balanced_dataset(samples_per_class=1000)\n",
    "    \n",
    "    # 创建只包含数字3和4的MNIST测试集\n",
    "    mnist_test = datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=bagan.transform,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    # 筛选出数字3和4，并重新映射标签：数字4->类别0，数字3->类别1\n",
    "    idx = (mnist_test.targets == 3) | (mnist_test.targets == 4)\n",
    "    mnist_test.data = mnist_test.data[idx]\n",
    "    mnist_test.targets = mnist_test.targets[idx]\n",
    "    # 重新映射标签\n",
    "    mnist_test.targets = (mnist_test.targets == 3).long()\n",
    "    \n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 评估模型\n",
    "    bagan.evaluate_model(test_loader)\n",
    "    \n",
    "    # 可视化二分类的生成结果\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    \n",
    "    class_name = {0: \"Number 4(Class 0)\", 1: \"Number 3(Class 1)\"}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(2):  # 只有2个类别\n",
    "            # 生成噪声和标签\n",
    "            z = torch.randn(1, latent_dim).to(device)\n",
    "            label = torch.tensor([i], device=device)\n",
    "            \n",
    "            # 使用类别特定的统计信息\n",
    "            z = z * torch.sqrt(bagan.latent_vars[i]) + bagan.latent_means[i]\n",
    "            \n",
    "            # 生成图像\n",
    "            gen_img = bagan.generator(z, label)\n",
    "            \n",
    "            # 显示图像\n",
    "            img = gen_img[0].cpu().detach().numpy()\n",
    "            img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "            img = img.reshape(28, 28)\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f\"{class_name[i]}\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mnist_binary_bagan_samples.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 额外：为每个类别生成多个样本并展示\n",
    "    n_samples = 5\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(n_samples*2, 4))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for class_idx in range(2):\n",
    "            for j in range(n_samples):\n",
    "                # 生成噪声和标签\n",
    "                z = torch.randn(1, latent_dim).to(device)\n",
    "                label = torch.tensor([class_idx], device=device)\n",
    "                \n",
    "                # 使用类别特定的统计信息\n",
    "                z = z * torch.sqrt(bagan.latent_vars[class_idx]) + bagan.latent_means[class_idx]\n",
    "                \n",
    "                # 生成图像\n",
    "                gen_img = bagan.generator(z, label)\n",
    "                \n",
    "                # 显示图像\n",
    "                img = gen_img[0].cpu().detach().numpy()\n",
    "                img = (img + 1) / 2  # 从[-1, 1]转换到[0, 1]\n",
    "                img = img.reshape(28, 28)\n",
    "                axes[class_idx, j].imshow(img, cmap='gray')\n",
    "                axes[class_idx, j].axis('off')\n",
    "                \n",
    "            # 为每一行添加类别标签\n",
    "            axes[class_idx, 0].set_ylabel(class_name[class_idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mnist_binary_bagan_multiple_samples.png\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
