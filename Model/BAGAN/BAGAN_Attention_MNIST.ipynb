{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% --------------------------------------- 固定随机种子 -----------------------------------------------------------------\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 数据准备 ---------------------------------------------------------------\n",
    "def change_image_shape(images):\n",
    "    \"\"\"调整图像形状以确保正确的格式\"\"\"\n",
    "    shape_tuple = images.shape  # 获取图像数组的形状\n",
    "    if len(shape_tuple) == 3:  # 如果形状的维度为3（例如：样本数，高度，宽度）\n",
    "        images = images.reshape(-1, 1, shape_tuple[-1], shape_tuple[-1])  # 重塑为四维：样本数，通道数(1)，高度，宽度\n",
    "    elif shape_tuple == 4 and shape_tuple[-1] > 3:  # 如果是四维且最后一个维度大于3（不是RGB通道）\n",
    "        images = images.reshape(-1, shape_tuple[1], shape_tuple[-1], shape_tuple[-1])  # 重塑为四维：样本数，通道数，高度，宽度\n",
    "    return images  # 返回调整后的图像数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "Test dataset\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载MNIST数据集\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 创建数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "fashion_mnist = MNIST(root = '/Users/max/MasterThesisData/MNIST/', train=True, download=True, transform=transform)\n",
    "test_fashion_mnist = MNIST(root = '/Users/max/MasterThesisData/MNIST/', train=False, download=True, transform=transform)\n",
    "images = fashion_mnist.data.numpy()\n",
    "labels = fashion_mnist.targets.numpy()\n",
    "test_images = test_fashion_mnist.data.numpy()\n",
    "test_labels = test_fashion_mnist.targets.numpy()\n",
    "# 转换图像形状\n",
    "images = images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "print(\"Train dataset\")\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(\"Test dataset\")\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Imbalance data shape: (6161, 28, 28, 1) (6161,)\n",
      "Train - Imbalance data distribution: (array([0, 1]), array([  30, 6131]))\n",
      "Test - Imbalance data shape: (1992, 28, 28, 1) (1992,)\n",
      "Test - Imbalance data distribution: (array([0, 1]), array([ 982, 1010]))\n"
     ]
    }
   ],
   "source": [
    "# 选择类别为3和4的样本\n",
    "images_3 = images[labels == 3]\n",
    "images_4 = images[labels == 4]\n",
    "# 将类别4的样本数减少到类别3样本数的0.5%\n",
    "num_3 = images_3.shape[0]\n",
    "num_4 = int(num_3 * 0.005)  # 0.5%\n",
    "images_4 = images_4[:num_4]\n",
    "# 构造新的标签数组\n",
    "labels_3 = np.full((images_3.shape[0],), 3)\n",
    "labels_4 = np.full((images_4.shape[0],), 4)\n",
    "# 合并样本和标签\n",
    "images_new = np.vstack([images_3, images_4])\n",
    "labels_new = np.concatenate([labels_3, labels_4])\n",
    "imbalance_images = images_new\n",
    "imbalance_labels = labels_new\n",
    "\n",
    "images = imbalance_images # 3和4类别的样本\n",
    "labels = imbalance_labels # 3和4类别的样本\n",
    "#  3 -> 1 4 -> 0\n",
    "labels[labels == 3] = 1\n",
    "labels[labels == 4] = 0\n",
    "print(\"Train - Imbalance data shape:\", images.shape, labels.shape)\n",
    "print(\"Train - Imbalance data distribution:\", np.unique(labels, return_counts=True))\n",
    "# 选择类别为3和4的样本\n",
    "test_images_3 = test_images[test_labels == 3]\n",
    "test_images_4 = test_images[test_labels == 4]\n",
    "# 构造新的标签数组\n",
    "test_labels_3 = np.full((test_images_3.shape[0],), 3)\n",
    "test_labels_4 = np.full((test_images_4.shape[0],), 4)\n",
    "# 合并样本和标签\n",
    "test_images_new = np.vstack([test_images_3, test_images_4])\n",
    "test_labels_new = np.concatenate([test_labels_3, test_labels_4])\n",
    "test_imbalance_images = test_images_new\n",
    "test_imbalance_labels = test_labels_new\n",
    "\n",
    "test_images = test_imbalance_images # 3和4类别的样本\n",
    "test_labels = test_imbalance_labels # 3和4类别的样本\n",
    "\n",
    "#  3 -> 1 4 -> 0\n",
    "test_labels[test_labels == 3] = 1\n",
    "test_labels[test_labels == 4] = 0\n",
    "\n",
    "print(\"Test - Imbalance data shape:\", test_images.shape, test_labels.shape)\n",
    "print(\"Test - Imbalance data distribution:\", np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Imbalance data shape: (6161, 64, 64, 1) (6161,)\n",
      "Train - Imbalance data distribution: (array([0, 1]), array([  30, 6131]))\n",
      "Test - Imbalance data shape: (1992, 64, 64, 1) (1992,)\n",
      "Test - Imbalance data distribution: (array([0, 1]), array([ 982, 1010]))\n"
     ]
    }
   ],
   "source": [
    "# 提高分辨率能够获得更好的信息\n",
    "# 设置通道数\n",
    "channel = images.shape[-1]\n",
    "\n",
    "# 将图像调整为 64 x 64 x channel\n",
    "real = np.ndarray(shape=(images.shape[0], 64, 64, channel))\n",
    "for i in range(images.shape[0]):\n",
    "    real[i] = cv2.resize(images[i], (64, 64)).reshape((64, 64, channel))\n",
    "\n",
    "\n",
    "test_channel = test_images.shape[-1]\n",
    "test_real = np.ndarray(shape=(test_images.shape[0], 64, 64, test_channel))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_real[i] = cv2.resize(test_images[i], (64, 64)).reshape((64, 64, test_channel))\n",
    "\n",
    "\n",
    "print(\"Train - Imbalance data shape:\", real.shape, labels.shape)\n",
    "print(\"Train - Imbalance data distribution:\", np.unique(labels, return_counts=True))\n",
    "print(\"Test - Imbalance data shape:\", test_real.shape, test_labels.shape)\n",
    "print(\"Test - Imbalance data distribution:\", np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (6161, 64, 64, 1) (6161,)\n",
      "Test data shape: (1992, 64, 64, 1) (1992,)\n"
     ]
    }
   ],
   "source": [
    "# 加载训练集和测试集 同时输出形状\n",
    "X_train = real\n",
    "y_train = labels\n",
    "X_test = test_real\n",
    "y_test = test_labels\n",
    "print(\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([6161, 1, 64, 64]) torch.Size([6161])\n",
      "Test data shape: torch.Size([1992, 1, 64, 64]) torch.Size([1992])\n"
     ]
    }
   ],
   "source": [
    "# 对GAN训练建议使用[-1, 1]范围的输入 标准化 归一化输入\n",
    "X_train = (X_train.astype('float32') - 127.5) / 127.5\n",
    "X_test = (X_test.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "# 转换为PyTorch张量并调整通道顺序 (N,H,W,C) -> (N,C,H,W)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader: 49\n",
      "Test Loader: 16\n"
     ]
    }
   ],
   "source": [
    "# 获取图像大小\n",
    "img_size = (channel, 64, 64)\n",
    "# 获取类别数量\n",
    "n_classes = len(torch.unique(y_train))\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True) # batch_size= 128\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False) #batch_size= 128\n",
    "\n",
    "print(\"Train Loader:\",len(train_loader))\n",
    "print(\"Test Loader:\",len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 超参数设置 ----------------------------------------------------------------\n",
    "# 潜在空间维度\n",
    "latent_dim = 128\n",
    "# 训练比率 === 训练判别器的次数 / 训练生成器的次数\n",
    "train_ratio = 10\n",
    "# 优化器参数\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "# 梯度惩罚权重\n",
    "gp_weight = 10.0 # GP的调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 模型设置 -------------------------------------------------------------------\n",
    "# 构建解码器模型\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, channel):\n",
    "        \"\"\"\n",
    "        生成器/解码器模型\n",
    "        参数:\n",
    "            latent_dim: 潜在空间维度\n",
    "            channel: 输出图像的通道数\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # 初始全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4*4*256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 转置卷积层\n",
    "        self.deconv = nn.Sequential(\n",
    "            # 尺寸: 4 x 4 x 256 -> 8 x 8 x 128\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 16 x 16 x 128\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 32 x 32 x 64\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 64 x 64 x channel\n",
    "            nn.ConvTranspose2d(64, channel, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 256, 4, 4)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力机制\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        \"\"\"\n",
    "        注意力机制\n",
    "        参数:\n",
    "            in_dim: 输入特征的维度\n",
    "        \"\"\"\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        # 计算Q、K、V的权重矩阵\n",
    "        self.query = nn.Conv2d(in_dim, in_dim//8, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_dim, in_dim//8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n",
    "        \n",
    "        # 输出映射\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        batch_size, C, width, height = x.size()\n",
    "        \n",
    "        # 计算Q、K、V\n",
    "        proj_query = self.query(x).view(batch_size, -1, width*height).permute(0, 2, 1)\n",
    "        proj_key = self.key(x).view(batch_size, -1, width*height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        \n",
    "        proj_value = self.value(x).view(batch_size, -1, width*height)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, width, height)\n",
    "        \n",
    "        # 输出映射\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "# 构建编码器模型\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "        \"\"\"\n",
    "        编码器模型\n",
    "        参数:\n",
    "            img_size: 输入图像的大小 (C, H, W)\n",
    "            latent_dim: 潜在空间维度\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            # 尺寸: 64 x 64 x channel -> 32 x 32 x 64\n",
    "            nn.Conv2d(img_size[0], 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SelfAttention(64),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 16 x 16 x 128\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SelfAttention(128),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 8 x 8 x 128\n",
    "            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SelfAttention(128),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 4 x 4 x 256\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SelfAttention(256)\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*256, latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x = self.conv(x)\n",
    "        # 保存特征图用于后续的判别器\n",
    "        self.features = x\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建嵌入模型\n",
    "class LabelEmbedding(nn.Module):\n",
    "    def __init__(self, n_classes, latent_dim):\n",
    "        \"\"\"\n",
    "        标签嵌入模型\n",
    "        参数:\n",
    "            n_classes: 类别数量\n",
    "            latent_dim: 潜在空间维度\n",
    "        \"\"\"\n",
    "        super(LabelEmbedding, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_classes, latent_dim)\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        参数:\n",
    "            noise: 噪声向量\n",
    "            label: 类别标签\n",
    "        \"\"\"\n",
    "        label_embedding = self.embedding(label).squeeze(1)\n",
    "        # 元素乘法融合噪声和标签信息\n",
    "        noise_le = noise * label_embedding\n",
    "        return noise_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建自编码器\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedding):\n",
    "        \"\"\"\n",
    "        自编码器模型\n",
    "        参数:\n",
    "            encoder: 编码器模型\n",
    "            decoder: 解码器模型\n",
    "            embedding: 标签嵌入模型\n",
    "        \"\"\"\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.embedding = embedding\n",
    "        \n",
    "    def forward(self, img, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        latent = self.encoder(img)\n",
    "        labeled_latent = self.embedding(latent, label)\n",
    "        rec_img = self.decoder(labeled_latent)\n",
    "        return rec_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建判别器模型\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, n_classes):\n",
    "        \"\"\"\n",
    "        判别器模型\n",
    "        参数:\n",
    "            img_size: 输入图像的大小 (C, H, W)\n",
    "            n_classes: 类别数量\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            # 尺寸: 64 x 64 x channel -> 32 x 32 x 64\n",
    "            nn.Conv2d(img_size[0], 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 16 x 16 x 128\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 8 x 8 x 128\n",
    "            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 4 x 4 x 256\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 标签嵌入层\n",
    "        self.label_embedding = nn.Sequential(\n",
    "            nn.Embedding(n_classes, 512),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 4*4*256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 最终判别层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4*4*256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        img_features = self.conv(img)\n",
    "        img_features = img_features.view(-1, 4*4*256)\n",
    "        \n",
    "        label_features = self.label_embedding(label)\n",
    "        \n",
    "        # 融合图像和标签特征\n",
    "        features = img_features * label_features\n",
    "        output = self.classifier(features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建生成器（继承预训练的解码器和嵌入层）\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, embedding, decoder):\n",
    "        \"\"\"\n",
    "        生成器模型\n",
    "        参数:\n",
    "            embedding: 预训练的标签嵌入模型\n",
    "            decoder: 预训练的解码器模型\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        labeled_latent = self.embedding(noise, label)\n",
    "        gen_img = self.decoder(labeled_latent)\n",
    "        return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 损失函数和训练函数 ----------------------------------------------------------------\n",
    "# 判别器损失函数\n",
    "def discriminator_loss(real_logits, fake_logits, wrong_label_logits):\n",
    "    \"\"\"\n",
    "    判别器的损失函数\n",
    "    参数:\n",
    "        real_logits: 真实图像的判别结果\n",
    "        fake_logits: 生成图像的判别结果\n",
    "        wrong_label_logits: 真实图像但标签错误的判别结果\n",
    "    \"\"\"\n",
    "    real_loss = F.binary_cross_entropy_with_logits(real_logits, torch.ones_like(real_logits))\n",
    "    fake_loss = F.binary_cross_entropy_with_logits(fake_logits, torch.zeros_like(fake_logits))\n",
    "    wrong_label_loss = F.binary_cross_entropy_with_logits(wrong_label_logits, torch.zeros_like(wrong_label_logits))\n",
    "    \n",
    "    return wrong_label_loss + fake_loss + real_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器损失函数\n",
    "def generator_loss(fake_logits):\n",
    "    \"\"\"\n",
    "    生成器的损失函数\n",
    "    参数:\n",
    "        fake_logits: 生成图像的判别结果\n",
    "    \"\"\"\n",
    "    return F.binary_cross_entropy_with_logits(fake_logits, torch.ones_like(fake_logits))\n",
    "\n",
    "# 梯度惩罚函数\n",
    "def gradient_penalty(discriminator, real_images, fake_images, labels):\n",
    "    \"\"\"\n",
    "    计算梯度惩罚\n",
    "    参数:\n",
    "        discriminator: 判别器模型\n",
    "        real_images: 真实图像\n",
    "        fake_images: 生成图像\n",
    "        labels: 类别标签\n",
    "    \"\"\"\n",
    "    batch_size = real_images.size(0)\n",
    "    \n",
    "    # 创建插值图像\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    interpolated = real_images + alpha * (fake_images - real_images)\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    # 计算判别器对插值图像的输出\n",
    "    disc_interpolates = discriminator(interpolated, labels)\n",
    "    \n",
    "    # 计算梯度\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolated,\n",
    "                                   grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                                   create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # 计算梯度范数\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    \n",
    "    # 返回梯度惩罚值\n",
    "    penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "    \n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练一个epoch的函数\n",
    "def train_epoch(discriminator, generator, dataloader, d_optimizer, g_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    训练一个epoch\n",
    "    参数:\n",
    "        discriminator: 判别器模型\n",
    "        generator: 生成器模型\n",
    "        dataloader: 数据加载器\n",
    "        d_optimizer: 判别器优化器\n",
    "        g_optimizer: 生成器优化器\n",
    "        epoch: 当前epoch\n",
    "    \"\"\"\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    for batch_idx, (real_images, labels) in enumerate(dataloader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images, labels = real_images.to(device), labels.to(device)\n",
    "        \n",
    "        # 每个生成器更新前，多次更新判别器\n",
    "        for _ in range(train_ratio):\n",
    "            # 生成随机噪声和标签\n",
    "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "            wrong_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "            \n",
    "            # 清除判别器梯度\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # 生成假图像\n",
    "            fake_images = generator(noise, fake_labels)\n",
    "            \n",
    "            # 计算判别器对真实图像、假图像和标签错误图像的输出\n",
    "            real_logits = discriminator(real_images, labels)\n",
    "            fake_logits = discriminator(fake_images.detach(), fake_labels)\n",
    "            wrong_label_logits = discriminator(real_images, wrong_labels)\n",
    "            \n",
    "            # 计算判别器损失和梯度惩罚\n",
    "            d_loss = discriminator_loss(real_logits, fake_logits, wrong_label_logits)\n",
    "            gp = gradient_penalty(discriminator, real_images, fake_images.detach(), labels)\n",
    "            d_total_loss = d_loss + gp_weight * gp\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            d_total_loss.backward()\n",
    "            d_optimizer.step()\n",
    "        \n",
    "        # 训练生成器\n",
    "        # 生成新的随机噪声和标签\n",
    "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "        \n",
    "        # 清除生成器梯度\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 生成假图像\n",
    "        fake_images = generator(noise, fake_labels)\n",
    "        \n",
    "        # 计算判别器对假图像的输出\n",
    "        fake_logits = discriminator(fake_images, fake_labels)\n",
    "        \n",
    "        # 计算生成器损失\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # 记录损失\n",
    "        d_losses.append(d_total_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch} [{batch_idx}/{len(dataloader)}] - D Loss: {d_total_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return sum(d_losses) / len(d_losses), sum(g_losses) / len(g_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 自编码器训练 ----------------------------------------------------------------\n",
    "# 初始化模型\n",
    "encoder = Encoder(img_size, latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim, channel).to(device)\n",
    "embedding = LabelEmbedding(n_classes, latent_dim).to(device)\n",
    "autoencoder = Autoencoder(encoder, decoder, embedding).to(device)\n",
    "\n",
    "# 优化器\n",
    "ae_optimizer = optim.Adam(autoencoder.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# 训练函数\n",
    "def train_autoencoder(autoencoder, dataloader, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    训练自编码器\n",
    "    参数:\n",
    "        autoencoder: 自编码器模型\n",
    "        dataloader: 数据加载器\n",
    "        optimizer: 优化器\n",
    "        num_epochs: 训练轮数\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            reconstructed = autoencoder(images, labels)\n",
    "            \n",
    "            # 计算损失（使用MAE损失）\n",
    "            loss = F.l1_loss(reconstructed, images)\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} [{batch_idx}/{len(dataloader)}] - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        losses.append(sum(epoch_loss) / len(epoch_loss))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed - Avg Loss: {losses[-1]:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 训练自编码器\n",
    "print(\"开始训练自编码器...\")\n",
    "ae_losses = train_autoencoder(autoencoder, train_loader, ae_optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 显示自编码器重建结果 ----------------------------------------------------------------\n",
    "# 评估自编码器并显示结果\n",
    "def show_reconstructed_images():\n",
    "    \"\"\"显示自编码器重建的图像\"\"\"\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    # 获取测试集的一批数据\n",
    "    show_test_images = []\n",
    "    show_test_labels = []\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        # 为每个类别找到一个示例\n",
    "        for images, labels in test_loader:\n",
    "            idx = (labels == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx) > 0:\n",
    "                show_test_images.append(images[idx[0]].unsqueeze(0))\n",
    "                show_test_labels.append(labels[idx[0]].unsqueeze(0))\n",
    "                break\n",
    "    \n",
    "    # 转换为批次\n",
    "    show_test_images = torch.cat(show_test_images, dim=0).to(device)\n",
    "    show_test_labels = torch.cat(show_test_labels, dim=0).to(device)\n",
    "    \n",
    "    # 重建图像\n",
    "    with torch.no_grad():\n",
    "        reconstructed = autoencoder(show_test_images, show_test_labels)\n",
    "    \n",
    "    # 转换为NumPy数组用于显示\n",
    "    show_test_images = show_test_images.cpu().numpy()\n",
    "    reconstructed = reconstructed.cpu().numpy()\n",
    "    \n",
    "    # 转换回[0, 1]范围\n",
    "    show_test_images = show_test_images * 0.5 + 0.5\n",
    "    reconstructed = reconstructed * 0.5 + 0.5\n",
    "    \n",
    "    # 显示结果\n",
    "    plt.figure(figsize=(2*n_classes, 4))\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        # 显示原始图像\n",
    "        ax = plt.subplot(2, n_classes, i+1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(show_test_images[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(show_test_images[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # 显示重建图像\n",
    "        ax = plt.subplot(2, n_classes, i + n_classes + 1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(reconstructed[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(reconstructed[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.savefig('./bagan_gp_results/autoencoder_reconstruction.png')\n",
    "    plt.show()\n",
    "\n",
    "# 显示重建结果\n",
    "show_reconstructed_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- BAGAN-GP训练 ----------------------------------------------------------------\n",
    "# 初始化BAGAN-GP模型\n",
    "discriminator = Discriminator(img_size, n_classes).to(device)\n",
    "generator = Generator(embedding, decoder).to(device)\n",
    "\n",
    "# 优化器\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# 创建目录保存结果\n",
    "os.makedirs('bagan_gp_results', exist_ok=True)\n",
    "\n",
    "# 生成并保存图像的函数\n",
    "def generate_and_save_images(generator, epoch):\n",
    "    \"\"\"\n",
    "    生成图像并保存\n",
    "    参数:\n",
    "        generator: 生成器模型\n",
    "        epoch: 当前epoch\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # 使用固定的噪声来跟踪训练进度\n",
    "    np.random.seed(42)\n",
    "    latent_gen = torch.tensor(np.random.normal(size=(n_classes, latent_dim)), \n",
    "                              dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 获取一些测试图像\n",
    "    test_images = []\n",
    "    for c in range(n_classes):\n",
    "        for images, labels in test_loader:\n",
    "            idx = (labels == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx) > 0:\n",
    "                test_images.append(images[idx[0]].unsqueeze(0))\n",
    "                break\n",
    "    \n",
    "    test_images = torch.cat(test_images, dim=0)\n",
    "    \n",
    "    # 转换回[0, 1]范围用于显示\n",
    "    test_images_np = test_images.cpu().numpy() * 0.5 + 0.5\n",
    "    \n",
    "    # 创建画布\n",
    "    plt.figure(figsize=(2*n_classes, 2*(n_classes+1)))\n",
    "    \n",
    "    # 显示真实图像\n",
    "    for i in range(n_classes):\n",
    "        ax = plt.subplot(n_classes+1, n_classes, i+1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(test_images_np[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(test_images_np[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # 对每个类别生成图像\n",
    "    with torch.no_grad():\n",
    "        for c in range(n_classes):\n",
    "            # 创建类别标签\n",
    "            class_labels = torch.ones(n_classes, dtype=torch.long, device=device) * c\n",
    "            \n",
    "            # 生成图像\n",
    "            generated_images = generator(latent_gen, class_labels)\n",
    "            \n",
    "            # 转换为NumPy并调整范围\n",
    "            generated_images_np = generated_images.cpu().numpy() * 0.5 + 0.5\n",
    "            \n",
    "            # 显示生成的图像\n",
    "            for i in range(n_classes):\n",
    "                ax = plt.subplot(n_classes+1, n_classes, (i+1)*n_classes+1+c)\n",
    "                if channel == 3:\n",
    "                    plt.imshow(np.transpose(generated_images_np[i], (1, 2, 0)))\n",
    "                else:\n",
    "                    plt.imshow(generated_images_np[i].reshape(64, 64), cmap='gray')\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.savefig(f'bagan_gp_results/generated_plot_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 训练BAGAN-GP\n",
    "print(\"开始训练BAGAN-GP...\")\n",
    "d_loss_history = []\n",
    "g_loss_history = []\n",
    "learning_steps = 50\n",
    "\n",
    "for learning_step in range(learning_steps):\n",
    "    print(f'学习步骤 # {learning_step + 1} {\"-\" * 50}')\n",
    "    \n",
    "    # 训练一个epoch\n",
    "    d_loss, g_loss = train_epoch(discriminator, generator, train_loader, d_optimizer, g_optimizer, learning_step)\n",
    "    \n",
    "    # 记录损失\n",
    "    d_loss_history.append(d_loss)\n",
    "    g_loss_history.append(g_loss)\n",
    "    \n",
    "    # 每一步显示并保存生成的图像\n",
    "    generate_and_save_images(generator, learning_step)\n",
    "    \n",
    "    # 每10步保存模型\n",
    "    if (learning_step + 1) % 10 == 0:\n",
    "        torch.save(generator.state_dict(), f'bagan_gp_results/generator_{learning_step}.pt')\n",
    "        torch.save(discriminator.state_dict(), f'bagan_gp_results/discriminator_{learning_step}.pt')\n",
    "\n",
    "# 绘制损失历史\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d_loss_history, label='D Loss')\n",
    "plt.plot(g_loss_history, label='C Loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('bagan_gp_results/loss_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gif from generated images\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "# Define the directory containing the generated images\n",
    "dir = 'bagan_gp_results/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Collect all the images\n",
    "ims = []\n",
    "for i in range(learning_steps):\n",
    "    fname = 'generated_plot_%d.png' % i\n",
    "    if fname in os.listdir(dir):\n",
    "        print('loading png...', i)\n",
    "        im = imageio.imread(dir + fname)\n",
    "        ims.append(im)\n",
    "\n",
    "# Check if any images were found\n",
    "if ims:\n",
    "    print('saving as gif...')\n",
    "    imageio.mimsave(dir + 'training_demo.gif', ims, fps=3)\n",
    "    print(f'GIF saved to {dir}training_demo.gif')\n",
    "else:\n",
    "    print('No images found to create GIF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 设置参数\n",
    "latent_dim = 128\n",
    "n_classes = 2  # 您的代码中有两个类别：0 (少数类) 和 1 (多数类)\n",
    "channel = 1  # MNIST图像是单通道的\n",
    "\n",
    "# 初始化模型组件\n",
    "decoder = Decoder(latent_dim, channel).to(device)\n",
    "embedding = LabelEmbedding(n_classes, latent_dim).to(device)\n",
    "generator = Generator(embedding, decoder).to(device)\n",
    "\n",
    "# 加载训练好的权重\n",
    "# 使用保存的最新模型或指定的模型\n",
    "model_path = 'bagan_gp_results/generator_49.pt'  # 假设您保存了50个epoch，使用最后一个\n",
    "generator.load_state_dict(torch.load(model_path))\n",
    "generator.eval()  # 设置为评估模式\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_minority_samples(generator, class_label=0, num_samples=100):\n",
    "    \"\"\"\n",
    "    生成少数类样本\n",
    "    \n",
    "    参数:\n",
    "        generator: 训练好的生成器模型\n",
    "        class_label: 要生成的类别标签 (0表示少数类)\n",
    "        num_samples: 要生成的样本数量\n",
    "    \n",
    "    返回:\n",
    "        生成的图像数组\n",
    "    \"\"\"\n",
    "    # 设置随机种子以便结果可重现\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # 创建噪声向量\n",
    "    noise = torch.randn(num_samples, latent_dim, device=device)\n",
    "    \n",
    "    # 创建类别标签\n",
    "    labels = torch.full((num_samples,), class_label, dtype=torch.long, device=device)\n",
    "    \n",
    "    # 生成图像\n",
    "    with torch.no_grad():\n",
    "        generated_images = generator(noise, labels)\n",
    "    \n",
    "    # 转换为NumPy数组并调整范围到[0,1]用于显示\n",
    "    generated_images_np = generated_images.cpu().numpy() * 0.5 + 0.5\n",
    "    \n",
    "    return generated_images_np\n",
    "\n",
    "# 生成100个少数类样本\n",
    "minority_samples = generate_minority_samples(generator, class_label=0, num_samples=100)\n",
    "\n",
    "\n",
    "\n",
    "def plot_generated_samples(images, rows=10, cols=10):\n",
    "    \"\"\"\n",
    "    显示生成的样本图像\n",
    "    \n",
    "    参数:\n",
    "        images: 生成的图像数组\n",
    "        rows: 行数\n",
    "        cols: 列数\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*1.5, rows*1.5))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(images):\n",
    "            if images.shape[1] == 1:  # 单通道图像\n",
    "                ax.imshow(images[i].reshape(64, 64), cmap='gray')\n",
    "            else:  # 三通道图像\n",
    "                ax.imshow(np.transpose(images[i], (1, 2, 0)))\n",
    "            \n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bagan_gp_results/generated_minority_samples.png')\n",
    "    plt.show()\n",
    "\n",
    "# 显示生成的少数类样本\n",
    "plot_generated_samples(minority_samples)\n",
    "\n",
    "\n",
    "\n",
    "def save_generated_samples(images, output_dir='bagan_gp_results/generated_samples'):\n",
    "    \"\"\"\n",
    "    保存生成的样本图像\n",
    "    \n",
    "    参数:\n",
    "        images: 生成的图像数组\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        # 转换为范围[0,255]的uint8类型\n",
    "        if img.shape[0] == 1:  # 单通道图像\n",
    "            img = (img.reshape(64, 64) * 255).astype(np.uint8)\n",
    "        else:  # 三通道图像\n",
    "            img = (np.transpose(img, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "        \n",
    "        # 保存图像\n",
    "        plt.imsave(f'{output_dir}/minority_sample_{i}.png', img, cmap='gray' if channel == 1 else None)\n",
    "\n",
    "# 保存生成的少数类样本\n",
    "save_generated_samples(minority_samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def augment_dataset_with_generated_samples(X_train, y_train, generated_samples, class_label=0):\n",
    "    \"\"\"\n",
    "    使用生成的样本增强数据集\n",
    "    \n",
    "    参数:\n",
    "        X_train: 原始训练特征\n",
    "        y_train: 原始训练标签\n",
    "        generated_samples: 生成的样本\n",
    "        class_label: 生成样本的类别\n",
    "    \n",
    "    返回:\n",
    "        增强后的特征和标签\n",
    "    \"\"\"\n",
    "    # 将生成的样本转换为与原始数据相同的格式\n",
    "    gen_samples = torch.tensor(generated_samples, dtype=torch.float32)\n",
    "    \n",
    "    # 创建标签\n",
    "    gen_labels = torch.full((len(generated_samples),), class_label, dtype=torch.long)\n",
    "    \n",
    "    # 合并原始数据和生成的数据\n",
    "    X_augmented = torch.cat([X_train, gen_samples], dim=0)\n",
    "    y_augmented = torch.cat([y_train, gen_labels], dim=0)\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "# 假设X_train和y_train是您的原始训练数据\n",
    "# X_augmented, y_augmented = augment_dataset_with_generated_samples(X_train, y_train, minority_samples, class_label=0)\n",
    "# \n",
    "# # 创建新的数据加载器\n",
    "# augmented_dataset = TensorDataset(X_augmented, y_augmented)\n",
    "# augmented_loader = DataLoader(augmented_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载Inception模型用于FID和IS计算\n",
    "def load_inception_model():\n",
    "    \"\"\"加载预训练的Inception-v3模型\"\"\"\n",
    "    model = inception_v3(pretrained=True, transform_input=False)\n",
    "    # 移除最后的全连接层\n",
    "    model.fc = torch.nn.Identity()\n",
    "    model.eval()\n",
    "    return model.to(device)\n",
    "\n",
    "# 预处理图像函数\n",
    "# 修改后的预处理图像函数\n",
    "def preprocess_images(images, target_size=(299, 299)):\n",
    "    \"\"\"将图像预处理为Inception模型需要的格式\"\"\"\n",
    "    # 如果输入是numpy数组，转换为torch张量\n",
    "    if isinstance(images, np.ndarray):\n",
    "        # 从[0,1]范围转换到[0,255]范围\n",
    "        if images.max() <= 1.0:\n",
    "            images = images * 255.0\n",
    "        \n",
    "        if len(images.shape) == 3:  # 单图像\n",
    "            images = np.expand_dims(images, axis=0)\n",
    "            \n",
    "        # 确保图像是NCHW格式\n",
    "        if images.shape[1] != 3 and images.shape[1] != 1:\n",
    "            images = np.transpose(images, (0, 3, 1, 2))\n",
    "        \n",
    "        # 转换为PyTorch张量\n",
    "        images = torch.from_numpy(images).float() / 255.0\n",
    "    \n",
    "    # 处理单通道图像 - 转换为3通道\n",
    "    if images.size(1) == 1:\n",
    "        images = images.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    # 定义预处理变换\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return preprocess(images)\n",
    "# 计算FID分数\n",
    "def calculate_fid(real_images, generated_images, model, batch_size=32):\n",
    "    \"\"\"\n",
    "    计算FID分数\n",
    "    \n",
    "    参数:\n",
    "        real_images: 真实图像数组 (NCHW格式)\n",
    "        generated_images: 生成的图像数组 (NCHW格式)\n",
    "        model: 预训练的Inception v3模型\n",
    "        batch_size: 批处理大小\n",
    "    \n",
    "    返回:\n",
    "        FID分数\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 获取真实图像的特征\n",
    "    real_features = []\n",
    "    n_batches = int(np.ceil(len(real_images) / batch_size))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(n_batches), desc=\"Processing real images\"):\n",
    "            start = i * batch_size\n",
    "            end = min((i + 1) * batch_size, len(real_images))\n",
    "            batch = real_images[start:end]\n",
    "            batch = preprocess_images(batch)\n",
    "            batch = batch.to(device)\n",
    "            features = model(batch).cpu().numpy()\n",
    "            real_features.append(features)\n",
    "    \n",
    "    real_features = np.vstack(real_features)\n",
    "    \n",
    "    # 获取生成图像的特征\n",
    "    gen_features = []\n",
    "    n_batches = int(np.ceil(len(generated_images) / batch_size))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(n_batches), desc=\"Processing generated images\"):\n",
    "            start = i * batch_size\n",
    "            end = min((i + 1) * batch_size, len(generated_images))\n",
    "            batch = generated_images[start:end]\n",
    "            batch = preprocess_images(batch)\n",
    "            batch = batch.to(device)\n",
    "            features = model(batch).cpu().numpy()\n",
    "            gen_features.append(features)\n",
    "    \n",
    "    gen_features = np.vstack(gen_features)\n",
    "    \n",
    "    # 计算均值和协方差\n",
    "    mu_real = np.mean(real_features, axis=0)\n",
    "    sigma_real = np.cov(real_features, rowvar=False)\n",
    "    \n",
    "    mu_gen = np.mean(gen_features, axis=0)\n",
    "    sigma_gen = np.cov(gen_features, rowvar=False)\n",
    "    \n",
    "    # 计算FID\n",
    "    ssdiff = np.sum((mu_real - mu_gen) ** 2)\n",
    "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
    "    \n",
    "    # 检查并处理复数结果\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = ssdiff + np.trace(sigma_real + sigma_gen - 2 * covmean)\n",
    "    \n",
    "    return fid\n",
    "\n",
    "# 计算IS分数\n",
    "def calculate_is(generated_images, model, batch_size=32, splits=10):\n",
    "    \"\"\"\n",
    "    计算Inception Score\n",
    "    \n",
    "    参数:\n",
    "        generated_images: 生成的图像数组 (NCHW格式)\n",
    "        model: 预训练的Inception v3模型 (带有全连接层)\n",
    "        batch_size: 批处理大小\n",
    "        splits: 用于计算均值和标准差的拆分数\n",
    "    \n",
    "    返回:\n",
    "        IS均值和标准差\n",
    "    \"\"\"\n",
    "    # 对于IS，我们需要完整的Inception模型，包括最后的分类层\n",
    "    if not hasattr(model, 'fc') or isinstance(model.fc, torch.nn.Identity):\n",
    "        print(\"Loading full Inception model for IS calculation...\")\n",
    "        full_model = inception_v3(pretrained=True, transform_input=False)\n",
    "        full_model.eval()\n",
    "        full_model = full_model.to(device)\n",
    "    else:\n",
    "        full_model = model\n",
    "    \n",
    "    # 获取所有生成图像的预测\n",
    "    preds = []\n",
    "    n_batches = int(np.ceil(len(generated_images) / batch_size))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(n_batches), desc=\"Calculating IS\"):\n",
    "            start = i * batch_size\n",
    "            end = min((i + 1) * batch_size, len(generated_images))\n",
    "            batch = generated_images[start:end]\n",
    "            batch = preprocess_images(batch)\n",
    "            batch = batch.to(device)\n",
    "            pred = F.softmax(full_model(batch), dim=1).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "    \n",
    "    preds = np.vstack(preds)\n",
    "    \n",
    "    # 计算分割的IS并返回均值和标准差\n",
    "    scores = []\n",
    "    n_images = len(generated_images)\n",
    "    n_split = int(np.floor(n_images / splits))\n",
    "    \n",
    "    for i in range(splits):\n",
    "        part = preds[i * n_split:(i + 1) * n_split]\n",
    "        kl = part * (np.log(part) - np.log(np.mean(part, axis=0, keepdims=True)))\n",
    "        kl = np.mean(np.sum(kl, axis=1))\n",
    "        scores.append(np.exp(kl))\n",
    "        \n",
    "    return float(np.mean(scores)), float(np.std(scores))\n",
    "\n",
    "# 加载真实数据集进行FID计算\n",
    "def load_real_dataset():\n",
    "    \"\"\"加载真实数据集\"\"\"\n",
    "    # 加载MNIST数据集\n",
    "    from torchvision.datasets import MNIST\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    # 加载训练集\n",
    "    dataset = MNIST(root='/Users/max/MasterThesisData/MNIST/', train=True, download=True, transform=transform)\n",
    "    \n",
    "    # 筛选类别为4的样本（对应于我们模型中的少数类0）\n",
    "    indices = np.where(np.array(dataset.targets) == 4)[0]\n",
    "    images = dataset.data[indices].numpy().reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    # 调整为64x64大小\n",
    "    resized_images = np.zeros((len(images), 64, 64, 1), dtype=np.float32)\n",
    "    for i in range(len(images)):\n",
    "        resized_images[i] = cv2.resize(images[i], (64, 64)).reshape(64, 64, 1)\n",
    "    \n",
    "    # 标准化到[-1, 1]\n",
    "    normalized_images = (resized_images.astype('float32') - 127.5) / 127.5\n",
    "    \n",
    "    # 转换为PyTorch张量并调整通道顺序 (N,H,W,C) -> (N,C,H,W)\n",
    "    real_images = torch.tensor(normalized_images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    \n",
    "    # 转换回[0, 1]范围用于计算FID\n",
    "    real_images = real_images * 0.5 + 0.5\n",
    "    \n",
    "    return real_images\n",
    "\n",
    "# 示例：评估生成的图像\n",
    "def evaluate_generated_images():\n",
    "    \"\"\"评估生成的图像质量\"\"\"\n",
    "    # 准备模型\n",
    "    # 设置参数\n",
    "    latent_dim = 128\n",
    "    n_classes = 2  \n",
    "    channel = 1  \n",
    "    \n",
    "    # 初始化模型组件\n",
    "    decoder = Decoder(latent_dim, channel).to(device)\n",
    "    embedding = LabelEmbedding(n_classes, latent_dim).to(device)\n",
    "    generator = Generator(embedding, decoder).to(device)\n",
    "    \n",
    "    # 加载训练好的权重\n",
    "    model_path = 'bagan_gp_results/generator_49.pt'\n",
    "    generator.load_state_dict(torch.load(model_path))\n",
    "    generator.eval()\n",
    "    \n",
    "    # 生成少数类样本\n",
    "    print(\"Generating minority class samples...\")\n",
    "    minority_samples = generate_minority_samples(generator, class_label=0, num_samples=1000)\n",
    "    \n",
    "    # 加载真实样本\n",
    "    print(\"Loading real samples...\")\n",
    "    real_samples = load_real_dataset()\n",
    "    \n",
    "    # 选择一部分真实样本进行评估\n",
    "    if len(real_samples) > 1000:\n",
    "        indices = np.random.choice(len(real_samples), 1000, replace=False)\n",
    "        real_samples = real_samples[indices]\n",
    "    \n",
    "    # 加载Inception模型\n",
    "    print(\"Loading Inception model...\")\n",
    "    inception_model = load_inception_model()\n",
    "    \n",
    "    # 计算FID\n",
    "    print(\"Calculating FID score...\")\n",
    "    fid_score = calculate_fid(real_samples, minority_samples, inception_model)\n",
    "    print(f\"FID Score: {fid_score:.4f}\")\n",
    "    \n",
    "    # 计算IS\n",
    "    print(\"Calculating Inception Score...\")\n",
    "    is_mean, is_std = calculate_is(minority_samples, inception_model)\n",
    "    print(f\"Inception Score: {is_mean:.4f} ± {is_std:.4f}\")\n",
    "    \n",
    "    # 保存结果\n",
    "    results = {\n",
    "        \"FID\": float(fid_score),\n",
    "        \"IS_mean\": float(is_mean),\n",
    "        \"IS_std\": float(is_std)\n",
    "    }\n",
    "    \n",
    "    # 将结果保存到JSON文件\n",
    "    import json\n",
    "    with open('bagan_gp_results/evaluation_metrics.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"Results saved to 'bagan_gp_results/evaluation_metrics.json'\")\n",
    "    \n",
    "    return fid_score, is_mean, is_std\n",
    "\n",
    "# 执行评估\n",
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "    # 确保结果可重现\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    fid_score, is_mean, is_std = evaluate_generated_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
