{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% --------------------------------------- 固定随机种子 -----------------------------------------------------------------\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 数据准备 ---------------------------------------------------------------\n",
    "def change_image_shape(images):\n",
    "    \"\"\"调整图像形状以确保正确的格式\"\"\"\n",
    "    shape_tuple = images.shape\n",
    "    if len(shape_tuple) == 3:\n",
    "        images = images.reshape(-1, 1, shape_tuple[-1], shape_tuple[-1])\n",
    "    elif shape_tuple == 4 and shape_tuple[-1] > 3:\n",
    "        images = images.reshape(-1, shape_tuple[1], shape_tuple[-1], shape_tuple[-1])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载MNIST Fashion数据集\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 创建数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "fashion_mnist = FashionMNIST(root = '/Users/max/MasterThesisData/FashionMNIST/', train=True, download=True, transform=transform)\n",
    "test_fashion_mnist = FashionMNIST(root = '/Users/max/MasterThesisData/FashionMNIST/', train=False, download=True, transform=transform)\n",
    "images = fashion_mnist.data.numpy()\n",
    "labels = fashion_mnist.targets.numpy()\n",
    "test_images = test_fashion_mnist.data.numpy()\n",
    "test_labels = test_fashion_mnist.targets.numpy()\n",
    "# 转换图像形状\n",
    "images = images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "print(\"Train dataset\")\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(\"Test dataset\")\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择类别为3和4的样本\n",
    "images_3 = images[labels == 3]\n",
    "images_4 = images[labels == 4]\n",
    "# 将类别4的样本数减少到类别3样本数的0.5%\n",
    "num_3 = images_3.shape[0]\n",
    "num_4 = int(num_3 * 0.005)  # 0.5%\n",
    "images_4 = images_4[:num_4]\n",
    "# 构造新的标签数组\n",
    "labels_3 = np.full((images_3.shape[0],), 3)\n",
    "labels_4 = np.full((images_4.shape[0],), 4)\n",
    "# 合并样本和标签\n",
    "images_new = np.vstack([images_3, images_4])\n",
    "labels_new = np.concatenate([labels_3, labels_4])\n",
    "imbalance_images = images_new\n",
    "imbalance_labels = labels_new\n",
    "\n",
    "images = imbalance_images # 3和4类别的样本\n",
    "labels = imbalance_labels # 3和4类别的样本\n",
    "#  3 -> 1 4 -> 0\n",
    "labels[labels == 3] = 1\n",
    "labels[labels == 4] = 0\n",
    "print(\"Train - Imbalance data shape:\", images.shape, labels.shape)\n",
    "print(\"Train - Imbalance data distribution:\", np.unique(labels, return_counts=True))\n",
    "# 选择类别为3和4的样本\n",
    "test_images_3 = test_images[test_labels == 3]\n",
    "test_images_4 = test_images[test_labels == 4]\n",
    "# 构造新的标签数组\n",
    "test_labels_3 = np.full((test_images_3.shape[0],), 3)\n",
    "test_labels_4 = np.full((test_images_4.shape[0],), 4)\n",
    "# 合并样本和标签\n",
    "test_images_new = np.vstack([test_images_3, test_images_4])\n",
    "test_labels_new = np.concatenate([test_labels_3, test_labels_4])\n",
    "test_imbalance_images = test_images_new\n",
    "test_imbalance_labels = test_labels_new\n",
    "\n",
    "test_images = test_imbalance_images # 3和4类别的样本\n",
    "test_labels = test_imbalance_labels # 3和4类别的样本\n",
    "\n",
    "#  3 -> 1 4 -> 0\n",
    "test_labels[test_labels == 3] = 1\n",
    "test_labels[test_labels == 4] = 0\n",
    "\n",
    "print(\"Test - Imbalance data shape:\", test_images.shape, test_labels.shape)\n",
    "print(\"Test - Imbalance data distribution:\", np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置通道数\n",
    "channel = images.shape[-1]\n",
    "\n",
    "# 将图像调整为 64 x 64 x channel\n",
    "real = np.ndarray(shape=(images.shape[0], 64, 64, channel))\n",
    "for i in range(images.shape[0]):\n",
    "    real[i] = cv2.resize(images[i], (64, 64)).reshape((64, 64, channel))\n",
    "\n",
    "\n",
    "test_channel = test_images.shape[-1]\n",
    "test_real = np.ndarray(shape=(test_images.shape[0], 64, 64, test_channel))\n",
    "for i in range(test_images.shape[0]):\n",
    "    test_real[i] = cv2.resize(test_images[i], (64, 64)).reshape((64, 64, test_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = real\n",
    "y_train = labels\n",
    "X_test = test_real\n",
    "y_test = test_labels\n",
    "print(\"Train data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对GAN训练建议使用[-1, 1]范围的输入\n",
    "X_train = (X_train.astype('float32') - 127.5) / 127.5\n",
    "X_test = (X_test.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "# 转换为PyTorch张量并调整通道顺序 (N,H,W,C) -> (N,C,H,W)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取图像大小\n",
    "img_size = (channel, 64, 64)\n",
    "# 获取类别数量\n",
    "n_classes = len(torch.unique(y_train))\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 超参数设置 ----------------------------------------------------------------\n",
    "# 潜在空间维度\n",
    "latent_dim = 128\n",
    "# 训练比率 === 训练判别器的次数 / 训练生成器的次数\n",
    "train_ratio = 10\n",
    "# 优化器参数\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "# 梯度惩罚权重\n",
    "gp_weight = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 模型设置 -------------------------------------------------------------------\n",
    "# 构建生成器/解码器模型\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, channel):\n",
    "        \"\"\"\n",
    "        生成器/解码器模型\n",
    "        参数:\n",
    "            latent_dim: 潜在空间维度\n",
    "            channel: 输出图像的通道数\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # 初始全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4*4*256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 转置卷积层\n",
    "        self.deconv = nn.Sequential(\n",
    "            # 尺寸: 4 x 4 x 256 -> 8 x 8 x 128\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 16 x 16 x 128\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 32 x 32 x 64\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 64 x 64 x channel\n",
    "            nn.ConvTranspose2d(64, channel, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 256, 4, 4)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建编码器模型\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "        \"\"\"\n",
    "        编码器模型\n",
    "        参数:\n",
    "            img_size: 输入图像的大小 (C, H, W)\n",
    "            latent_dim: 潜在空间维度\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            # 尺寸: 64 x 64 x channel -> 32 x 32 x 64\n",
    "            nn.Conv2d(img_size[0], 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 16 x 16 x 128\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 8 x 8 x 128\n",
    "            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 4 x 4 x 256\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*4*256, latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        x = self.conv(x)\n",
    "        # 保存特征图用于后续的判别器\n",
    "        self.features = x\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建嵌入模型\n",
    "class LabelEmbedding(nn.Module):\n",
    "    def __init__(self, n_classes, latent_dim):\n",
    "        \"\"\"\n",
    "        标签嵌入模型\n",
    "        参数:\n",
    "            n_classes: 类别数量\n",
    "            latent_dim: 潜在空间维度\n",
    "        \"\"\"\n",
    "        super(LabelEmbedding, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_classes, latent_dim)\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        参数:\n",
    "            noise: 噪声向量\n",
    "            label: 类别标签\n",
    "        \"\"\"\n",
    "        label_embedding = self.embedding(label).squeeze(1)\n",
    "        # 元素乘法融合噪声和标签信息\n",
    "        noise_le = noise * label_embedding\n",
    "        return noise_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建自编码器\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedding):\n",
    "        \"\"\"\n",
    "        自编码器模型\n",
    "        参数:\n",
    "            encoder: 编码器模型\n",
    "            decoder: 解码器模型\n",
    "            embedding: 标签嵌入模型\n",
    "        \"\"\"\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.embedding = embedding\n",
    "        \n",
    "    def forward(self, img, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        latent = self.encoder(img)\n",
    "        labeled_latent = self.embedding(latent, label)\n",
    "        rec_img = self.decoder(labeled_latent)\n",
    "        return rec_img\n",
    "\n",
    "# 构建判别器模型\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, n_classes):\n",
    "        \"\"\"\n",
    "        判别器模型\n",
    "        参数:\n",
    "            img_size: 输入图像的大小 (C, H, W)\n",
    "            n_classes: 类别数量\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            # 尺寸: 64 x 64 x channel -> 32 x 32 x 64\n",
    "            nn.Conv2d(img_size[0], 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 32 x 32 x 64 -> 16 x 16 x 128\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 16 x 16 x 128 -> 8 x 8 x 128\n",
    "            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 尺寸: 8 x 8 x 128 -> 4 x 4 x 256\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 标签嵌入层\n",
    "        self.label_embedding = nn.Sequential(\n",
    "            nn.Embedding(n_classes, 512),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 4*4*256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # 最终判别层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4*4*256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        img_features = self.conv(img)\n",
    "        img_features = img_features.view(-1, 4*4*256)\n",
    "        \n",
    "        label_features = self.label_embedding(label)\n",
    "        \n",
    "        # 融合图像和标签特征\n",
    "        features = img_features * label_features\n",
    "        output = self.classifier(features)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建生成器（继承预训练的解码器和嵌入层）\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, embedding, decoder):\n",
    "        \"\"\"\n",
    "        生成器模型\n",
    "        参数:\n",
    "            embedding: 预训练的标签嵌入模型\n",
    "            decoder: 预训练的解码器模型\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, noise, label):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        labeled_latent = self.embedding(noise, label)\n",
    "        gen_img = self.decoder(labeled_latent)\n",
    "        return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 损失函数和训练函数 ----------------------------------------------------------------\n",
    "# 判别器损失函数\n",
    "def discriminator_loss(real_logits, fake_logits, wrong_label_logits):\n",
    "    \"\"\"\n",
    "    判别器的损失函数\n",
    "    参数:\n",
    "        real_logits: 真实图像的判别结果\n",
    "        fake_logits: 生成图像的判别结果\n",
    "        wrong_label_logits: 真实图像但标签错误的判别结果\n",
    "    \"\"\"\n",
    "    real_loss = F.binary_cross_entropy_with_logits(real_logits, torch.ones_like(real_logits))\n",
    "    fake_loss = F.binary_cross_entropy_with_logits(fake_logits, torch.zeros_like(fake_logits))\n",
    "    wrong_label_loss = F.binary_cross_entropy_with_logits(wrong_label_logits, torch.zeros_like(wrong_label_logits))\n",
    "    \n",
    "    return wrong_label_loss + fake_loss + real_loss\n",
    "\n",
    "# 生成器损失函数\n",
    "def generator_loss(fake_logits):\n",
    "    \"\"\"\n",
    "    生成器的损失函数\n",
    "    参数:\n",
    "        fake_logits: 生成图像的判别结果\n",
    "    \"\"\"\n",
    "    return F.binary_cross_entropy_with_logits(fake_logits, torch.ones_like(fake_logits))\n",
    "\n",
    "# 梯度惩罚函数\n",
    "def gradient_penalty(discriminator, real_images, fake_images, labels):\n",
    "    \"\"\"\n",
    "    计算梯度惩罚\n",
    "    参数:\n",
    "        discriminator: 判别器模型\n",
    "        real_images: 真实图像\n",
    "        fake_images: 生成图像\n",
    "        labels: 类别标签\n",
    "    \"\"\"\n",
    "    batch_size = real_images.size(0)\n",
    "    \n",
    "    # 创建插值图像\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    interpolated = real_images + alpha * (fake_images - real_images)\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    # 计算判别器对插值图像的输出\n",
    "    disc_interpolates = discriminator(interpolated, labels)\n",
    "    \n",
    "    # 计算梯度\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolated,\n",
    "                                   grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                                   create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    # 计算梯度范数\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    \n",
    "    # 返回梯度惩罚值\n",
    "    penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "    \n",
    "    return penalty\n",
    "\n",
    "# 训练一个epoch的函数\n",
    "def train_epoch(discriminator, generator, dataloader, d_optimizer, g_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    训练一个epoch\n",
    "    参数:\n",
    "        discriminator: 判别器模型\n",
    "        generator: 生成器模型\n",
    "        dataloader: 数据加载器\n",
    "        d_optimizer: 判别器优化器\n",
    "        g_optimizer: 生成器优化器\n",
    "        epoch: 当前epoch\n",
    "    \"\"\"\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    \n",
    "    for batch_idx, (real_images, labels) in enumerate(dataloader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images, labels = real_images.to(device), labels.to(device)\n",
    "        \n",
    "        # 每个生成器更新前，多次更新判别器\n",
    "        for _ in range(train_ratio):\n",
    "            # 生成随机噪声和标签\n",
    "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "            wrong_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "            \n",
    "            # 清除判别器梯度\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # 生成假图像\n",
    "            fake_images = generator(noise, fake_labels)\n",
    "            \n",
    "            # 计算判别器对真实图像、假图像和标签错误图像的输出\n",
    "            real_logits = discriminator(real_images, labels)\n",
    "            fake_logits = discriminator(fake_images.detach(), fake_labels)\n",
    "            wrong_label_logits = discriminator(real_images, wrong_labels)\n",
    "            \n",
    "            # 计算判别器损失和梯度惩罚\n",
    "            d_loss = discriminator_loss(real_logits, fake_logits, wrong_label_logits)\n",
    "            gp = gradient_penalty(discriminator, real_images, fake_images.detach(), labels)\n",
    "            d_total_loss = d_loss + gp_weight * gp\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            d_total_loss.backward()\n",
    "            d_optimizer.step()\n",
    "        \n",
    "        # 训练生成器\n",
    "        # 生成新的随机噪声和标签\n",
    "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_labels = torch.randint(0, n_classes, (batch_size,), device=device)\n",
    "        \n",
    "        # 清除生成器梯度\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 生成假图像\n",
    "        fake_images = generator(noise, fake_labels)\n",
    "        \n",
    "        # 计算判别器对假图像的输出\n",
    "        fake_logits = discriminator(fake_images, fake_labels)\n",
    "        \n",
    "        # 计算生成器损失\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # 记录损失\n",
    "        d_losses.append(d_total_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch} [{batch_idx}/{len(dataloader)}] - D Loss: {d_total_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return sum(d_losses) / len(d_losses), sum(g_losses) / len(g_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 自编码器训练 ----------------------------------------------------------------\n",
    "# 初始化模型\n",
    "encoder = Encoder(img_size, latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim, channel).to(device)\n",
    "embedding = LabelEmbedding(n_classes, latent_dim).to(device)\n",
    "autoencoder = Autoencoder(encoder, decoder, embedding).to(device)\n",
    "\n",
    "# 优化器\n",
    "ae_optimizer = optim.Adam(autoencoder.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# 训练函数\n",
    "def train_autoencoder(autoencoder, dataloader, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    训练自编码器\n",
    "    参数:\n",
    "        autoencoder: 自编码器模型\n",
    "        dataloader: 数据加载器\n",
    "        optimizer: 优化器\n",
    "        num_epochs: 训练轮数\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            reconstructed = autoencoder(images, labels)\n",
    "            \n",
    "            # 计算损失（使用MAE损失）\n",
    "            loss = F.l1_loss(reconstructed, images)\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} [{batch_idx}/{len(dataloader)}] - Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        losses.append(sum(epoch_loss) / len(epoch_loss))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed - Avg Loss: {losses[-1]:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 训练自编码器\n",
    "print(\"开始训练自编码器...\")\n",
    "ae_losses = train_autoencoder(autoencoder, train_loader, ae_optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- 显示自编码器重建结果 ----------------------------------------------------------------\n",
    "# 评估自编码器并显示结果\n",
    "def show_reconstructed_images():\n",
    "    \"\"\"显示自编码器重建的图像\"\"\"\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    # 获取测试集的一批数据\n",
    "    show_test_images = []\n",
    "    show_test_labels = []\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        # 为每个类别找到一个示例\n",
    "        for images, labels in test_loader:\n",
    "            idx = (labels == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx) > 0:\n",
    "                show_test_images.append(images[idx[0]].unsqueeze(0))\n",
    "                show_test_labels.append(labels[idx[0]].unsqueeze(0))\n",
    "                break\n",
    "    \n",
    "    # 转换为批次\n",
    "    show_test_images = torch.cat(show_test_images, dim=0).to(device)\n",
    "    show_test_labels = torch.cat(show_test_labels, dim=0).to(device)\n",
    "    \n",
    "    # 重建图像\n",
    "    with torch.no_grad():\n",
    "        reconstructed = autoencoder(show_test_images, show_test_labels)\n",
    "    \n",
    "    # 转换为NumPy数组用于显示\n",
    "    show_test_images = show_test_images.cpu().numpy()\n",
    "    reconstructed = reconstructed.cpu().numpy()\n",
    "    \n",
    "    # 转换回[0, 1]范围\n",
    "    show_test_images = show_test_images * 0.5 + 0.5\n",
    "    reconstructed = reconstructed * 0.5 + 0.5\n",
    "    \n",
    "    # 显示结果\n",
    "    plt.figure(figsize=(2*n_classes, 4))\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        # 显示原始图像\n",
    "        ax = plt.subplot(2, n_classes, i+1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(show_test_images[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(show_test_images[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # 显示重建图像\n",
    "        ax = plt.subplot(2, n_classes, i + n_classes + 1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(reconstructed[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(reconstructed[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.savefig('./bagan_gp_results/autoencoder_reconstruction.png')\n",
    "    plt.show()\n",
    "\n",
    "# 显示重建结果\n",
    "show_reconstructed_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ---------------------------------- BAGAN-GP训练 ----------------------------------------------------------------\n",
    "# 初始化BAGAN-GP模型\n",
    "discriminator = Discriminator(img_size, n_classes).to(device)\n",
    "generator = Generator(embedding, decoder).to(device)\n",
    "\n",
    "# 优化器\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# 创建目录保存结果\n",
    "os.makedirs('bagan_gp_results', exist_ok=True)\n",
    "\n",
    "# 生成并保存图像的函数\n",
    "def generate_and_save_images(generator, epoch):\n",
    "    \"\"\"\n",
    "    生成图像并保存\n",
    "    参数:\n",
    "        generator: 生成器模型\n",
    "        epoch: 当前epoch\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # 使用固定的噪声来跟踪训练进度\n",
    "    np.random.seed(42)\n",
    "    latent_gen = torch.tensor(np.random.normal(size=(n_classes, latent_dim)), \n",
    "                              dtype=torch.float32).to(device)\n",
    "    \n",
    "    # 获取一些测试图像\n",
    "    test_images = []\n",
    "    for c in range(n_classes):\n",
    "        for images, labels in test_loader:\n",
    "            idx = (labels == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx) > 0:\n",
    "                test_images.append(images[idx[0]].unsqueeze(0))\n",
    "                break\n",
    "    \n",
    "    test_images = torch.cat(test_images, dim=0)\n",
    "    \n",
    "    # 转换回[0, 1]范围用于显示\n",
    "    test_images_np = test_images.cpu().numpy() * 0.5 + 0.5\n",
    "    \n",
    "    # 创建画布\n",
    "    plt.figure(figsize=(2*n_classes, 2*(n_classes+1)))\n",
    "    \n",
    "    # 显示真实图像\n",
    "    for i in range(n_classes):\n",
    "        ax = plt.subplot(n_classes+1, n_classes, i+1)\n",
    "        if channel == 3:\n",
    "            plt.imshow(np.transpose(test_images_np[i], (1, 2, 0)))\n",
    "        else:\n",
    "            plt.imshow(test_images_np[i].reshape(64, 64), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # 对每个类别生成图像\n",
    "    with torch.no_grad():\n",
    "        for c in range(n_classes):\n",
    "            # 创建类别标签\n",
    "            class_labels = torch.ones(n_classes, dtype=torch.long, device=device) * c\n",
    "            \n",
    "            # 生成图像\n",
    "            generated_images = generator(latent_gen, class_labels)\n",
    "            \n",
    "            # 转换为NumPy并调整范围\n",
    "            generated_images_np = generated_images.cpu().numpy() * 0.5 + 0.5\n",
    "            \n",
    "            # 显示生成的图像\n",
    "            for i in range(n_classes):\n",
    "                ax = plt.subplot(n_classes+1, n_classes, (i+1)*n_classes+1+c)\n",
    "                if channel == 3:\n",
    "                    plt.imshow(np.transpose(generated_images_np[i], (1, 2, 0)))\n",
    "                else:\n",
    "                    plt.imshow(generated_images_np[i].reshape(64, 64), cmap='gray')\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.savefig(f'bagan_gp_results/generated_plot_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 训练BAGAN-GP\n",
    "print(\"开始训练BAGAN-GP...\")\n",
    "d_loss_history = []\n",
    "g_loss_history = []\n",
    "learning_steps = 50\n",
    "\n",
    "for learning_step in range(learning_steps):\n",
    "    print(f'学习步骤 # {learning_step + 1} {\"-\" * 50}')\n",
    "    \n",
    "    # 训练一个epoch\n",
    "    d_loss, g_loss = train_epoch(discriminator, generator, train_loader, d_optimizer, g_optimizer, learning_step)\n",
    "    \n",
    "    # 记录损失\n",
    "    d_loss_history.append(d_loss)\n",
    "    g_loss_history.append(g_loss)\n",
    "    \n",
    "    # 每一步显示并保存生成的图像\n",
    "    generate_and_save_images(generator, learning_step)\n",
    "    \n",
    "    # 每10步保存模型\n",
    "    if (learning_step + 1) % 10 == 0:\n",
    "        torch.save(generator.state_dict(), f'bagan_gp_results/generator_{learning_step}.pt')\n",
    "        torch.save(discriminator.state_dict(), f'bagan_gp_results/discriminator_{learning_step}.pt')\n",
    "\n",
    "# 绘制损失历史\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d_loss_history, label='判别器损失')\n",
    "plt.plot(g_loss_history, label='生成器损失')\n",
    "plt.legend()\n",
    "plt.title('训练损失')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('bagan_gp_results/loss_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gif from generated images\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "# Define the directory containing the generated images\n",
    "dir = 'bagan_gp_results/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Collect all the images\n",
    "ims = []\n",
    "for i in range(learning_steps):\n",
    "    fname = 'generated_plot_%d.png' % i\n",
    "    if fname in os.listdir(dir):\n",
    "        print('loading png...', i)\n",
    "        im = imageio.imread(dir + fname)\n",
    "        ims.append(im)\n",
    "\n",
    "# Check if any images were found\n",
    "if ims:\n",
    "    print('saving as gif...')\n",
    "    imageio.mimsave(dir + 'training_demo.gif', ims, fps=3)\n",
    "    print(f'GIF saved to {dir}training_demo.gif')\n",
    "else:\n",
    "    print('No images found to create GIF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
