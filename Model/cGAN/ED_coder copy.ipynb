{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections  # 导入collections模块，用于统计和操作容器数据，如Counter\n",
    "import torch  # 导入PyTorch库，用于深度学习任务\n",
    "import torch.nn as nn  # 从torch中导入神经网络模块，简化模型构建\n",
    "from torch.utils.data import TensorDataset  # 导入TensorDataset，用于将Tensor数据打包成数据集\n",
    "import numpy as np  # 导入NumPy库，用于高效的数值计算和数组操作\n",
    "from sklearn.neighbors import NearestNeighbors  # 导入最近邻算法，用于在SMOTE中寻找相邻样本\n",
    "import time  # 导入time模块，用于计时\n",
    "import os  # 导入os模块，用于文件和目录操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'dim_h': 64, 'n_channel': 1, 'n_z': 300, 'sigma': 1.0, 'lambda': 0.01, 'lr': 0.0002, 'epochs': 50, 'batch_size': 64, 'save': True, 'train': True, 'dataset': 'mnist34', 'fraction': 0.005}\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # 打印当前PyTorch使用的CUDA版本，例如显示\"10.1\"\n",
    "\n",
    "t3 = time.time()  # 记录程序开始时的时间，用于后续计算总运行时间\n",
    "##############################################################################\n",
    "\"\"\"args for AE\"\"\"\n",
    "# 以下部分设置自动编码器（AE）的相关参数\n",
    "args = {}  # 创建一个空字典，用于存放模型和训练的参数\n",
    "args['dim_h'] = 64         # 设置隐藏层通道数的基础因子，后续卷积层的通道数会成倍增加\n",
    "args['n_channel'] = 1  #3    # 输入数据的通道数，1表示灰度图（3则为彩色图）；这里选用灰度图\n",
    "args['n_z'] = 300 #600     # 潜在空间（编码空间）的维度数，决定编码器输出特征向量的大小\n",
    "args['sigma'] = 1.0        # 潜在空间中使用的方差参数，可用于正则化\n",
    "args['lambda'] = 0.01      # 判别器损失的权重超参数（如在对抗训练中使用）\n",
    "args['lr'] = 0.0002        # Adam优化器的学习率，决定参数更新的步长\n",
    "args['epochs'] = 50       # 训练过程中遍历数据集的轮数\n",
    "args['batch_size'] = 64   # 每个训练批次的样本数量\n",
    "args['save'] = True        # 如果为True，则在每个训练轮结束时保存模型权重\n",
    "args['train'] = True       # 若为True则进行训练，否则加载已保存的模型进行测试\n",
    "args['dataset'] = 'mnist34'  #'fmnist' # 指定使用的数据集，这里选择MNIST数据集 mnist34 mnist17 fashionmnist34 cifar10\n",
    "args['fraction'] = 0.005   # 用于训练的数据集的子集比例，可用于快速测试\n",
    "\n",
    "##############################################################################\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Attention Block\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        \"\"\"\n",
    "        :param filters: 输入特征图的通道数(同时也是卷积输出的通道数)\n",
    "        \"\"\"\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        # 与 Keras 中的 Conv2D(filters, kernel_size=1, padding='same') 对应\n",
    "        # PyTorch 中 padding=0 就相当于 'same'（仅当 kernel_size=1 时）\n",
    "        self.query_conv = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "        self.key_conv   = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "        self.value_conv = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 的形状一般是 (batch_size, filters, H, W)\n",
    "        \"\"\"\n",
    "        # 1. 分别得到 query, key, value\n",
    "        query = F.relu(self.query_conv(x))\n",
    "        key   = F.relu(self.key_conv(x))\n",
    "        value = F.relu(self.value_conv(x))\n",
    "\n",
    "        # 2. 计算注意力图: 先元素乘，再对通道维度 (dim=1) 求和\n",
    "        attention_map = query * key                  # 形状 (N, filters, H, W)\n",
    "        attention_map = torch.sum(attention_map, dim=1, keepdim=True)  \n",
    "        # 现在 attention_map 的形状是 (N, 1, H, W)\n",
    "\n",
    "        # 3. 对空间维度 (H, W) 做 softmax\n",
    "        # 先展平再 softmax，再 reshape 回去\n",
    "        N, _, H, W = attention_map.shape\n",
    "        attention_map = attention_map.view(N, 1, -1)         # (N, 1, H*W)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)     # 在 H*W 上做 softmax\n",
    "        attention_map = attention_map.view(N, 1, H, W)       # (N, 1, H, W)\n",
    "\n",
    "        # 4. 注意力加权 value，并与原输入相加\n",
    "        attended_value = attention_map * value\n",
    "        output = x + attended_value\n",
    "\n",
    "        return output\n",
    "# 定义编码器模型\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入数据的通道数\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "        \n",
    "        # 使用卷积层提取图像特征\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),  \n",
    "            # 第一层卷积：输入通道数为n_channel，输出为dim_h，卷积核大小4，步幅2，填充1，无偏置\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 使用LeakyReLU激活函数，负半部斜率设为0.2\n",
    "            AttentionBlock(filters=self.dim_h),\n",
    "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),  \n",
    "            # 第二层卷积：通道数翻倍到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 对第二层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),  \n",
    "            # 第三层卷积：通道数增加到dim_h*4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            \n",
    "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),  \n",
    "            # 第四层卷积：通道数增加到dim_h*8\n",
    "            \n",
    "            #3d and 32 by 32\n",
    "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),  # 备用卷积层配置\n",
    "            nn.BatchNorm2d(self.dim_h * 8),  # 对第四层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True)  # 激活函数\n",
    "            # 注释中还有其他可能的卷积配置，这里使用的是标准配置\n",
    "        )\n",
    "        # 全连接层：将卷积层输出映射到潜在空间\n",
    "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)  \n",
    "        # 这里计算dim_h * (2**3)相当于dim_h*8，假设卷积层最后输出特征数为dim_h*8\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('enc')  # 调试打印，可查看编码器被调用\n",
    "        # print('input ', x.size())  # 打印输入尺寸，例如torch.Size([batch_size, channel, H, W])\n",
    "        x = self.conv(x)  # 将输入图像通过卷积层提取特征\n",
    "        x = x.squeeze()   # 去除多余的尺寸（例如将[batch_size, 1, N]变为[batch_size, N]）\n",
    "        # print('aft squeeze ', x.size())  # 调试打印压缩后的尺寸\n",
    "        x = self.fc(x)    # 通过全连接层映射到潜在空间维度\n",
    "        # print('out ', x.size())  # 打印最终输出尺寸，应为[batch_size, n_z]\n",
    "        return x  # 返回编码后的潜在表示\n",
    "\n",
    "# 定义解码器模型\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入通道数（用于输出重构图像）\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "\n",
    "        # 全连接层：将潜在向量映射到足够重构卷积特征图的尺寸\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),  # 将潜在向量转换为高维特征，尺寸为[batch_size, dim_h*8*7*7]\n",
    "            nn.ReLU()  # 使用ReLU激活函数\n",
    "        )\n",
    "\n",
    "        # 反卷积层（转置卷积）：将全连接层的输出转换为图像\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),  \n",
    "            # 第一层反卷积：将通道数从dim_h*8降到dim_h*4，卷积核大小4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),  \n",
    "            # 第二层反卷积：将通道数从dim_h*4降到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),  \n",
    "            # 第三层反卷积：将通道数降为1，同时上采样（步幅为2），恢复到原图大小\n",
    "            # nn.Sigmoid())  # 也可用Sigmoid激活函数使输出在[0,1]之间\n",
    "            nn.Tanh()  # 这里使用Tanh激活函数，将输出映射到[-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('dec')  # 调试打印，查看解码器调用\n",
    "        # print('input ', x.size())  # 打印输入潜在向量的尺寸\n",
    "        x = self.fc(x)  # 通过全连接层处理潜在向量\n",
    "        x = x.view(-1, self.dim_h * 8, 7, 7)  \n",
    "        # 将全连接层输出重塑为特征图，尺寸为[batch_size, dim_h*8, 7, 7]，为反卷积做准备\n",
    "        x = self.deconv(x)  # 通过反卷积层重构出图像\n",
    "        return x  # 返回重构图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the MNIST dataset with labels 3 and 4.\n",
      "Imbalanced Ratio:  0.1\n",
      "Number of label 3 in the final training set:  6131\n",
      "Number of label 4 in the final training set (after downsampling):  613\n",
      "Number of label 3 in the final test set:  1010\n",
      "Number of label 4 in the final test set:  982\n",
      "Total samples in final training set:  6744\n",
      "Total samples in final test set:  1992\n",
      "Number of batches in training set:  106\n",
      "Number of batches in test set:  32\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5451, 0.9922, 0.6627, 0.5412, 0.5412, 0.0941, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2549, 0.9882, 0.9882, 0.9882, 0.9882, 0.9922, 0.6784,\n",
      "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.3529, 0.5922, 0.4353, 0.7176, 0.9922, 0.9882,\n",
      "          0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882,\n",
      "          0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882,\n",
      "          0.2706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8941,\n",
      "          0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.9922, 0.7255,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.9647, 0.9686, 0.2627,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.2235, 0.9569, 0.9882, 0.5294, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0275, 0.6196, 0.9882, 0.9451, 0.5294,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4157, 1.0000, 0.9922,\n",
      "          0.7451, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4039, 0.9255,\n",
      "          0.9882, 0.8588, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3059,\n",
      "          0.9882, 0.9882, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
      "          0.9882, 0.8549, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922,\n",
      "          0.9882, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5843, 0.9922,\n",
      "          0.8039, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.3882, 0.9922, 0.7922,\n",
      "          0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0275, 0.2745, 0.2745, 0.7373, 0.9882, 0.8431, 0.2627,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2588, 0.9882, 0.9882, 0.9882, 0.8235, 0.0824, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3373, 0.9882, 0.9882, 0.4549, 0.0471, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6744, 784)\n",
      "y_train.shape: (6744,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "Encoder(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): AttentionBlock(\n",
      "      (query_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (key_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=300, bias=True)\n",
      ")\n",
      "Decoder(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=25088, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "train image shape: (6744, 784)\n",
      "train label shape: (6744,)\n",
      "Counter({np.int64(1): 6131, np.int64(0): 613})\n",
      "train image shape: (6744, 1, 28, 28)\n",
      "(Features)Tensor Dec_X: torch.Size([6744, 1, 28, 28])\n",
      "(Labels)Tensor Dec_y: torch.Size([6744])\n",
      "train_loader: <torch.utils.data.dataloader.DataLoader object at 0x17f26f460>\n"
     ]
    }
   ],
   "source": [
    "from Get_datasets import get_datasets\n",
    "X_train, y_train, X_test, y_test,train_loader,test_loader = get_datasets(dataname=\"mnist34\",fraction=0.1)  # 获取数据集\n",
    "encoder = Encoder(args)  # 创建编码器模型\n",
    "decoder = Decoder(args)  # 创建解码器模型\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 检测GPU是否可用\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)  # 将模型移动到GPU上\n",
    "train_on_gpu = torch.cuda.is_available()  # 检测GPU是否可用\n",
    "#Deconder loss function\n",
    "criterion = nn.MSELoss()  # 定义均方误差损失函数\n",
    "criterion = criterion.to(device)  # 将损失函数移动到GPU上\n",
    "\n",
    "dec_x = X_train  # 获取训练数据\n",
    "dec_y = y_train  # 获取训练标签\n",
    "print('train image shape:', dec_x.shape)  # 打印训练数据形状\n",
    "print('train label shape:', dec_y.shape)  # 打印训练标签形状\n",
    "#print('train image:', dec_x)  # 打印训练数据\n",
    "#print('train label:', dec_y)  # 打印训练标签\n",
    "print(collections.Counter(dec_y))  # 使用Counter统计每个类别的样本数量\n",
    "dec_x = dec_x.reshape(-1, 1, 28, 28)  # 将训练数据重塑为合适的形状\n",
    "print('train image shape:', dec_x.shape)  # 打印重塑后的训练数据形状\n",
    "batch_size = args['batch_size']  # 获取批次大小\n",
    "num_workers = 0  # 设置数据加载器的线程数\n",
    "tensor_x = torch.Tensor(dec_x)  # 将NumPy数组转换为PyTorch张量\n",
    "tensor_y = torch.tensor(dec_y, dtype = torch.long)  # 将NumPy数组转换为PyTorch张量\n",
    "print('(Features)Tensor Dec_X:',tensor_x.shape)\n",
    "print('(Labels)Tensor Dec_y:',tensor_y.shape)\n",
    "\n",
    "mnist_train  =  TensorDataset(tensor_x, tensor_y)  # 将特征和标签打包为数据集\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True)  # 创建数据加载器\n",
    "print('train_loader:',train_loader)\n",
    "classes = ('0','1') # binary classification\n",
    "best_loss = np.inf  # 初始化最佳损失为无穷大\n",
    "\n",
    "t0 = time.time()  # 记录当前时间，用于计算训练时间\n",
    "if args['train']:\n",
    "    fraction = args['fraction']  # 获取数据集子集比例\n",
    "    encoder_optim = torch.optim.Adam(encoder.parameters(), lr=args['lr'])  # 创建编码器的Adam优化器\n",
    "    decoder_optim = torch.optim.Adam(decoder.parameters(), lr=args['lr'])  # 创建解码器的Adam优化器\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        train_loss = 0.0  # 初始化训练损失为0\n",
    "        tmse_loss = 0.0 # 初始化均方误差损失为0\n",
    "        tdiscr_loss = 0.0 # 初始化判别器损失为0\n",
    "        encoder.train()  # 设置编码器为训练模式\n",
    "        decoder.train()\n",
    "        for images, labels in train_loader: # 从数据加载器中加载数据\n",
    "            encoder_optim.zero_grad()\n",
    "            decoder_optim.zero_grad()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labsn = labels.detach().cpu().numpy()  # 将标签转换为NumPy数组\n",
    "            #print('labsn:',labsn.shape, labsn)\n",
    "            z_hat = encoder(images) # 通过编码器生成潜在向量\n",
    "            x_hat = decoder(z_hat) # 通过解码器生成重构图像\n",
    "            mse_loss = criterion(x_hat, images) # 计算重构图像与原始图像的均方误差\n",
    "            #print('mse_loss:',mse_loss)\n",
    "            resx = [] \n",
    "            resy = []\n",
    "            tc = 0 # 固定类别\n",
    "            xbeg = dec_x[dec_y == tc]  # 从全局训练图像dec_x中选择标签等于c的所有样本\n",
    "            ybeg = dec_y[dec_y == tc]  # 从全局标签dec_y中选择标签等于c的所有样本\n",
    "            xlen = len(xbeg)\n",
    "            #print('xbeg:',xbeg.shape)\n",
    "            nsample = min(100, xlen)  # 生成样本数\n",
    "            ind = np.random.choice(list(range(xlen)), nsample, replace=False)  # 随机选择nsample个样本\n",
    "            xclass = xbeg[ind]  # 选择对应的图像\n",
    "            yclass = ybeg[ind]\n",
    "            xclen = len(xclass)\n",
    "            xcminus = np.arange(1,xclen) # 1 to xclen-1\n",
    "            xcplus = np.append(xcminus, 0 ) # 0 to xclen-2\n",
    "\n",
    "            xcnew = (xclass[[xcplus], :])  \n",
    "\n",
    "            xcnew = xcnew = xcnew.reshape(xcnew.shape[1], xcnew.shape[2], xcnew.shape[3], xcnew.shape[4]) # 1 to xclen-1, 0 to xclen-2\n",
    "            #print('xcnew:',xcnew.shape)\n",
    "\n",
    "            xcnew = torch.Tensor(xcnew)\n",
    "            xcnew = xcnew.to(device)\n",
    "            xclass = torch.Tensor(xclass)\n",
    "            xclass = xclass.to(device)\n",
    "            xclass = encoder(xclass)\n",
    "            xclass = xclass.detach().cpu().numpy()\n",
    "            xc_enc = (xclass[[xcplus],:])\n",
    "            xc_enc = np.squeeze(xc_enc)\n",
    "            xc_enc = torch.Tensor(xc_enc)\n",
    "            xc_enc = xc_enc.to(device)\n",
    "            #print('xc_enc:',xc_enc.shape)\n",
    "            ximg = decoder(xc_enc)\n",
    "            mse_loss2 = criterion(ximg, xcnew)\n",
    "            #print('mse_loss2:',mse_loss2)\n",
    "            combined_loss = mse_loss + mse_loss2\n",
    "            combined_loss.backward()\n",
    "\n",
    "            encoder_optim.step()\n",
    "            decoder_optim.step()\n",
    "\n",
    "            train_loss += combined_loss.item() * images.size(0)\n",
    "            tmse_loss += mse_loss.item() * images.size(0)\n",
    "            #print('train_loss:',train_loss)\n",
    "            #print('tmse_loss:',tmse_loss)\n",
    "            tdiscr_loss += mse_loss2.item() * images.size(0)\n",
    "            #print('tdiscr_loss:',tdiscr_loss)\n",
    "\n",
    "\n",
    "        # print training statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        tmse_loss = tmse_loss / len(train_loader.dataset)\n",
    "        tdiscr_loss = tdiscr_loss / len(train_loader.dataset)\n",
    "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
    "                  train_loss, tmse_loss, tdiscr_loss))  \n",
    "            # 打印当前epoch的损失信息\n",
    "        # store the best encoder and decoder models\n",
    "            # here, /crs5 is a reference to 5 way cross validation, but is not\n",
    "            # necessary for illustration purposes\n",
    "        if train_loss < best_loss:  \n",
    "            # 如果当前epoch的平均损失低于历史最佳损失，则保存模型\n",
    "            print('Saving..')\n",
    "            path_enc = 'DeepSMOTE_{}_bst_enc.pth'.format(fraction)\n",
    "            # 构造保存最佳编码器模型的文件路径\n",
    "            path_dec = 'DeepSMOTE_{}_bst_dec.pth'.format(fraction)\n",
    "            # 构造保存最佳解码器模型的文件路径\n",
    "            \n",
    "            torch.save(encoder.state_dict(), path_enc)  \n",
    "            # 保存编码器当前状态字典（权重参数）\n",
    "            torch.save(decoder.state_dict(), path_dec)  \n",
    "            # 保存解码器当前状态字典\n",
    "            \n",
    "            best_loss = train_loss  # 更新历史最佳损失值\n",
    "     # in addition, store the final model (may not be the best) for\n",
    "    # informational purposes\n",
    "    \n",
    "    path_enc = 'DS_{}_final_enc.pth'.format(fraction)  \n",
    "    # 构造保存最终编码器模型（可能不是最佳）的文件路径\n",
    "    path_dec = 'DS_{}_final_dec.pth'.format(fraction)  \n",
    "    # 构造保存最终解码器模型的文件路径\n",
    "    print(path_enc)\n",
    "    print(path_dec)\n",
    "    torch.save(encoder.state_dict(), path_enc)  # 保存最终编码器状态\n",
    "    torch.save(decoder.state_dict(), path_dec)  # 保存最终解码器状态\n",
    "    print()\n",
    "t1 = time.time()  # 记录当前fold训练结束时间\n",
    "print('total time(min): {:.2f}'.format((t1 - t0) / 60))  \n",
    "# 输出当前fold训练耗时（单位：分钟）\n",
    "\n",
    "t4 = time.time()  # 记录整个程序结束时的时间\n",
    "print('final time(min): {:.2f}'.format((t4 - t3) / 60))  \n",
    "# 输出整个程序运行的总耗时（单位：分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
