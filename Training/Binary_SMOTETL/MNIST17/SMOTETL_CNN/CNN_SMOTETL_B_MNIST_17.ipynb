{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/max/MasterThesis/Training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 1 in the final training set:  6742\n",
      "Number of label 7 in the final training set (after downsampling):  1348\n",
      "Number of label 1 in the final test set:  1135\n",
      "Number of label 7 in the final test set:  1028\n",
      "Total samples in final training set:  8090\n",
      "Total samples in final test set:  2163\n",
      "Number of batches in training set:  127\n",
      "Number of batches in test set:  34\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3608, 0.9922, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.8471, 0.9882, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.9922, 0.9882, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3961,\n",
      "          0.9922, 0.9882, 0.4627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0392, 0.7020,\n",
      "          1.0000, 0.8706, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882,\n",
      "          0.9922, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.9882,\n",
      "          0.9922, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.9647, 0.9882,\n",
      "          0.9451, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.9922, 0.9922,\n",
      "          0.6392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.8824, 0.9882, 0.9882,\n",
      "          0.4431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.8980, 0.9882, 0.9882, 0.9882,\n",
      "          0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1490, 0.6392, 0.9922, 0.9882, 0.9882, 0.9882,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0745, 0.6039, 0.9922, 0.9843, 0.9569, 0.9922, 0.9922,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6627, 0.9882, 0.9882, 0.2941, 0.6627, 0.9882, 0.8902,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.9176, 0.9882, 0.4980, 0.0000, 0.6627, 0.9882, 0.5451,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0157, 0.1098, 0.1098, 0.0118, 0.0510, 0.8078, 0.9882, 0.5451,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.9922, 0.9922, 0.3059,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.9882, 0.9882, 0.2078,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.9882, 0.9882, 0.5451,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.6980, 0.8392, 0.3059,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcdklEQVR4nO3dDXBU1fnH8ScgCS+SxPCSFwgIBMQKpBUhUl4EYXgpRYN0Ci0docPAgMERKC9NR95qZ1Jpiw4WwWktgapgcQQUnTgYIFALWKBIaYUSJhYoCShtNhCagMn9zzn8s81CAu6yybO79/uZObO5u/fsPbm5ub899569N8pxHEcAAGhkTRp7gQAAGAQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBBwhz777DOJioqSX/7yl0F7z927d9v3NI9ApCKA4Eq5ubl2B3/w4EGJRCdOnJC5c+fKN7/5TWnevLn9XU1QAqGEAAIi0L59+2TVqlVy6dIluf/++7WbA9SJAAIi0GOPPSalpaXy17/+VSZPnqzdHKBOBBBQj6tXr8qSJUukb9++EhcXJ61atZLBgwfLrl276q3zwgsvSOfOnaVFixbyyCOPyLFjx26a5/jx4/Kd73xHEhIS7OGxhx56SN55553btufKlSu27hdffHHbec17t27d+iv8loAeAgioR1lZmfz2t7+VoUOHyvPPPy/Lli2Tzz//XEaNGiVHjhy5af4NGzbYw15ZWVmSnZ1tw+fRRx+V8+fPe+f529/+Jg8//LB8+umn8uMf/1h+9atf2WDLzMyULVu23LI9H3/8sT2c9utf/7pBfl+gsd3V6EsEwsQ999xjT9xHR0d7n5s+fbr07NlTXnrpJXn11Vd95i8sLJSTJ09Khw4d7PTo0aMlIyPDhtfKlSvtc88884x06tRJ/vznP0tMTIx97qmnnpJBgwbJokWLZPz48Y36OwKa6AEB9WjatKk3fKqrq+Xf//63fPnll/aQ2eHDh2+a3/RiasLH6N+/vw2g999/306b+jt37pTvfve7dnCAOZRmysWLF22vyoTXv/71r3rbY3pi5v6RpicGRAICCLiF9evXS58+fey5mjZt2ki7du3kvffeE4/Hc9O83bt3v+m5Hj16eIc/mx6SCZDFixfb96ldli5daue5cOFCI/xWQGjgEBxQj9dee02mTp1qezYLFiyQ9u3b215RTk6OnDp1yu/3M70oY/78+bbHU5e0tLQ7bjcQLgggoB5vvfWWdO3aVd5++237Rc4aNb2VG5lDaDf6xz/+Iffee6/92byX0axZMxkxYkSDtRsIFxyCA+phejuGOWxW48CBA/ZLnnXZunWrzzkcM2rNzD9mzBg7bXpQ5jzOK6+8IsXFxTfVNyPsgjUMGwgH9IDgar/73e8kLy/vpufNaLVvf/vbtvdjRqaNHTtWioqKZO3atfK1r31NLl++XOfhMzOabdasWVJZWSkvvviiPW+0cOFC7zyrV6+28/Tu3duOqDO9IjNM24Ta2bNn5ZNPPqm3rSbQhg0bZntgtxuIYM5RmZF6xkcffWQfzfDt+Ph4W2bPnu3XegIaAgEEV1uzZk2dz5tzP6aUlJTYHssHH3xgg8ecF9q8eXOdFwl98sknpUmTJjZ4zGACMwrO7PSTk5O985j3MNefW758ub0enRkBZ3pG3/jGN+yXXoPlP//5jx3sUJv5zpFhvihLACEURDm1jy8AANBIOAcEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFSE3PeAzPWyzp07Z2+mVfvyJwCA8GC+3WOu+J6SkmK/Gxc2AWTCJzU1VbsZAIA7dObMGenYsWP4HILjNsIAEBlutz9vsAAy17wyVwE291ExN+Uy17H6KjjsBgCR4Xb78wYJoDfffFPmzZtnL5po7hyZnp5u73/CzbYAAF5OA+jfv7+TlZXlna6qqnJSUlKcnJyc29b1eDzm2nQUCoVCkfAuZn9+K0HvAV29elUOHTrkc8MtMwrCTNd1HxVz2fqysjKfAgCIfEEPIHOzrKqqKklMTPR53kybS9vfyNzeOC4uzlsYAQcA7qA+Ci47O9vePKummGF7AIDIF/TvAbVt29beytjc5bE2M52UlHTT/DExMbYAANwl6D2g6Oho6du3r+Tn5/tc3cBMDxgwINiLAwCEqQa5EoIZgj1lyhR56KGH7G2JzS2Ky8vL5Yc//GFDLA4AEIYaJIAmTpwon3/+ub3HvRl48PWvf13y8vJuGpgAAHCvKDMWW0KIGYZtRsMBAMKbGVgWGxsbuqPgAADuRAABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFXfpLBZAY/jBD34QUL3169f7XWfz5s1+15k0aZLfdRA56AEBAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQwcVIgQj27LPPBlTPcZygtwW4ET0gAIAKAggAEBkBtGzZMomKivIpPXv2DPZiAABhrkHOAT3wwAPy4Ycf/m8hd3GqCQDgq0GSwQROUlJSQ7w1ACBCNMg5oJMnT0pKSop07dpVJk+eLKdPn6533srKSikrK/MpAIDIF/QAysjIkNzcXMnLy5M1a9ZIUVGRDB48WC5dulTn/Dk5ORIXF+ctqampwW4SACAERTkNPOC/tLRUOnfuLCtXrpRp06bV2QMypYbpARFCQHAcP348oHppaWl+13nrrbf8rjNp0iS/6yB8eDweiY2Nrff1Bh8dEB8fLz169JDCwsI6X4+JibEFAOAuDf49oMuXL8upU6ckOTm5oRcFAHBzAM2fP18KCgrks88+kz/96U8yfvx4adq0qXzve98L9qIAAGEs6Ifgzp49a8Pm4sWL0q5dOxk0aJDs37/f/gwAQIMF0KZNm4L9lgAC1L1794DqcTFSNAauBQcAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEBFg9+QDkBwTJ8+XULZ4cOHtZuAMEMPCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACggqthAwpatmzpd53HHnvM7zpNmgT2GbOoqMjvOr///e8DWhbcix4QAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFVyMFFAwduxYv+uMGTPG7zrV1dUSiN/85jd+1ykuLg5oWXAvekAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUcDFSQEGPHj0klJ08eVK7CXABekAAABUEEAAgPAJoz549Mm7cOElJSZGoqCjZunWrz+uO48iSJUskOTlZWrRoISNGjKA7DwC48wAqLy+X9PR0Wb16dZ2vr1ixQlatWiVr166VAwcOSKtWrWTUqFFSUVHh76IAABHsrkDuyljfnRlN7+fFF1+UZ599Vh5//HH73IYNGyQxMdH2lCZNmnTnLQYARISgngMqKiqSkpISe9itRlxcnGRkZMi+ffvqrFNZWSllZWU+BQAQ+YIaQCZ8DNPjqc1M17x2o5ycHBtSNSU1NTWYTQIAhCj1UXDZ2dni8Xi85cyZM9pNAgCEWwAlJSXZx/Pnz/s8b6ZrXrtRTEyMxMbG+hQAQOQLagB16dLFBk1+fr73OXNOx4yGGzBgQDAXBQBw2yi4y5cvS2Fhoc/AgyNHjkhCQoJ06tRJ5syZIz/72c+ke/fuNpAWL15svzOUmZkZ7LYDANwUQAcPHpRhw4Z5p+fNm2cfp0yZIrm5ubJw4UL7XaEZM2ZIaWmpDBo0SPLy8qR58+bBbTkAIKxFOebLOyHEHLIzo+GAcNG3b1+/6+zdu9fvOtHR0X7XMR8GAzFkyBC/63zyyScBLQuRywwsu9V5ffVRcAAAdyKAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAhMftGAD4WrRokd91zJ2AG8M777wTUD2ubI3GQA8IAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACi5GCtTSq1cvv+tkZGT4XcdxHGkMhw8fbpTlAIGgBwQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFFyMFavnggw/8rpOYmCih6uTJk9pNAOpFDwgAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKLkaKkNejRw+/6yxevDigZSUlJfldx3EcCVXbt2/XbgJQL3pAAAAVBBAAIDwCaM+ePTJu3DhJSUmRqKgo2bp1q8/rU6dOtc/XLqNHjw5mmwEAbgyg8vJySU9Pl9WrV9c7jwmc4uJib9m4ceOdthMA4PZBCGPGjLHlVmJiYgI6mQsAcI8GOQe0e/duad++vdx3330ya9YsuXjxYr3zVlZWSllZmU8BAES+oAeQOfy2YcMGyc/Pl+eff14KCgpsj6mqqqrO+XNyciQuLs5bUlNTg90kAIAbvgc0adIk78+9e/eWPn36SLdu3WyvaPjw4TfNn52dLfPmzfNOmx4QIQQAka/Bh2F37dpV2rZtK4WFhfWeL4qNjfUpAIDI1+ABdPbsWXsOKDk5uaEXBQCI5ENwly9f9unNFBUVyZEjRyQhIcGW5cuXy4QJE+wouFOnTsnChQslLS1NRo0aFey2AwDcFEAHDx6UYcOGeadrzt9MmTJF1qxZI0ePHpX169dLaWmp/bLqyJEj5bnnnrOH2gAAqBHlhNiVFM0gBDMaDpGpTZs2ftcxIyX9NW3aNAlEdXW133UqKir8rtOyZUtpDE2bNm2U5QB18Xg8tzyvz7XgAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAACRcUtu4FZefvllv+uY+0v5K9CLvGdmZvpd58knn2yU36m4uNjvOkAoowcEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABRcjRcASExP9rjNs2DBpDM8991xA9d57771GuRhpIDZt2tQoywEaCz0gAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKrgYKQJ28eJFv+s8+OCD0hiKi4sDqte6dWu/63Tv3j2gZQFuRw8IAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACi5GioB9+eWXftc5e/ashLL4+Hi/66Snp0tj2Lt3b6MsB2gs9IAAACoIIABA6AdQTk6O9OvXz94zpX379pKZmSknTpzwmaeiokKysrKkTZs2cvfdd8uECRPk/PnzwW43AMBNAVRQUGDDZf/+/bJjxw65du2ajBw5UsrLy73zzJ07V959913ZvHmznf/cuXPyxBNPNETbAQBuGYSQl5fnM52bm2t7QocOHZIhQ4aIx+ORV199Vd544w159NFH7Tzr1q2T+++/34bWww8/HNzWAwDceQ7IBI6RkJBgH00QmV7RiBEjvPP07NlTOnXqJPv27avzPSorK6WsrMynAAAiX8ABVF1dLXPmzJGBAwdKr1697HMlJSUSHR1901DWxMRE+1p955Xi4uK8JTU1NdAmAQDcEEDmXNCxY8dk06ZNd9SA7Oxs25OqKWfOnLmj9wMARPAXUWfPni3bt2+XPXv2SMeOHb3PJyUlydWrV6W0tNSnF2RGwZnX6hITE2MLAMBd/OoBOY5jw2fLli2yc+dO6dKli8/rffv2lWbNmkl+fr73OTNM+/Tp0zJgwIDgtRoA4K4ekDnsZka4bdu2zX4XqOa8jjl306JFC/s4bdo0mTdvnh2YEBsbK08//bQNH0bAAQACDqA1a9bYx6FDh/o8b4ZaT5061f78wgsvSJMmTewXUM0It1GjRsnLL7/sz2IAAC4Q5ZjjaiHEDMM2PSlAQyCjMIuKiqQxBHIU4eDBgw3SFuCrMAPLzJGw+nAtOACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIABA+NwRFUDjmzhxot91uBo2Qhk9IACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACq4GClQS3Fxsd913n//fb/rpKWl+V1n7969ftcBQhk9IACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACqiHMdxJISUlZVJXFycdjMAAHfI4/FIbGxsva/TAwIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAQOgHUE5OjvTr109at24t7du3l8zMTDlx4oTPPEOHDpWoqCifMnPmzGC3GwDgpgAqKCiQrKws2b9/v+zYsUOuXbsmI0eOlPLycp/5pk+fLsXFxd6yYsWKYLcbABDm7vJn5ry8PJ/p3Nxc2xM6dOiQDBkyxPt8y5YtJSkpKXitBABEnCZ3ertVIyEhwef5119/Xdq2bSu9evWS7OxsuXLlSr3vUVlZaW/DXbsAAFzACVBVVZUzduxYZ+DAgT7Pv/LKK05eXp5z9OhR57XXXnM6dOjgjB8/vt73Wbp0qWOaQaFQKBSJqOLxeG6ZIwEH0MyZM53OnTs7Z86cueV8+fn5tiGFhYV1vl5RUWEbWVPM+2mvNAqFQqFIgweQX+eAasyePVu2b98ue/bskY4dO95y3oyMDPtYWFgo3bp1u+n1mJgYWwAA7uJXAJke09NPPy1btmyR3bt3S5cuXW5b58iRI/YxOTk58FYCANwdQGYI9htvvCHbtm2z3wUqKSmxz8fFxUmLFi3k1KlT9vVvfetb0qZNGzl69KjMnTvXjpDr06dPQ/0OAIBw5M95n/qO861bt86+fvr0aWfIkCFOQkKCExMT46SlpTkLFiy47XHA2sy82sctKRQKhSJ3XG6374/6/2AJGWYYtulRAQDCm/mqTmxsbL2vcy04AIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAICKkAsgx3G0mwAAaIT9ecgF0KVLl7SbAABohP15lBNiXY7q6mo5d+6ctG7dWqKionxeKysrk9TUVDlz5ozExsaKW7EermM9XMd6uI71EDrrwcSKCZ+UlBRp0qT+fs5dEmJMYzt27HjLecxKdfMGVoP1cB3r4TrWw3Wsh9BYD3FxcbedJ+QOwQEA3IEAAgCoCKsAiomJkaVLl9pHN2M9XMd6uI71cB3rIfzWQ8gNQgAAuENY9YAAAJGDAAIAqCCAAAAqCCAAgAoCCACgImwCaPXq1XLvvfdK8+bNJSMjQz7++GPtJjW6ZcuW2csT1S49e/aUSLdnzx4ZN26cvayH+Z23bt3q87oZyLlkyRJJTk6WFi1ayIgRI+TkyZPitvUwderUm7aP0aNHSyTJycmRfv362Ut1tW/fXjIzM+XEiRM+81RUVEhWVpa0adNG7r77bpkwYYKcP39e3LYehg4detP2MHPmTAklYRFAb775psybN8+ObT98+LCkp6fLqFGj5MKFC+I2DzzwgBQXF3vLH//4R4l05eXl9m9uPoTUZcWKFbJq1SpZu3atHDhwQFq1amW3D7MjctN6MEzg1N4+Nm7cKJGkoKDAhsv+/ftlx44dcu3aNRk5cqRdNzXmzp0r7777rmzevNnOb64t+cQTT4jb1oMxffp0n+3B/K+EFCcM9O/f38nKyvJOV1VVOSkpKU5OTo7jJkuXLnXS09MdNzOb7JYtW7zT1dXVTlJSkvOLX/zC+1xpaakTExPjbNy40XHLejCmTJniPP74446bXLhwwa6LgoIC79++WbNmzubNm73zfPrpp3aeffv2OW5ZD8YjjzziPPPMM04oC/ke0NWrV+XQoUP2sErtC5aa6X379onbmENL5hBM165dZfLkyXL69Glxs6KiIikpKfHZPsxFEM1hWjduH7t377aHZO677z6ZNWuWXLx4USKZx+OxjwkJCfbR7CtMb6D29mAOU3fq1CmitwfPDeuhxuuvvy5t27aVXr16SXZ2tly5ckVCSchdDftGX3zxhVRVVUliYqLP82b6+PHj4iZmp5qbm2t3LqY7vXz5chk8eLAcO3bMHgt2IxM+Rl3bR81rbmEOv5lDTV26dJFTp07JT37yExkzZozd8TZt2lQijbl1y5w5c2TgwIF2B2uYv3l0dLTEx8e7ZnuormM9GN///velc+fO9gPr0aNHZdGiRfY80dtvvy2hIuQDCP9jdiY1+vTpYwPJbGB/+MMfZNq0aaptg75JkyZ5f+7du7fdRrp162Z7RcOHD5dIY86BmA9fbjgPGsh6mDFjhs/2YAbpmO3AfDgx20UoCPlDcKb7aD693TiKxUwnJSWJm5lPeT169JDCwkJxq5ptgO3jZuYwrfn/icTtY/bs2bJ9+3bZtWuXz/3DzN/cHLYvLS11xfYwu571UBfzgdUIpe0h5APIdKf79u0r+fn5Pl1OMz1gwABxs8uXL9tPM+aTjVuZw01mx1J7+zB3hDSj4dy+fZw9e9aeA4qk7cOMvzA73S1btsjOnTvt3782s69o1qyZz/ZgDjuZc6WRtD04t1kPdTly5Ih9DKntwQkDmzZtsqOacnNznb///e/OjBkznPj4eKekpMRxkx/96EfO7t27naKiIuejjz5yRowY4bRt29aOgIlkly5dcv7yl7/YYjbZlStX2p//+c9/2td//vOf2+1h27ZtztGjR+1IsC5dujj//e9/HbesB/Pa/Pnz7Ugvs318+OGHzoMPPuh0797dqaiocCLFrFmznLi4OPt/UFxc7C1XrlzxzjNz5kynU6dOzs6dO52DBw86AwYMsCWSzLrNeigsLHR++tOf2t/fbA/mf6Nr167OkCFDnFASFgFkvPTSS3ajio6OtsOy9+/f77jNxIkTneTkZLsOOnToYKfNhhbpdu3aZXe4NxYz7LhmKPbixYudxMRE+0Fl+PDhzokTJxw3rQez4xk5cqTTrl07Owy5c+fOzvTp0yPuQ1pdv78p69at885jPng89dRTzj333OO0bNnSGT9+vN05u2k9nD592oZNQkKC/Z9IS0tzFixY4Hg8HieUcD8gAICKkD8HBACITAQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBAAQDf8HKoC+24Y/X9QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frac = [0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "frac = 0.2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist17_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist17_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist17_transforms, download=True)\n",
    "\n",
    "# 选取标签为 1 和 7 的索引\n",
    "indices1_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 1]\n",
    "indices7_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 7]\n",
    "\n",
    "indices1_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 1]\n",
    "indices7_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 7]\n",
    "\n",
    "# 获取训练集中标签为 1 和 7 的数据\n",
    "mnist1_train_data = full_train_datasets.data[indices1_train]\n",
    "mnist1_train_labels = torch.ones(len(indices1_train), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_train_data = full_train_datasets.data[indices7_train]\n",
    "mnist7_train_labels = torch.zeros(len(indices7_train), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 1 和 7 的数据\n",
    "mnist1_test_data = full_test_datasets.data[indices1_test]\n",
    "mnist1_test_labels = torch.ones(len(indices1_test), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_test_data = full_test_datasets.data[indices7_test]\n",
    "mnist7_test_labels = torch.zeros(len(indices7_test), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(frac * len(mnist1_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_7 = np.random.choice(len(mnist7_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist7_train_data = mnist7_train_data[selected_indices_7]\n",
    "fraction_mnist7_train_labels = mnist7_train_labels[selected_indices_7]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist1_train_data, fraction_mnist7_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist1_train_labels, fraction_mnist7_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist1_test_data, mnist7_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist1_test_labels, mnist7_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 1 in the final training set: \", len(mnist1_train_data))\n",
    "print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data))\n",
    "print(\"Number of label 1 in the final test set: \", len(mnist1_test_data))\n",
    "print(\"Number of label 7 in the final test set: \", len(mnist7_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n",
    "\n",
    "\n",
    "\n",
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (8090, 784)\n",
      "y_train.shape: (8090,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/Thesis/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/max/anaconda3/envs/Thesis/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/max/anaconda3/envs/Thesis/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({np.int64(0): 6742, np.int64(1): 6742})\n",
      "##############################################\n",
      "SMOTE done!\n",
      "X_train.shape: (13484, 784)\n",
      "y_train.shape: (13484,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  \n",
    "        flattened_img = img.flatten()           \n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img) # \n",
    "        y_train.append(label)\n",
    "\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in test_loader:\n",
    "    images, labels = batch  # images: (batch_size, 1,28  ,28 ), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           # flatten the image\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTETomek(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_train))\n",
    "print(\"##############################################\")\n",
    "print(\"SMOTE done!\")\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([13484, 784])\n",
      "y_train_tensor.shape: torch.Size([13484])\n",
      "总共恢复的图像数量： 13484\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_images.shape: torch.Size([13484, 28, 28])\n",
      "Number of batches in new training set:  211\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 假设 X_train 和 y_train 都是 numpy 数组\n",
    "# 注意：如果你的像素值范围在 0~255，建议在转换为 tensor 时进行归一化\n",
    "X_train_tensor= torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "print(\"X_train_tensor.shape:\", X_train_tensor.shape)\n",
    "print(\"y_train_tensor.shape:\", y_train_tensor.shape)\n",
    "\n",
    "# 假设 X_train_tensor 的形状为 (N, 784)，每个样本是一个扁平化的 28x28 图像\n",
    "reconstructed_images = []  # 用于保存恢复后的图像\n",
    "\n",
    "for i in range(len(X_train_tensor)):\n",
    "    flattened_img = X_train_tensor[i]        # 取出第 i 个样本，形状 (784,)\n",
    "    original_img = flattened_img.view(28, 28)  # 恢复为 (28, 28) 图像\n",
    "    reconstructed_images.append(original_img)  # 存入列表\n",
    "\n",
    "print(\"总共恢复的图像数量：\", len(reconstructed_images))\n",
    "\n",
    "# 可视化恢复后的图像\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, img in enumerate(reconstructed_images[:20]):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 创建 Dataset\n",
    "reconstructed_images = torch.stack(reconstructed_images)  # 将列表转换为张量\n",
    "print(\"reconstructed_images.shape:\", reconstructed_images.shape)  # (N, 28, 28)\n",
    "final_train_datasets = TensorDataset(reconstructed_images.unsqueeze(1).float(), y_train_tensor)\n",
    "\n",
    "# 使用新的 Dataset 构建新的 DataLoader\n",
    "new_train_loader = DataLoader(final_train_datasets, batch_size=64, shuffle=True)\n",
    "print(\"Number of batches in new training set: \", len(new_train_loader))\n",
    "\n",
    "# 获取一个 batch\n",
    "images, labels = next(iter(new_train_loader))\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.0358, Train Accuracy: 0.9915, Test Loss: 0.0335, Test Accuracy: 0.9884\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.9884\n",
      "TP: 1135.0\n",
      "FP: 25.0\n",
      "FN: 0.0\n",
      "TN: 1003.0\n",
      "Accuracy: 0.9884\n",
      "Misclassification rate: 0.0116\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9757\n",
      "Precision: 0.9784\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9878\n",
      "F-measure: 0.9891\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9827\n",
      "InvF0.5-measure: 0.9956\n",
      "AGF: 0.9891\n",
      "Balanced Accuracy: 0.9878\n",
      "Matthew's Correlation Coefficient: 0.9771\n",
      "Cohen's Kappa: 0.9768\n",
      "Youden's Index: 0.9757\n",
      "Positive Likelihood Ratio: 41.1200\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 2/50, Train Loss: 0.0057, Train Accuracy: 0.9981, Test Loss: 0.0318, Test Accuracy: 0.9908\n",
      "==> New best model saved at epoch 2 with Test Accuracy: 0.9908\n",
      "TP: 1135.0\n",
      "FP: 20.0\n",
      "FN: 0.0\n",
      "TN: 1008.0\n",
      "Accuracy: 0.9908\n",
      "Misclassification rate: 0.0092\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9805\n",
      "Precision: 0.9827\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9902\n",
      "F-measure: 0.9913\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9861\n",
      "InvF0.5-measure: 0.9965\n",
      "AGF: 0.9913\n",
      "Balanced Accuracy: 0.9903\n",
      "Matthew's Correlation Coefficient: 0.9816\n",
      "Cohen's Kappa: 0.9814\n",
      "Youden's Index: 0.9805\n",
      "Positive Likelihood Ratio: 51.4000\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 3/50, Train Loss: 0.0029, Train Accuracy: 0.9990, Test Loss: 0.0309, Test Accuracy: 0.9935\n",
      "==> New best model saved at epoch 3 with Test Accuracy: 0.9935\n",
      "TP: 1135.0\n",
      "FP: 14.0\n",
      "FN: 0.0\n",
      "TN: 1014.0\n",
      "Accuracy: 0.9935\n",
      "Misclassification rate: 0.0065\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9864\n",
      "Precision: 0.9878\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9932\n",
      "F-measure: 0.9939\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9902\n",
      "InvF0.5-measure: 0.9975\n",
      "AGF: 0.9939\n",
      "Balanced Accuracy: 0.9932\n",
      "Matthew's Correlation Coefficient: 0.9871\n",
      "Cohen's Kappa: 0.9870\n",
      "Youden's Index: 0.9864\n",
      "Positive Likelihood Ratio: 73.4286\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 4/50, Train Loss: 0.0029, Train Accuracy: 0.9991, Test Loss: 0.0105, Test Accuracy: 0.9972\n",
      "==> New best model saved at epoch 4 with Test Accuracy: 0.9972\n",
      "TP: 1135.0\n",
      "FP: 6.0\n",
      "FN: 0.0\n",
      "TN: 1022.0\n",
      "Accuracy: 0.9972\n",
      "Misclassification rate: 0.0028\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9942\n",
      "Precision: 0.9947\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9971\n",
      "F-measure: 0.9974\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9958\n",
      "InvF0.5-measure: 0.9989\n",
      "AGF: 0.9974\n",
      "Balanced Accuracy: 0.9971\n",
      "Matthew's Correlation Coefficient: 0.9945\n",
      "Cohen's Kappa: 0.9944\n",
      "Youden's Index: 0.9942\n",
      "Positive Likelihood Ratio: 171.3333\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 5/50, Train Loss: 0.0029, Train Accuracy: 0.9990, Test Loss: 0.0375, Test Accuracy: 0.9926\n",
      "Epoch: 6/50, Train Loss: 0.0017, Train Accuracy: 0.9993, Test Loss: 0.0085, Test Accuracy: 0.9972\n",
      "Epoch: 7/50, Train Loss: 0.0015, Train Accuracy: 0.9995, Test Loss: 0.0143, Test Accuracy: 0.9968\n",
      "Epoch: 8/50, Train Loss: 0.0005, Train Accuracy: 0.9999, Test Loss: 0.0281, Test Accuracy: 0.9949\n",
      "Epoch: 9/50, Train Loss: 0.0003, Train Accuracy: 0.9999, Test Loss: 0.0197, Test Accuracy: 0.9972\n",
      "Epoch: 10/50, Train Loss: 0.0009, Train Accuracy: 0.9998, Test Loss: 0.0305, Test Accuracy: 0.9954\n",
      "Epoch: 11/50, Train Loss: 0.0001, Train Accuracy: 1.0000, Test Loss: 0.0272, Test Accuracy: 0.9958\n",
      "Epoch: 12/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0330, Test Accuracy: 0.9949\n",
      "Epoch: 13/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0329, Test Accuracy: 0.9949\n",
      "Epoch: 14/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0325, Test Accuracy: 0.9949\n",
      "Epoch: 15/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0323, Test Accuracy: 0.9949\n",
      "Epoch: 16/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0333, Test Accuracy: 0.9949\n",
      "Epoch: 17/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0345, Test Accuracy: 0.9949\n",
      "Epoch: 18/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0317, Test Accuracy: 0.9954\n",
      "Epoch: 19/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0367, Test Accuracy: 0.9949\n",
      "Epoch: 20/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0336, Test Accuracy: 0.9954\n",
      "Epoch: 21/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0366, Test Accuracy: 0.9949\n",
      "Epoch: 22/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0351, Test Accuracy: 0.9954\n",
      "Epoch: 23/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0358, Test Accuracy: 0.9954\n",
      "Epoch: 24/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0369, Test Accuracy: 0.9949\n",
      "Epoch: 25/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0386, Test Accuracy: 0.9949\n",
      "Epoch: 26/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0402, Test Accuracy: 0.9949\n",
      "Epoch: 27/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0374, Test Accuracy: 0.9954\n",
      "Epoch: 28/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0384, Test Accuracy: 0.9949\n",
      "Epoch: 29/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0407, Test Accuracy: 0.9949\n",
      "Epoch: 30/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0391, Test Accuracy: 0.9949\n",
      "Epoch: 31/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0415, Test Accuracy: 0.9949\n",
      "Epoch: 32/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0415, Test Accuracy: 0.9949\n",
      "Epoch: 33/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0425, Test Accuracy: 0.9949\n",
      "Epoch: 34/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0412, Test Accuracy: 0.9949\n",
      "Epoch: 35/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0458, Test Accuracy: 0.9949\n",
      "Epoch: 36/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0447, Test Accuracy: 0.9949\n",
      "Epoch: 37/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0448, Test Accuracy: 0.9949\n",
      "Epoch: 38/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0463, Test Accuracy: 0.9949\n",
      "Epoch: 39/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0480, Test Accuracy: 0.9949\n",
      "Epoch: 40/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0447, Test Accuracy: 0.9949\n",
      "Epoch: 41/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0478, Test Accuracy: 0.9949\n",
      "Epoch: 42/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0467, Test Accuracy: 0.9949\n",
      "Epoch: 43/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0476, Test Accuracy: 0.9949\n",
      "Epoch: 44/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0506, Test Accuracy: 0.9949\n",
      "Epoch: 45/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0501, Test Accuracy: 0.9949\n",
      "Epoch: 46/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0503, Test Accuracy: 0.9949\n",
      "Epoch: 47/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0504, Test Accuracy: 0.9949\n",
      "Epoch: 48/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0516, Test Accuracy: 0.9949\n",
      "Epoch: 49/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0524, Test Accuracy: 0.9949\n",
      "Epoch: 50/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.0513, Test Accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 50\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(new_train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST17_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 3 in the final training set\": len(mnist1_train_data),\n",
    "            \"Number of label 4 in the final training set (after downsampling)\": len(fraction_mnist7_train_data),\n",
    "            \"Number of label 3 in the final test set\": len(mnist1_test_data),\n",
    "            \"Number of label 4 in the final test set\": len(mnist7_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"SMOTETL_CNNBinaryMNIST17_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
