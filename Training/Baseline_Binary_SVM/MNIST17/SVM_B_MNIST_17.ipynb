{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "def show_images(dataloader):\n",
    "    inputs, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = inputs[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_0.005', 'train_0.01', 'train_0.02', 'train_0.05', 'train_0.10', 'train_0.20', 'test'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "file_name = \"/Users/max/MasterThesisData/Binary17_MNIST_data_loaders.pkl\"\n",
    "with open(file_name, \"rb\") as f:\n",
    "    Binary17_MNIST = pickle.load(f)\n",
    "\n",
    "print(Binary17_MNIST.keys())\n",
    "train_data_0005 = Binary17_MNIST[\"train_0.005\"]\n",
    "show_images(train_data_0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_data_0005 = Binary17_MNIST[\"train_0.005\"]\n",
    "train_data_001 = Binary17_MNIST[\"train_0.01\"]\n",
    "train_data_002 = Binary17_MNIST[\"train_0.02\"]\n",
    "train_data_005 = Binary17_MNIST[\"train_0.05\"]\n",
    "train_data_010 = Binary17_MNIST[\"train_0.10\"]\n",
    "train_data_020 = Binary17_MNIST[\"train_0.20\"]\n",
    "test_data = Binary17_MNIST[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5\\%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.005\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 31\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (6296, 784)\n",
      "y_train.shape: (6296,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1026\n",
      "FP: 221\n",
      "FN: 2\n",
      "TN: 914\n",
      "Accuracy: 0.8969\n",
      "Misclassification rate: 0.1031\n",
      "Sensitivity (Recall): 0.9981\n",
      "Specificity: 0.8053\n",
      "Precision: 0.8228\n",
      "Negative Predictive Value: 0.9978\n",
      "G-mean: 0.8965\n",
      "F-measure: 0.9020\n",
      "Discriminant Power: 4.2231\n",
      "F2-measure: 0.8527\n",
      "InvF0.5-measure: 0.9573\n",
      "AGF: 0.9035\n",
      "Balanced Accuracy: 0.9017\n",
      "Matthew's Correlation Coefficient: 0.8119\n",
      "Cohen's Kappa: 0.7954\n",
      "Youden's Index: 0.8033\n",
      "Positive Likelihood Ratio: 5.1258\n",
      "Negative Likelihood Ratio: 0.0024\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_0005 # 0.005 0.5%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.005\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "# labels = np.unique(y_train)\n",
    "# print(\"Labels:\", labels)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.01\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 62\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (6327, 784)\n",
      "y_train.shape: (6327,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1025\n",
      "FP: 108\n",
      "FN: 3\n",
      "TN: 1027\n",
      "Accuracy: 0.9487\n",
      "Misclassification rate: 0.0513\n",
      "Sensitivity (Recall): 0.9971\n",
      "Specificity: 0.9048\n",
      "Precision: 0.9047\n",
      "Negative Predictive Value: 0.9971\n",
      "G-mean: 0.9498\n",
      "F-measure: 0.9486\n",
      "Discriminant Power: 4.4581\n",
      "F2-measure: 0.9218\n",
      "InvF0.5-measure: 0.9771\n",
      "AGF: 0.9490\n",
      "Balanced Accuracy: 0.9510\n",
      "Matthew's Correlation Coefficient: 0.9018\n",
      "Cohen's Kappa: 0.8976\n",
      "Youden's Index: 0.9019\n",
      "Positive Likelihood Ratio: 10.4786\n",
      "Negative Likelihood Ratio: 0.0032\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_001 # 0.01 1%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.01\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.02\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 125\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (6390, 784)\n",
      "y_train.shape: (6390,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1021\n",
      "FP: 54\n",
      "FN: 7\n",
      "TN: 1081\n",
      "Accuracy: 0.9718\n",
      "Misclassification rate: 0.0282\n",
      "Sensitivity (Recall): 0.9932\n",
      "Specificity: 0.9524\n",
      "Precision: 0.9498\n",
      "Negative Predictive Value: 0.9936\n",
      "G-mean: 0.9726\n",
      "F-measure: 0.9710\n",
      "Discriminant Power: 4.3992\n",
      "F2-measure: 0.9581\n",
      "InvF0.5-measure: 0.9842\n",
      "AGF: 0.9711\n",
      "Balanced Accuracy: 0.9728\n",
      "Matthew's Correlation Coefficient: 0.9445\n",
      "Cohen's Kappa: 0.9436\n",
      "Youden's Index: 0.9456\n",
      "Positive Likelihood Ratio: 20.8754\n",
      "Negative Likelihood Ratio: 0.0071\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_002 # 0.02 2%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.02\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.05\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 313\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (6578, 784)\n",
      "y_train.shape: (6578,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1022\n",
      "FP: 15\n",
      "FN: 6\n",
      "TN: 1120\n",
      "Accuracy: 0.9903\n",
      "Misclassification rate: 0.0097\n",
      "Sensitivity (Recall): 0.9942\n",
      "Specificity: 0.9868\n",
      "Precision: 0.9855\n",
      "Negative Predictive Value: 0.9947\n",
      "G-mean: 0.9905\n",
      "F-measure: 0.9898\n",
      "Discriminant Power: 5.2105\n",
      "F2-measure: 0.9872\n",
      "InvF0.5-measure: 0.9924\n",
      "AGF: 0.9898\n",
      "Balanced Accuracy: 0.9905\n",
      "Matthew's Correlation Coefficient: 0.9806\n",
      "Cohen's Kappa: 0.9805\n",
      "Youden's Index: 0.9809\n",
      "Positive Likelihood Ratio: 75.2250\n",
      "Negative Likelihood Ratio: 0.0059\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_005 # 0.05 5%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.05\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.10\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 626\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (6891, 784)\n",
      "y_train.shape: (6891,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1023\n",
      "FP: 18\n",
      "FN: 5\n",
      "TN: 1117\n",
      "Accuracy: 0.9894\n",
      "Misclassification rate: 0.0106\n",
      "Sensitivity (Recall): 0.9951\n",
      "Specificity: 0.9841\n",
      "Precision: 0.9827\n",
      "Negative Predictive Value: 0.9955\n",
      "G-mean: 0.9896\n",
      "F-measure: 0.9889\n",
      "Discriminant Power: 5.2096\n",
      "F2-measure: 0.9852\n",
      "InvF0.5-measure: 0.9926\n",
      "AGF: 0.9889\n",
      "Balanced Accuracy: 0.9896\n",
      "Matthew's Correlation Coefficient: 0.9788\n",
      "Cohen's Kappa: 0.9787\n",
      "Youden's Index: 0.9793\n",
      "Positive Likelihood Ratio: 62.7489\n",
      "Negative Likelihood Ratio: 0.0049\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_010 # 0.1 10%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.10\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary17_MNIST\n",
      "Imbalanced Ratio: 0.20\n",
      "1 is negative, 7 is positive\n",
      "Train_label1: 1253\n",
      "Train_label7: 6265\n",
      "Test_label1: 1135\n",
      "Test_label7: 1028\n",
      "X_train.shape: (7518, 784)\n",
      "y_train.shape: (7518,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "y_pred.shape: (2163,)\n",
      "TP: 1023\n",
      "FP: 9\n",
      "FN: 5\n",
      "TN: 1126\n",
      "Accuracy: 0.9935\n",
      "Misclassification rate: 0.0065\n",
      "Sensitivity (Recall): 0.9951\n",
      "Specificity: 0.9921\n",
      "Precision: 0.9913\n",
      "Negative Predictive Value: 0.9956\n",
      "G-mean: 0.9936\n",
      "F-measure: 0.9932\n",
      "Discriminant Power: 5.5961\n",
      "F2-measure: 0.9920\n",
      "InvF0.5-measure: 0.9944\n",
      "AGF: 0.9932\n",
      "Balanced Accuracy: 0.9936\n",
      "Matthew's Correlation Coefficient: 0.9870\n",
      "Cohen's Kappa: 0.9870\n",
      "Youden's Index: 0.9872\n",
      "Positive Likelihood Ratio: 125.4977\n",
      "Negative Likelihood Ratio: 0.0049\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_020 # 0.2 20%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary17_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.20\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"1 is negative, 7 is positive\")\n",
    "train_label1 = np.count_nonzero(y_train == 1)\n",
    "train_label7 = np.count_nonzero(y_train == 7)\n",
    "print(\"Train_label1:\", train_label1)\n",
    "print(\"Train_label7:\", train_label7)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label1 = np.count_nonzero(y_test == 1)\n",
    "test_label7 = np.count_nonzero(y_test == 7)\n",
    "print(\"Test_label1:\", test_label1)\n",
    "print(\"Test_label7:\", test_label7)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary17_got_confusion_matrix(y_test, y_pred)\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
