{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "def show_images(dataloader):\n",
    "    inputs, labels = next(iter(dataloader))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = inputs[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_0.005', 'train_0.01', 'train_0.02', 'train_0.05', 'train_0.10', 'train_0.20', 'test'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAI0CAYAAACakV+gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmnElEQVR4nO3dCZRV1Z0v4F1VIFOckEFBEQgQQgcaA+L8xCkmoh1donG9bo0azYvtEG3n7lY03R2HaGuIPjQaxeFlaEw0Go12d4RMIogG0xhBQBzAiIhEEGSoqvvWvd2yNMg+FPdfVBV831q1hPs7d59dJHfD75xbd9eUSqVSAgAACFQbORgAAECZogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcotGGvfLKK6mmpibdcMMNYWNOmTKlMmb5v8DWzRoCVMs6Qo6isYVNnDix8uKZMWNG2hYcccQRle/3nHPOaempwFbBGgJUyzrClqJo0Gx+8pOfpKlTp7b0NIA2yhoCVMs60rIUDZrF6tWr04UXXpguvfTSlp4K0AZZQ4BqWUdanqLRCq1duzZdeeWVacSIEWnHHXdMXbp0SQcddFCaPHnyRp9z0003pT333DN16tQpHXzwwWnWrFkbHDN79uw0duzY1LVr19SxY8c0cuTI9PDDDxfOZ9WqVZXnvv3225v8PVx//fWpsbExXXTRRZv8HCCGNQSolnWECIpGK7R8+fJ05513ptGjR6frrrsuXXXVVWnJkiXpyCOPTDNnztzg+HvvvTeNHz8+nX322enyyy+vvLAPPfTQtHjx4vXHvPDCC2nfffdNL774YrrsssvSjTfeWFk0jj322PTggw9m5zN9+vT06U9/Ot1yyy2bNP/XXnstXXvttZW5lxcbYMuyhgDVso4QosQWdffdd5fKf+zPPPPMRo+pr68vrVmz5iOPLVu2rNSzZ8/S6aefvv6xBQsWVMbq1KlTaeHChesfnzZtWuXxCy64YP1jhx12WGno0KGl1atXr3+ssbGxtP/++5cGDhy4/rHJkydXnlv+758/Nm7cuE36HseOHVsZ9wPl55599tmb9FwgzxoCVMs6wpbijkYrVFdXl7bbbrvKr8u3/N55551UX19fub343HPPbXB8+UpA79691/9+1KhRaZ999kmPPfZY5ffl5z/55JPpxBNPTCtWrKjcdix/LV26tHJlYu7cuWnRokUbnU/5akb5NVq+mlGkfEv1xz/+cbr55ps387sHqmUNAaplHSGCotFK3XPPPWnYsGGV9y/usssuqXv37unRRx9N77777gbHDhw4cIPHBg0aVPls67J58+ZVXpxXXHFFZZwPf40bN65yzFtvvVX1nMsL0HnnnZdOPvnktPfee1c9HrD5rCFAtawjVKtd1SMQ7v7770+nnnpq5erAxRdfnHr06FG5snDNNdek+fPnN3m88pWIsvIPQ5WvGnycAQMGVD3v8vsz58yZk26//fb1C8sHylcvyo+Vv5fOnTtXfS5g46whQLWsI0RQNFqhBx54IPXv37/y2c/lDWY+8EHj/3Pl241/7qWXXkp9+/at/Lo8Vln79u3T4Ycf3mzzLv/g1bp169IBBxzwsS/88lf5h73KixbQfKwhQLWsI0RQNFqh8hWDsvItxg9e3NOmTatsONOnT58Njn/ooYcq72v84L2R5U9mKB9//vnnV35fbu7l9zaW2/25556bdtttt488v/wpEuVbl7mPlCu/cLt161b52piTTjopDR8+fIPHjzvuuHTUUUelM888s/J+TaB5WUOAallHiKBotJC77rorPf744xs8/vWvfz0dffTRlSsI5RfFmDFj0oIFC9Jtt92WhgwZkt57772PvdV44IEHprPOOiutWbOm8sNP5fdSXnLJJeuPufXWWyvHDB06tPIiK19ZKH/kXHnBWLhwYXr++ec3OtfyYnHIIYdUrmLkfghr8ODBla+P069fP1cPIJA1BKiWdYTmpmi0kAkTJnzs4+X3Q5a/3nzzzUrrf+KJJyov6vJ7JSdNmpSmTJmywXNOOeWUVFtbW3lRl3+QqvxJD+XPmf7w1YLyGDNmzEhXX311mjhxYuVTHspXF/baa6/KhjxA22INAaplHaG51ZQ/47bZzwIAAGxTfLwtAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAtNyGfUfUnhB/dmCz/EfjpNQWWUeg9WiL64g1BNrWGuKOBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHDt4ocEgK1b7fAh2fznj30/m5+zaJ/Cc8w/rV82b5w1u3AMtj0vX7tfNq/vWl84xqCvPhM4I7Zl7mgAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOPtobGPqPjUgmz82+YFsfmSv4cEzAmh7lozcMZuvKzVk83/adXLhOQ45ZEQ27zmrcAi2Qn+8cP9sPuvkb2fzYXefFzwj2Dh3NAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcfTRamZfu2Dub9+y9LJvveNS8bN4wJ5+P/sqZ2XzKG3dk8xFXn5WKdLt9auExQPNpt+ce2XzV4J7ZfLsnZqSt3bIv75fNHx93Q8EIHbPpEd+4sHAOPe94qvAYtj3vj1iVzR98r0c273f1s4XnKDV5VvDx3NEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcPbRaGWO2WtmNh/f65lsfmQaXtX5V5+b36ejyLPjJhQec+Tt1c0RyKtpl1/a/3D5btn8uTE3Z/OT5x+fzdcd+lY2T40NqcXV1mXj3b+S33No59pO2Xxp4/vZvPsPZ6UijYVHsC264rM/y+arS+2zeWnd2tTa1XXvns1X/2WfbN7hNy8UnqNx9eomz4umc0cDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwtlHo5Up2ifjvDf2LhhhXVXnH9Xj1aqeD7S8ReePyuYvHfOdbL6wPr+DwyuP98vmvVPBPhpbQMPoz2bzjlf9MZv/6JP5vQoueTO/Fs+8ZK9s3m7Fs9kctmU9H8nvcfGFrg9k84n7jSg+iX00tgh3NAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcfTS2oHcfG7AJR83Mpr+/Yng275Dy+3BUu48H0LJqt9++8Jirvnp/Vee47Z0Ds3nva59KLa22S5dsPuKmGdn86h6/q+r8T1+b30fjE7+YVtX4sDWr22nHbP6t3o9l81EP/l02H7jU66+1cEcDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOBv2bUFPD3+g6jE6/NyGerA1q+3cOZuvfKBb4Rh/1WVZNv/q66Oz+eLTdys4w0upObXbY/fCY969Y7tsfnWPX2Xztxvez+afG39JNt/9keeyeWM2hc139TPHZPOpo2/J5vcdmn9+Wbsnn03NaclxQ7L5zrWTs/nR++dff9NO3q9wDqt2rcnmvcfn/wxKa9YUngN3NAAAgGagaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADC2Ucj0KvfKPrc5pmFYwy+86xsvmea2sRZAW3J0km9s/lvP/PDwjFWldZm8+k/HZrNd//DU6lZ1eQ/v372hcX7aMweemtVU3i5Pr9fSe9frsjmtbt0zeaNi97YrHlBkV4P5veQ2eXQTtm89h/eKjxHuxd3Tc2p45/yO82sKdVn85t2m5Y/wbUFeUrp87O/mM1r7+iYzRvso7FJ3NEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcPbRCDT7jAlVj7HnlW17n4xHV+U/dxq2djXt859x/9oPBmXzKcNuLzhD8Wts3+9emM37XFPdPhm1w4dk8zdG75TNu45ZlM1nD6luj4xNsW+HfP7IQxOz+Zixp2fzGvto0Ey2/+XcbP6llz+XzR8f/NPik8xIzaquJn+du6FU3T9PB/7ijMJjBp8zLz+H5curmgP/zR0NAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACGcfjSZY84W9C46YmU33nTm28Bw7pvznOrf091Dkym+dVnhMt9S29wqBnLnXfzabz96vaI+I6veiOfPEx7P5V776QlXjt0/T83lNXWpu60oN2fyfl4zM5kvWbp/NZ317aDbf4elp2RyaS8PSd7L5qmN2zOYDxxfvMXHC0Oey+Td75PMiDaXG1JwGf2NZ8Rzsk7FFuKMBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4eyj0QRv7lfdH1fXC4qPyX8yfPUu/s59zTp+t9vtkcHWbeXYfbL5hGO+l1rauTvPLThiu2y6prSuRffJ+MX7nQuPufi7X8nmva5/qmCEldl0h/R04RygNWr407vZfOApxXtgFO2odVTK7xdUrV1+u3M2v6/vL5r1/MRxRwMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADC2UejCWafMaGq5y8e3b3wmPY3VXWKdMWgn2XzMZ1XV3cC2Mb98tv5daAxlaoa/+erts/mP11a/Pn1T/90WDZvtyr//HU75PPnv/adVI3G1JjNr77itMIxev2gaJ8MoK16+neD8gcU7KOxdo/8PhxldfMWNHVabAZ3NAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcfTS2oGfHVbcPx6Y47429s/mV3xrZ4nOEtuzQr30tm782Jv/8Dm/VZfNP3vF6Nq9/fWH+BCml3VN+j4makZ/J5pf96PupGutKDdl8+G/OyOb9fvB0VecH2ra+D+fXkPePXZvNl55fsFlQSqnH5CZPi83gjgYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEUzQAAIBwNuxrgtFfOTObr+hT/R9nzylLsnnDnHkFI6zLpt3S1Gx+3pn5Df/G93qm4Pywdev4yPRsPuiR6savT9Wr3X77bL7sG6uz+QEd8+tIkRHfPT+b9/tGfkNBYNvW/t9nZPOXCxbKLw8o3vTziS69s3njypWFY1DMHQ0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIZx+NJujw8/weEh0CztGQWpZ9MqB1q+3SpfCYOf/8F/n8L2/N5mtK+X00Rtx9QTbv+0/5/XoAqjF7bc9sfu5OLxeO8cSA/fIHPP9iU6fFx3BHAwAACKdoAAAA4RQNAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMLZR4OP6Pfomdl8wZg7snndpwYUnqNhzrwmzwv4b7NvGVx4zEufy++TUeSkecdl875X2CcDaDmXPvmlbH78MbdtsbmQ544GAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhLOPBh/RdUbB/yXG5OPFo7sXnqObfTRgo97+P/tl8+cOv3ETRumQTb+1dEg2bzyhfhPOAdAyBv/f5dn8tS+sKhxjwfE7ZfM9n2/ytPgY7mgAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOPto8BHtv7ikpacAW7V2/fbM5uMvvTWbf6I2v0dG2R8b3s/mP/uXQ7L59kueLjwHQEtp/P3sbD533c6FY5x9/GPZ/NFv5PcFK9Xbb2hTuKMBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4eyjAbAFLT6sVzbft2CbjMZNOMeRd16Szfv86KlNGAWgbfraY6cXHjP3+AnZ/OH9Ds3mtb/+XZPntS1yRwMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADC2UcDYAvqsrghm8+vfz+bX/bqsYXn6DdhbjbPzwCgbfv0N18pPObXY/L/BJ5/wnbZfOCvmzytbZI7GgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMLZsI9Q279W39JTgFat4yPTs/m5jxxQMMKS0PkAbG3q31xceMw1nxyWzQemaYEz2na5owEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADh7KPBR+x41LxsfmQans07pGeCZwQAQFvkjgYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEqymVSqX4YQEAgG2ZOxoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUjTbslVdeSTU1NemGG24IG3PKlCmVMcv/BbZu1hCgWtYRchSNLWzixImVF8+MGTPStuCII46ofL/nnHNOS08FtgrWEKBa1hG2FEWDZvOTn/wkTZ06taWnAbRR1hCgWtaRlqVo0CxWr16dLrzwwnTppZe29FSANsgaAlTLOtLyFI1WaO3atenKK69MI0aMSDvuuGPq0qVLOuigg9LkyZM3+pybbrop7bnnnqlTp07p4IMPTrNmzdrgmNmzZ6exY8emrl27po4dO6aRI0emhx9+uHA+q1atqjz37bff3uTv4frrr0+NjY3poosu2uTnADGsIUC1rCNEUDRaoeXLl6c777wzjR49Ol133XXpqquuSkuWLElHHnlkmjlz5gbH33vvvWn8+PHp7LPPTpdffnnlhX3ooYemxYsXrz/mhRdeSPvuu2968cUX02WXXZZuvPHGyqJx7LHHpgcffDA7n+nTp6dPf/rT6ZZbbtmk+b/22mvp2muvrcy9vNgAW5Y1BKiWdYQQJbaou+++u1T+Y3/mmWc2ekx9fX1pzZo1H3ls2bJlpZ49e5ZOP/309Y8tWLCgMlanTp1KCxcuXP/4tGnTKo9fcMEF6x877LDDSkOHDi2tXr16/WONjY2l/fffvzRw4MD1j02ePLny3PJ///yxcePGbdL3OHbs2Mq4Hyg/9+yzz96k5wJ51hCgWtYRthR3NFqhurq6tN1221V+Xb7l984776T6+vrK7cXnnntug+PLVwJ69+69/vejRo1K++yzT3rssccqvy8//8knn0wnnnhiWrFiReW2Y/lr6dKllSsTc+fOTYsWLdrofMpXM8qv0fLVjCLlW6o//vGP080337yZ3z1QLWsIUC3rCBEUjVbqnnvuScOGDau8f3GXXXZJ3bt3T48++mh69913Nzh24MCBGzw2aNCgymdbl82bN6/y4rziiisq43z4a9y4cZVj3nrrrarnXF6AzjvvvHTyySenvffeu+rxgM1nDQGqZR2hWu2qHoFw999/fzr11FMrVwcuvvji1KNHj8qVhWuuuSbNnz+/yeOVr0SUlX8YqnzV4OMMGDCg6nmX3585Z86cdPvtt69fWD5QvnpRfqz8vXTu3LnqcwEbZw0BqmUdIYKi0Qo98MADqX///pXPfi5vMPOBDxr/nyvfbvxzL730Uurbt2/l1+Wxytq3b58OP/zwZpt3+Qev1q1blw444ICPfeGXv8o/7FVetIDmYw0BqmUdIYKi0QqVrxiUlW8xfvDinjZtWmXDmT59+mxw/EMPPVR5X+MH740sfzJD+fjzzz+/8vtycy+/t7Hc7s8999y02267feT55U+RKN+6zH2kXPmF261bt8rXxpx00klp+PDhGzx+3HHHpaOOOiqdeeaZlfdrAs3LGgJUyzpCBEWjhdx1113p8ccf3+Dxr3/96+noo4+uXEEovyjGjBmTFixYkG677bY0ZMiQ9N57733srcYDDzwwnXXWWWnNmjWVH34qv5fykksuWX/MrbfeWjlm6NChlRdZ+cpC+SPnygvGwoUL0/PPP7/RuZYXi0MOOaRyFSP3Q1iDBw+ufH2cfv36uXoAgawhQLWsIzQ3RaOFTJgw4WMfL78fsvz15ptvVlr/E088UXlRl98rOWnSpDRlypQNnnPKKaek2trayou6/INU5U96KH/O9IevFpTHmDFjRrr66qvTxIkTK5/yUL66sNdee1U25AHaFmsIUC3rCM2tpvwZt81+FgAAYJvi420BAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAACg5TbsO6L2hPizA5vlPxonpbbIOgKtR1tcR6wh0LbWEHc0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhGsXPyTbsnZ77F54zP96bE42v/PRw7N5/8umNnleAE1R2u8vs/nPH7g7m//VqKOzef2iNzZrXlCk3e69s3mPB5YXjrHw0gHZvPaXv2vyvNg2uaMBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4eyjQag//EOvwmMm7PjDbP6rCYOzeX2TZwXQNENv+a9s/r3l+T2DSiveC54R/I/aumz86vidsvnDezxSeIpv37oomz/xmR1SNWqH5f+ef21M12y+x7emZ/NSvX8ptBbuaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4+2i0MivH7pPN3/psvhv2+/upqTm127VnNn/s8zcXjvHVeV/K5qVXX2/yvACaZNTQbPy33SZk89Nmn5zNOy1fsFnTgiLt+u6RzZ/f576qz3Fwl9nZ/OcHfjWb1/5mZjZf2T+/D8fvz7klm4/a/6Rs3vPChlSk4aX5hcdQPXc0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJx9NFqZnc55LZvvt8Ob2fz3f5+a1bKD+2XzQe07Fo4xf3qfbN4/LWryvIA48/5132ze/8E12bz2179Lrd2w22Zl8551+b8e192T31OoU7KPBm3Xp9o3ZvP3+uT/rs/vklG96Z/9YTYffMbZhWP0v8Q+GluCOxoAAEA4RQMAAAinaAAAAOEUDQAAIJyiAQAAhFM0AACAcIoGAAAQzj4aW1C7PfcoPObb/X6Qzb/84inZvEt6OTWn4RfNrHqMHs/mP58baF51QwZl838//oZs/oVef5vN+/06tbiaEX+Rza/teV82H3zfBdm8//enbta8oC347p+GZPMdvv90as16Dlvc0lPgf7ijAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOHsoxGobueds/m5v/j3wjG61dVl847X7ZSaU7vde2fzC3v8KJvf8M5ehef4xKRpTZ4XsOlqOnTI5vPHdczmfdt1zua97s2PvyXU7bBDNj944vRs/kr9qmw+8J63s3lDNgVaUo/OKwqPWdO/bzavf/mVwBltu9zRAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEM6GfYHmXPmpbH5Ep18UjjHo3y7I5gMmP52aU32vrlVt5DX1nf6bcJbFTZwV0BS1e+6ezWcdeHc2P2TW2Gze5dezs3ljan5vfPkz2fzvuk7O5qPPvzCbf+JFG4tCc1nVPb85cbUmffKJwmMefeIT2fw7p52YzWt/M7PJ89oWuaMBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4eyj0QTv/s2+2XzG2H/N5tct3avwHH0fWZfN6wb0y+YN8xakarz+ue2rev5eO71eeMy0XXbN5g1L36lqDrBVGzW08JDD7/ptNp/8fsds3vGqHbJ544rq1pkia48cWXjMf17yrWz+pfnHZvNPTLJPBmxMt3bLs3nDIaOz+fwv5f95+YPP3VIwg5rU3MZ0fi9/wN3/lo0vm3hqNt/jX57anGltddzRAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHD20fiQmvbbZfNT//6RbL5Dbf6z6f9mp2cL53DpfS9m8/rUkM3vfLd/Nq9Ljdn8iC7XZ/OUOmfTf+w2q+D5KR3+w4HZfLsj7KPBtuu9E/bJ5vtfPr1wjCEdF2Xzf/jmGdm869SpqSW9elTxX01/WNclm79/zi4FIyxp4qxg2/HX27+Vz++/s8ozNP8+Gc29z8ZFn1m5xebSlrmjAQAAhFM0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOHso/EhNdu1z+YDO7xZ1fi96/J7UGyK363Jd8Pu7ZZn8+O7LCs4Q3VzfGZNqfCY5ZN6ZfNu6dWq5gBteZ+MO791UzZf0lj8Gv2nU07N5l1/07L7ZMy7ad9sPumvxheO8afGTtl8VZ8dsnnH3xeeAtiGXbZ4RDbvfU9+7zX+mzsaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEM4+Gh/SuHJlNr/+k0PzeWr9Lr3tS9l83jG3ZfPP3HFONu9z1VOFc+iWWvYz/KFZjcqvE/tfPj2bD2rfMZu/s6axcAqvnVtwzLnDUjXu2PvebP6/8t9Caig9F/BX07ps2n78d7P5v/xs+CacA1qhNWuz8S/e75DND+u0JnhCbdNfv3J4Nn/38/k1ZrsVzwTPaOvkjgYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEs4/GNqa2S/5zoYt0+31D2FygTaqty8Z11y3N5t/sOSObF+2SsW+HmoIjUpp14N2pJTWU8nP8r7X5dWh1qfivprP+66+zea/z3y8Y4dXCc0BrVL/ojWx+/ZknZ/PGO/5f4TmO6FT0+qnOfSt2zeYnb/9mam5z3+mWzbuteKnZ57AtcEcDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwtlHYxszY/St2fylgm02dnjqlWxevzmTgjakXa/8578/NOjhqsb/6uujs/mC5bsUjvH6H/Jz3OV3+X0uVvbK5zPP+U42P27eUdm8/tg12bxh2bJUpEeanT9H4Qiwdaqb/Fw2H//FYwvHuKF7l9ScVuzRIZuffG3+3yq0He5oAAAA4RQNAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACGfDvq1MzcjPZPOd62Zm86vfGpnNG5ev2Kx5wdai/o03s/mxo46pavyGt5dm8w5r8ptmlg1I+WPqdumazXd/sC6bv7guv7PnuqPy60TjypXZHGg+DS/MKTwmvwJUr8Oxo5r5DLQW7mgAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOPtobGXmnNE5mzeUGrP5b2/ZO5t3XTV1s+YFW43Ghmxcv+iN1NrN/U6fbP6HT34vm+//jxdk864rrRMAuKMBAAA0A0UDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEM4+Gm1Mu/59s/l/fuFfs/n3lg/K5j1++cdsXp9NgdbgndP2y+azD741mx92xteyedef2ycD2HydX1+ZzX+9Ov/P04M6Vv+vkUN7z83mL3Tvns0bliypeg7bAnc0AACAcIoGAAAQTtEAAADCKRoAAEA4RQMAAAinaAAAAOEUDQAAIJx9NNqYne//Uzbv265zNr/+Z1/M5p982efjQ2vWcMhnC4+58YoJ2XzkjP+dzXf77Zz8HApnALBxpWdfyOb3Ldk/mx+0x6+qnsO1PZ/N5mN2Pzk/gH00Nok7GgAAQDhFAwAACKdoAAAA4RQNAAAgnKIBAACEUzQAAIBwigYAABDOPhqtTLtde2bz03r+Zzafsrp9Nh847vls3phNgZb2+tfqC495/N1h2bzHF2dnc/tkABDBHQ0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIZx+NVmbuTbtm89Ed12XzQf/2t9l8wKqnN2tewJbx0vdGZvPr9ppUOMY9nz+k4IhXmjgrgC3nyeeG5A/Y41dbaipUyR0NAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACGcfjVbmzKG/yebLGt/P5p+6dXE2b9isWQFR3jthn2x+4menZfM7Tzuu8Bw1L89s8rwAWouadfnr4HU1rpO3Ff6XAgAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEK6mVCqVNuXAI2pPiD87sFn+o3FSaousI9B6tMV1xBoCbWsNcUcDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwikaAABAOEUDAAAIp2gAAADhFA0AACCcogEAAIRTNAAAgHCKBgAAEE7RAAAAwtWUSqVS/LAAAMC2zB0NAAAgnKIBAACEUzQAAIBwigYAABBO0QAAAMIpGgAAQDhFAwAACKdoAAAA4RQNAAAgRfv/wuVknvxW1vIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "file_name = \"/Users/max/MasterThesisData/Binary_MNIST_data_loaders.pkl\"\n",
    "with open(file_name, \"rb\") as f:\n",
    "    Binary_MNIST = pickle.load(f)\n",
    "\n",
    "print(Binary_MNIST.keys())\n",
    "train_data_0005 = Binary_MNIST[\"train_0.005\"]\n",
    "show_images(train_data_0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_data_0005 = Binary_MNIST[\"train_0.005\"]\n",
    "train_data_001 = Binary_MNIST[\"train_0.01\"]\n",
    "train_data_002 = Binary_MNIST[\"train_0.02\"]\n",
    "train_data_005 = Binary_MNIST[\"train_0.05\"]\n",
    "train_data_010 = Binary_MNIST[\"train_0.10\"]\n",
    "train_data_020 = Binary_MNIST[\"train_0.20\"]\n",
    "test_data = Binary_MNIST[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5\\%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.005\n",
      "3 is negative, 4 is positive\n",
      "Train_label1: 29\n",
      "Train_label7: 5842\n",
      "Test_label1: 1010\n",
      "Test_label7: 982\n",
      "X_train.shape: (5871, 784)\n",
      "y_train.shape: (5871,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 982\n",
      "FP: 120\n",
      "FN: 0\n",
      "TN: 890\n",
      "Accuracy: 0.9398\n",
      "Misclassification rate: 0.0602\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8812\n",
      "Precision: 0.8911\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9387\n",
      "F-measure: 0.9424\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9109\n",
      "InvF0.5-measure: 0.9761\n",
      "AGF: 0.9430\n",
      "Balanced Accuracy: 0.9406\n",
      "Matthew's Correlation Coefficient: 0.8861\n",
      "Cohen's Kappa: 0.8797\n",
      "Youden's Index: 0.8812\n",
      "Positive Likelihood Ratio: 8.4167\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_0005 # 0.005 0.5%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.005\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "# labels = np.unique(y_train)\n",
    "# print(\"Labels:\", labels)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.01\n",
      "3 is negative, 4 is positive\n",
      "Train_label3: 58\n",
      "Train_label4: 5842\n",
      "Test_label3: 1010\n",
      "Test_label4: 982\n",
      "X_train.shape: (5900, 784)\n",
      "y_train.shape: (5900,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 981\n",
      "FP: 82\n",
      "FN: 1\n",
      "TN: 928\n",
      "Accuracy: 0.9583\n",
      "Misclassification rate: 0.0417\n",
      "Sensitivity (Recall): 0.9990\n",
      "Specificity: 0.9188\n",
      "Precision: 0.9229\n",
      "Negative Predictive Value: 0.9989\n",
      "G-mean: 0.9581\n",
      "F-measure: 0.9594\n",
      "Discriminant Power: 5.1356\n",
      "F2-measure: 0.9371\n",
      "InvF0.5-measure: 0.9828\n",
      "AGF: 0.9597\n",
      "Balanced Accuracy: 0.9589\n",
      "Matthew's Correlation Coefficient: 0.9198\n",
      "Cohen's Kappa: 0.9167\n",
      "Youden's Index: 0.9178\n",
      "Positive Likelihood Ratio: 12.3045\n",
      "Negative Likelihood Ratio: 0.0011\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_001 # 0.01 1%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.01\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.02\n",
      "3 is negative, 4 is positive\n",
      "Train_label3: 116\n",
      "Train_label4: 5842\n",
      "Test_label3: 1010\n",
      "Test_label4: 982\n",
      "X_train.shape: (5958, 784)\n",
      "y_train.shape: (5958,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 982\n",
      "FP: 52\n",
      "FN: 0\n",
      "TN: 958\n",
      "Accuracy: 0.9739\n",
      "Misclassification rate: 0.0261\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9485\n",
      "Precision: 0.9497\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9739\n",
      "F-measure: 0.9742\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9594\n",
      "InvF0.5-measure: 0.9895\n",
      "AGF: 0.9743\n",
      "Balanced Accuracy: 0.9743\n",
      "Matthew's Correlation Coefficient: 0.9491\n",
      "Cohen's Kappa: 0.9478\n",
      "Youden's Index: 0.9485\n",
      "Positive Likelihood Ratio: 19.4231\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_002 # 0.02 2%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.02\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.05\n",
      "3 is negative, 4 is positive\n",
      "Train_label3: 292\n",
      "Train_label4: 5842\n",
      "Test_label3: 1010\n",
      "Test_label4: 982\n",
      "X_train.shape: (6134, 784)\n",
      "y_train.shape: (6134,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 982\n",
      "FP: 31\n",
      "FN: 0\n",
      "TN: 979\n",
      "Accuracy: 0.9844\n",
      "Misclassification rate: 0.0156\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9693\n",
      "Precision: 0.9694\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9845\n",
      "F-measure: 0.9845\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9754\n",
      "InvF0.5-measure: 0.9937\n",
      "AGF: 0.9845\n",
      "Balanced Accuracy: 0.9847\n",
      "Matthew's Correlation Coefficient: 0.9694\n",
      "Cohen's Kappa: 0.9689\n",
      "Youden's Index: 0.9693\n",
      "Positive Likelihood Ratio: 32.5806\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_005 # 0.05 5%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.05\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.10\n",
      "3 is negative, 4 is positive\n",
      "Train_label3: 584\n",
      "Train_label4: 5842\n",
      "Test_label3: 1010\n",
      "Test_label4: 982\n",
      "X_train.shape: (6426, 784)\n",
      "y_train.shape: (6426,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 980\n",
      "FP: 23\n",
      "FN: 2\n",
      "TN: 987\n",
      "Accuracy: 0.9874\n",
      "Misclassification rate: 0.0126\n",
      "Sensitivity (Recall): 0.9980\n",
      "Specificity: 0.9772\n",
      "Precision: 0.9771\n",
      "Negative Predictive Value: 0.9980\n",
      "G-mean: 0.9875\n",
      "F-measure: 0.9874\n",
      "Discriminant Power: 5.4877\n",
      "F2-measure: 0.9812\n",
      "InvF0.5-measure: 0.9937\n",
      "AGF: 0.9874\n",
      "Balanced Accuracy: 0.9876\n",
      "Matthew's Correlation Coefficient: 0.9751\n",
      "Cohen's Kappa: 0.9749\n",
      "Youden's Index: 0.9752\n",
      "Positive Likelihood Ratio: 43.8236\n",
      "Negative Likelihood Ratio: 0.0021\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_010 # 0.1 10%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.10\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Binary_MNIST\n",
      "Imbalanced Ratio: 0.20\n",
      "3 is negative, 4 is positive\n",
      "Train_label3: 1168\n",
      "Train_label4: 5842\n",
      "Test_label3: 1010\n",
      "Test_label4: 982\n",
      "X_train.shape: (7010, 784)\n",
      "y_train.shape: (7010,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n",
      "y_pred.shape: (1992,)\n",
      "TP: 982\n",
      "FP: 15\n",
      "FN: 0\n",
      "TN: 995\n",
      "Accuracy: 0.9925\n",
      "Misclassification rate: 0.0075\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9851\n",
      "Precision: 0.9850\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9925\n",
      "F-measure: 0.9924\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9879\n",
      "InvF0.5-measure: 0.9970\n",
      "AGF: 0.9924\n",
      "Balanced Accuracy: 0.9926\n",
      "Matthew's Correlation Coefficient: 0.9851\n",
      "Cohen's Kappa: 0.9849\n",
      "Youden's Index: 0.9851\n",
      "Positive Likelihood Ratio: 67.3333\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train_DataLoader = train_data_020 # 0.2 20%\n",
    "Test_DataLoader = test_data\n",
    "print(\"Dataset: Binary_MNIST\")\n",
    "print(\"Imbalanced Ratio: 0.20\")\n",
    "X_train = [] # features\n",
    "y_train = [] # labels\n",
    "\n",
    "for batch in Train_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  (1, 28, 28)\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img)\n",
    "        y_train.append(label)\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in Test_DataLoader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           #  (784,)\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print(\"3 is negative, 4 is positive\")\n",
    "train_label3 = np.count_nonzero(y_train == 3)\n",
    "train_label4 = np.count_nonzero(y_train == 4)\n",
    "print(\"Train_label3:\", train_label3)\n",
    "print(\"Train_label4:\", train_label4)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "test_label3 = np.count_nonzero(y_test == 3)\n",
    "test_label4 = np.count_nonzero(y_test == 4)\n",
    "print(\"Test_label3:\", test_label3)\n",
    "print(\"Test_label4:\", test_label4)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "### Metrics\n",
    "import self_metrics\n",
    "TP, FP, FN, TN = self_metrics.Binary_got_cofusion_matrix(y_test, y_pred, labels = [4,3])\n",
    "metrics = self_metrics.Binary_got_metrics(TP, FP, FN, TN)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
