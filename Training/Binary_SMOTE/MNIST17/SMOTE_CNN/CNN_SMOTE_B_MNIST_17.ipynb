{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/max/MasterThesis/Training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 1 in the final training set:  6742\n",
      "Number of label 7 in the final training set (after downsampling):  33\n",
      "Number of label 1 in the final test set:  1135\n",
      "Number of label 7 in the final test set:  1028\n",
      "Total samples in final training set:  6775\n",
      "Total samples in final test set:  2163\n",
      "Number of batches in training set:  106\n",
      "Number of batches in test set:  34\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0118, 0.6431, 0.9961, 0.7843, 0.0235,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.6275, 0.9922, 0.9922, 0.7569, 0.0235,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2314, 0.9333, 0.9922, 0.9922, 0.5529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1569, 0.9098, 0.9922, 0.9922, 0.7882, 0.2392, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0392, 0.2784, 0.9294, 0.9922, 0.9922, 0.4431, 0.0275, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6000, 0.9922, 0.9922, 0.9922, 0.4392, 0.0353, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627,\n",
      "          0.9216, 0.9922, 0.9922, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 0.9176,\n",
      "          0.9922, 0.9922, 0.6627, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.9176, 0.9922,\n",
      "          0.9922, 0.9216, 0.1294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9922, 0.9922,\n",
      "          0.7765, 0.1804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0471, 0.2706, 0.6667, 0.9922, 0.7882,\n",
      "          0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0392, 0.4627, 0.8157, 0.9922, 0.9922, 0.6588, 0.0549,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0235, 0.6078, 0.9922, 0.9922, 0.9216, 0.1804, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0353, 0.6392, 0.9333, 0.9922, 0.9255, 0.2706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0980, 0.9922, 0.9922, 0.9922, 0.6196, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588,\n",
      "          0.8863, 0.9922, 0.9922, 0.6510, 0.0392, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.7725,\n",
      "          0.9922, 0.9922, 0.8588, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 0.9647,\n",
      "          0.9922, 0.9922, 0.3961, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.9922,\n",
      "          0.9922, 0.9922, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.7804,\n",
      "          0.9451, 0.2118, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAActElEQVR4nO3dC3BU1R3H8X9AWMIjieGVBALyNCqPWl6mPATJEFBRkLaizBQ6FgokjkABG6e8+pgU2qqDpUCnSmRUQBweSp10MECwloeANKVVSmgooRBQMBsIJcFwO+cw2bKQgBs2+W/2fj8zZza7e8/uyc3N/e259+y5EY7jOAIAQB1rUNdvCACAQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAG36dixYxIRESG//vWvg/aaO3bssK9pboFwRQDBlbKysuwOft++fRKODh8+LDNnzpRvfetb0qRJE/u7mqAEQgkBBIShXbt2ydKlS+X8+fNyzz33aDcHqBIBBIShxx57TIqLi+Vvf/ubTJgwQbs5QJUIIKAa5eXlMn/+fOnTp49ER0dLs2bNZPDgwbJ9+/Zq67z00kvSsWNHiYyMlAcffFAOHTp0wzKfffaZfPvb35bY2Fh7eKxv377y7rvv3rI9Fy9etHW/+OKLWy5rXrtFixZf47cE9BBAQDVKSkrkD3/4gwwdOlQWL14sCxculM8//1xSU1Pl4MGDNyy/evVqe9grLS1NMjIybPg89NBDcvr0ad8yf//73+WBBx6QTz/9VH784x/Lb37zGxtsY8aMkY0bN960PXv37rWH037729/Wyu8L1LU76vwdgXrizjvvtCfuGzdu7Hts8uTJkpSUJK+88oq8+uqrfsvn5+fLkSNHpF27dvb+yJEjZcCAATa8XnzxRfvYc889Jx06dJCPP/5YPB6PfWz69OkyaNAgef7552Xs2LF1+jsCmugBAdVo2LChL3yuXLki586dk6+++soeMjtw4MANy5teTGX4GP3797cB9P7779v7pv62bdvku9/9rh0cYA6lmXL27FnbqzLh9Z///Kfa9piemLl+pOmJAeGAAAJu4vXXX5devXrZczUtW7aU1q1byx//+Efxer03LNutW7cbHuvevbtv+LPpIZkAmTdvnn2da8uCBQvsMmfOnKmD3woIDRyCA6rxxhtvyKRJk2zPZs6cOdKmTRvbK8rMzJSjR48G/HqmF2XMnj3b9niq0rVr19tuN1BfEEBANd555x3p3LmzbNiwwX6Rs1Jlb+V65hDa9f75z3/KXXfdZX82r2U0atRIUlJSaq3dQH3BITigGqa3Y5jDZpX27Nljv+RZlU2bNvmdwzGj1szyo0aNsvdND8qcx1m5cqWcOnXqhvpmhF2whmED9QE9ILjaa6+9JtnZ2Tc8bkarPfroo7b3Y0amPfLII1JQUCArVqyQe++9Vy5cuFDl4TMzmm3atGlSVlYmL7/8sj1vNHfuXN8yy5Yts8v07NnTjqgzvSIzTNuE2okTJ+Svf/1rtW01gTZs2DDbA7vVQARzjsqM1DM++ugje2uGb8fExNiSnp4e0HoCagMBBFdbvnx5lY+bcz+mFBUV2R7Ln/70Jxs85rzQ+vXrq5wk9Hvf+540aNDABo8ZTGBGwZmdfnx8vG8Z8xpm/rlFixbZ+ejMCDjTM7r//vvtl16D5csvv7SDHa5lvnNkmC/KEkAIBRHOtccXAACoI5wDAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqQu57QGa+rJMnT9qLaV07/QkAoH4w3+4xM74nJCTY78bVmwAy4ZOYmKjdDADAbSosLJT27dvXn0NwXEYYAMLDrfbntRZAZs4rMwuwuY6KuSiXmcfq6+CwGwCEh1vtz2slgNatWyezZs2ykyaaK0f27t3bXv+Ei20BAHycWtC/f38nLS3Nd7+iosJJSEhwMjMzb1nX6/WauekoFAqFIvW7mP35zQS9B1ReXi779+/3u+CWGQVh7ld1HRUzbX1JSYlfAQCEv6AHkLlYVkVFhbRt29bvcXPfTG1/PXN54+joaF9hBBwAuIP6KLiMjAx78azKYobtAQDCX9C/B9SqVSt7KWNzlcdrmftxcXE3LO/xeGwBALhL0HtAjRs3lj59+khOTo7f7AbmfnJycrDfDgBQT9XKTAhmCPbEiROlb9++9rLE5hLFpaWl8v3vf7823g4AUA/VSgA9+eST8vnnn9tr3JuBB9/4xjckOzv7hoEJAAD3ijBjsSWEmGHYZjQcAKB+MwPLoqKiQncUHADAnQggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCouEPnbQFApGHDhgHXWb16dcB1nn76aamJvXv3Blxn8ODBAdcpLy8XN6IHBABQQQABAMIjgBYuXCgRERF+JSkpKdhvAwCo52rlHNB9990nH3zwwf/f5A5ONQEA/NVKMpjAiYuLq42XBgCEiVo5B3TkyBFJSEiQzp07y4QJE+T48ePVLltWViYlJSV+BQAQ/oIeQAMGDJCsrCzJzs6W5cuXS0FBgR2WeP78+SqXz8zMlOjoaF9JTEwMdpMAAG4IoFGjRsl3vvMd6dWrl6Smpsr7778vxcXF8vbbb1e5fEZGhni9Xl8pLCwMdpMAACGo1kcHxMTESPfu3SU/P7/K5z0ejy0AAHep9e8BXbhwQY4ePSrx8fG1/VYAADcH0OzZsyU3N1eOHTsmf/nLX2Ts2LF2uo2nnnoq2G8FAKjHgn4I7sSJEzZszp49K61bt5ZBgwbJ7t277c8AANRaAK1duzbYLwkgTL322msB16nJ0RTHcaQmzNdEUHuYCw4AoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAEB4XpAOgDsMHDgw4DqPPfaYhLJ9+/YFXKe8vLxW2hKO6AEBAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQwGzaAGyQlJQVcZ8OGDQHXiY6OllCd1bqmvxO+PnpAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVDAZKRDGmjZtWqN6HTt2DLhOo0aNJFStWbOmRvU+/vjjoLcF/0cPCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAomIwXC2Msvv1yjej/4wQ8kVM2aNSvgOitXrqzRe5WVldWoHr4eekAAABUEEACgfgTQzp07ZfTo0ZKQkCARERGyadMmv+cdx5H58+dLfHy8REZGSkpKihw5ciSYbQYAuDGASktLpXfv3rJs2bIqn1+yZIksXbpUVqxYIXv27JFmzZpJamqqXLp0KRjtBQC4dRDCqFGjbKmK6f2Yk54/+clP5PHHH7ePrV69Wtq2bWt7SuPHj7/9FgMAwkJQzwEVFBRIUVGRPexWKTo6WgYMGCC7du2qdpRJSUmJXwEAhL+gBpAJH8P0eK5l7lc+d73MzEwbUpUlMTExmE0CAIQo9VFwGRkZ4vV6faWwsFC7SQCA+hZAcXFx9vb06dN+j5v7lc9dz+PxSFRUlF8BAIS/oAZQp06dbNDk5OT4HjPndMxouOTk5GC+FQDAbaPgLly4IPn5+X4DDw4ePCixsbHSoUMHmTFjhvz85z+Xbt262UCaN2+e/c7QmDFjgt12AICbAmjfvn0ybNiwG+ZlmjhxomRlZcncuXPtd4WmTJkixcXFMmjQIMnOzpYmTZoEt+UAgHotwjFf3gkh5pCdGQ0HwN/w4cMDrrNu3boavZc5olEXPvzww4DrPPzwwwHXMR+KUffMwLKbnddXHwUHAHAnAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAED9uBwDgNu3aNGigOtMnz49ZGe1Nt55552A6yxevDjgOsxsHT7oAQEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFAR4TiOIyGkpKREoqOjtZsBfG1JSUkB1/nwww8DrtOyZUupK+fOnQu4Tt++fQOuc+zYsYDroP7wer0SFRVV7fP0gAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKi4Q+dtgfAxevTokJ1YdM+ePTWq98Mf/jDgOkwsikDRAwIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCyUgRlpo3b16jesnJyQHX6d+/v9SFffv2BVxnwYIFNXqvvLy8GtUDAkEPCACgggACANSPANq5c6e9/klCQoJERETIpk2b/J6fNGmSffzaMnLkyGC2GQDgxgAqLS2V3r17y7Jly6pdxgTOqVOnfGXNmjW3204AgNsHIYwaNcqWm/F4PBIXF3c77QIAhLlaOQe0Y8cOadOmjdx9990ybdo0OXv2bLXLlpWVSUlJiV8BAIS/oAeQOfy2evVqycnJkcWLF0tubq7tMVVUVFS5fGZmpkRHR/tKYmJisJsEAHDD94DGjx/v+7lnz57Sq1cv6dKli+0VDR8+/IblMzIyZNasWb77pgdECAFA+Kv1YdidO3eWVq1aSX5+frXni6KiovwKACD81XoAnThxwp4Dio+Pr+23AgCE8yG4Cxcu+PVmCgoK5ODBgxIbG2vLokWLZNy4cXYU3NGjR2Xu3LnStWtXSU1NDXbbAQBuCiAzH9WwYcN89yvP30ycOFGWL19u55B6/fXXpbi42H5ZdcSIEfKzn/3MHmoDAKBShOM4joQQMwjBjIZDeGratGnAddLT0wOuM2HCBKkJM3CmLqxfvz7gOpMnTw64Dl9rgCav13vT8/rMBQcAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQACI9LcgM389VXXwVcp3v37iE7q7Vx7ty5gOv84he/CLgOM1sj3NADAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoILJSFFjkZGRAdf5/e9/H3CdRx99VOrKl19+GXCdp556KuA6eXl5AdcBwg09IACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACqYjBQ1FhMTE3CdCRMmSCh79913A66zdevWWmkLEO7oAQEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFDBZKSQYcOG1aje6tWrJVStW7euRvXS0tKC3hYAVaMHBABQQQABAEI/gDIzM6Vfv37SokULadOmjYwZM0YOHz7st8ylS5fsYYyWLVtK8+bNZdy4cXL69OlgtxsA4KYAys3NteGye/duexGuy5cvy4gRI6S0tNS3zMyZM+W9996T9evX2+VPnjwpTzzxRG20HQDglkEI2dnZfvezsrJsT2j//v0yZMgQ8Xq98uqrr8pbb70lDz30kF1m1apVcs8999jQeuCBB4LbegCAO88BmcAxYmNj7a0JItMrSklJ8S2TlJQkHTp0kF27dlX5GmVlZVJSUuJXAADhr8YBdOXKFZkxY4YMHDhQevToYR8rKiqSxo0bS0xMjN+ybdu2tc9Vd14pOjraVxITE2vaJACAGwLInAs6dOiQrF279rYakJGRYXtSlaWwsPC2Xg8AEMZfRE1PT5ctW7bIzp07pX379r7H4+LipLy8XIqLi/16QWYUnHmuKh6PxxYAgLsE1ANyHMeGz8aNG2Xbtm3SqVMnv+f79OkjjRo1kpycHN9jZpj28ePHJTk5OXitBgC4qwdkDruZEW6bN2+23wWqPK9jzt1ERkba22eeeUZmzZplByZERUXJs88+a8OHEXAAgBoH0PLly+3t0KFD/R43Q60nTZpkf37ppZekQYMG9guoZoRbamqq/O53vwvkbQAALhDhmONqIcQMwzY9KdRMTc6nbd++vUbvVVe92n/9618B16kcmRkoM5MHgOAwA8vMkbDqMBccAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAKD+XBEVoeuFF14IuM79998voWzx4sUB12FWayD00QMCAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACggslIw8yBAwcCruPxeCSUhfpkqQBqhh4QAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFUxGGmays7MDrrN3794avde9994bcJ2UlJSA63zyyScB1wEQ+ugBAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUBHhOI4jIaSkpESio6O1mwEAuE1er1eioqKqfZ4eEABABQEEAAj9AMrMzJR+/fpJixYtpE2bNjJmzBg5fPiw3zJDhw6ViIgIvzJ16tRgtxsA4KYAys3NlbS0NNm9e7ds3bpVLl++LCNGjJDS0lK/5SZPniynTp3ylSVLlgS73QAAN10R9fqrbWZlZdme0P79+2XIkCG+x5s2bSpxcXHBayUAIOw0uN0RDkZsbKzf42+++aa0atVKevToIRkZGXLx4sVqX6OsrMyOfLu2AABcwKmhiooK55FHHnEGDhzo9/jKlSud7OxsJy8vz3njjTecdu3aOWPHjq32dRYsWGCGgVMoFApFwqt4vd6b5kiNA2jq1KlOx44dncLCwpsul5OTYxuSn59f5fOXLl2yjaws5vW0VxqFQqFQpNYDKKBzQJXS09Nly5YtsnPnTmnfvv1Nlx0wYIC9zc/Ply5dutzwvMfjsQUA4C4BBZDpMT377LOyceNG2bFjh3Tq1OmWdQ4ePGhv4+Pja95KAIC7A8gMwX7rrbdk8+bN9rtARUVF9nEzdU5kZKQcPXrUPv/www9Ly5YtJS8vT2bOnGlHyPXq1au2fgcAQH0UyHmf6o7zrVq1yj5//PhxZ8iQIU5sbKzj8Xicrl27OnPmzLnlccBrmWW1j1tSKBQKRW673Grfz2SkAIBawWSkAICQRAABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQEXIB5DiOdhMAAHWwPw+5ADp//rx2EwAAdbA/j3BCrMtx5coVOXnypLRo0UIiIiL8nispKZHExEQpLCyUqKgocSvWw1Wsh6tYD1exHkJnPZhYMeGTkJAgDRpU38+5Q0KMaWz79u1vuoxZqW7ewCqxHq5iPVzFeriK9RAa6yE6OvqWy4TcITgAgDsQQAAAFfUqgDwejyxYsMDeuhnr4SrWw1Wsh6tYD/VvPYTcIAQAgDvUqx4QACB8EEAAABUEEABABQEEAFBBAAEAVNSbAFq2bJncdddd0qRJExkwYIDs3btXu0l1buHChXZ6omtLUlKShLudO3fK6NGj7bQe5nfetGmT3/NmIOf8+fMlPj5eIiMjJSUlRY4cOSJuWw+TJk26YfsYOXKkhJPMzEzp16+fnaqrTZs2MmbMGDl8+LDfMpcuXZK0tDRp2bKlNG/eXMaNGyenT58Wt62HoUOH3rA9TJ06VUJJvQigdevWyaxZs+zY9gMHDkjv3r0lNTVVzpw5I25z3333yalTp3zlz3/+s4S70tJS+zc3H0KqsmTJElm6dKmsWLFC9uzZI82aNbPbh9kRuWk9GCZwrt0+1qxZI+EkNzfXhsvu3btl69atcvnyZRkxYoRdN5Vmzpwp7733nqxfv94ub+aWfOKJJ8Rt68GYPHmy3/Zg/ldCilMP9O/f30lLS/Pdr6iocBISEpzMzEzHTRYsWOD07t3bcTOzyW7cuNF3/8qVK05cXJzzq1/9yvdYcXGx4/F4nDVr1jhuWQ/GxIkTnccff9xxkzNnzth1kZub6/vbN2rUyFm/fr1vmU8//dQus2vXLsct68F48MEHneeee84JZSHfAyovL5f9+/fbwyrXTlhq7u/atUvcxhxaModgOnfuLBMmTJDjx4+LmxUUFEhRUZHf9mEmQTSHad24fezYscMekrn77rtl2rRpcvbsWQlnXq/X3sbGxtpbs68wvYFrtwdzmLpDhw5hvT14r1sPld58801p1aqV9OjRQzIyMuTixYsSSkJuNuzrffHFF1JRUSFt27b1e9zc/+yzz8RNzE41KyvL7lxMd3rRokUyePBgOXTokD0W7EYmfIyqto/K59zCHH4zh5o6deokR48elRdeeEFGjRpld7wNGzaUcGMu3TJjxgwZOHCg3cEa5m/euHFjiYmJcc32cKWK9WA8/fTT0rFjR/uBNS8vT55//nl7nmjDhg0SKkI+gPB/ZmdSqVevXjaQzAb29ttvyzPPPKPaNugbP3687+eePXvabaRLly62VzR8+HAJN+YciPnw5YbzoDVZD1OmTPHbHswgHbMdmA8nZrsIBSF/CM50H82nt+tHsZj7cXFx4mbmU1737t0lPz9f3KpyG2D7uJE5TGv+f8Jx+0hPT5ctW7bI9u3b/a4fZv7m5rB9cXGxK7aH9GrWQ1XMB1YjlLaHkA8g053u06eP5OTk+HU5zf3k5GRxswsXLthPM+aTjVuZw01mx3Lt9mGuCGlGw7l9+zhx4oQ9BxRO24cZf2F2uhs3bpRt27bZv/+1zL6iUaNGftuDOexkzpWG0/bg3GI9VOXgwYP2NqS2B6ceWLt2rR3VlJWV5fzjH/9wpkyZ4sTExDhFRUWOm/zoRz9yduzY4RQUFDgfffSRk5KS4rRq1cqOgAln58+fdz755BNbzCb74osv2p///e9/2+d/+ctf2u1h8+bNTl5enh0J1qlTJ+e///2v45b1YJ6bPXu2Hellto8PPvjA+eY3v+l069bNuXTpkhMupk2b5kRHR9v/g1OnTvnKxYsXfctMnTrV6dChg7Nt2zZn3759TnJysi3hZNot1kN+fr7z05/+1P7+Znsw/xudO3d2hgwZ4oSSehFAxiuvvGI3qsaNG9th2bt373bc5sknn3Ti4+PtOmjXrp29bza0cLd9+3a7w72+mGHHlUOx582b57Rt29Z+UBk+fLhz+PBhx03rwex4RowY4bRu3doOQ+7YsaMzefLksPuQVtXvb8qqVat8y5gPHtOnT3fuvPNOp2nTps7YsWPtztlN6+H48eM2bGJjY+3/RNeuXZ05c+Y4Xq/XCSVcDwgAoCLkzwEBAMITAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAETD/wAbI92WoBHi5QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frac = [0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "frac = 0.005\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist17_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist17_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist17_transforms, download=True)\n",
    "\n",
    "# 选取标签为 1 和 7 的索引\n",
    "indices1_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 1]\n",
    "indices7_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 7]\n",
    "\n",
    "indices1_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 1]\n",
    "indices7_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 7]\n",
    "\n",
    "# 获取训练集中标签为 1 和 7 的数据\n",
    "mnist1_train_data = full_train_datasets.data[indices1_train]\n",
    "mnist1_train_labels = torch.ones(len(indices1_train), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_train_data = full_train_datasets.data[indices7_train]\n",
    "mnist7_train_labels = torch.zeros(len(indices7_train), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 1 和 7 的数据\n",
    "mnist1_test_data = full_test_datasets.data[indices1_test]\n",
    "mnist1_test_labels = torch.ones(len(indices1_test), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_test_data = full_test_datasets.data[indices7_test]\n",
    "mnist7_test_labels = torch.zeros(len(indices7_test), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(frac * len(mnist1_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_7 = np.random.choice(len(mnist7_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist7_train_data = mnist7_train_data[selected_indices_7]\n",
    "fraction_mnist7_train_labels = mnist7_train_labels[selected_indices_7]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist1_train_data, fraction_mnist7_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist1_train_labels, fraction_mnist7_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist1_test_data, mnist7_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist1_test_labels, mnist7_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 1 in the final training set: \", len(mnist1_train_data))\n",
    "print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data))\n",
    "print(\"Number of label 1 in the final test set: \", len(mnist1_test_data))\n",
    "print(\"Number of label 7 in the final test set: \", len(mnist7_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n",
    "\n",
    "\n",
    "\n",
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6775, 784)\n",
      "y_train.shape: (6775,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n",
      "Resampled dataset shape Counter({np.int64(1): 6742, np.int64(0): 6742})\n",
      "##############################################\n",
      "SMOTE done!\n",
      "X_train.shape: (13484, 784)\n",
      "y_train.shape: (13484,)\n",
      "X_test.shape: (2163, 784)\n",
      "y_test.shape: (2163,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda3/envs/Thesis/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, labels = batch  # images: (batch_size, 1, 28, 28), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        #print(f\"Original shape: {img.shape}\")  #  \n",
    "        flattened_img = img.flatten()           \n",
    "        #print(f\"Flattened shape: {flattened_img.shape}\")\n",
    "        X_train.append(flattened_img) # \n",
    "        y_train.append(label)\n",
    "\n",
    "\n",
    "X_test = [] # features\n",
    "y_test = [] # labels\n",
    "for batch in test_loader:\n",
    "    images, labels = batch  # images: (batch_size, 1,28  ,28 ), labels: (batch_size,)\n",
    "    if hasattr(images, 'numpy'): # images is tensor\n",
    "        images = images.numpy()\n",
    "    # batch_size = 64\n",
    "    for img, label in zip(images, labels):\n",
    "        flattened_img = img.flatten()           # flatten the image\n",
    "        X_test.append(flattened_img)\n",
    "        y_test.append(label)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_train))\n",
    "print(\"##############################################\")\n",
    "print(\"SMOTE done!\")\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape: torch.Size([13484, 784])\n",
      "y_train_tensor.shape: torch.Size([13484])\n",
      "总共恢复的图像数量： 13484\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAAFpCAYAAAD6LYuZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAomUlEQVR4nO3de7BV5Xk44HO4Kl6wAhpDCqjlErAYSVMvXDxoFKiaogZvTYjGVOtEUxgJM0EUkDaZaNTamAYTjAZvERGLxUBJGoGgEwghQsULXooEBIOoRC4B5ezfOPnjl3W+BXu5z/r2Pmfv5/nvfedbH+84y2/vc96z1ltfKBQKdQAAAAAAADlrk/eGAAAAAAAAH9KEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAomiXdWF9fX2cCmiVCoVCWf4d9x3lvu/cc/w5Zx2V4L6jEnzGUm7OOirBWUe5OeuoBPcdLfG+8yQEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQhSYEAAAAAAAQRbs42wJ5Gj9+fJC74IILEvHixYuDNTNnzgxyr7/+es7VAZRPr169gtz06dOD3Be+8IWie/3kJz8JcpdeemkzqgNqyZ133hnkvva1ryXiadOmBWtee+21IDdr1qycq6NatWkT/h3h9ddfn4iPOuqoYM2kSZOC3Pvvv59zddSq2bNnB7kxY8YEucbGxkTctm3bqHVBJTz88MNB7pJLLknEo0ePDtY88cQTQa5QKORcHVSOJyEAAAAAAIAoNCEAAAAAAIAoNCEAAAAAAIAoNCEAAAAAAIAoDKaOYMWKFUEubSjdk08+WaaKaO1uueWWINeuXfJ/3yFDhgRrPvOZzwS5kSNH5lwdrV3aQLgpU6YEuRtvvDER33TTTZkGBEOe9+eVV14ZrLnsssuKDj5MY9AbWU2dOjXITZ48OdO1TT+vaZ26desW5IYOHVr07Em7T9KGATc9j+6///4SK6Xa9e/fP8h9+9vfLnpd2s8FDQ0NudVFbUv73pU1B9Wmffv2Re/9uXPnBmsOOuigTN8ZaJ1uSvn9Sdrvip955pkgN3jw4Lpq4EkIAAAAAAAgCk0IAAAAAAAgCk0IAAAAAAAgCi+pzUHfvn0T8V//9V8Ha775zW8GuQULFgQ570gkT6ecckqlS6AVOPzww4PcDTfcUPR88j59yqHp+9QnTZpU8l579+5NxAsXLix5L2pL2nnnO1tt2bp1a5BbunRpkDvxxBNLeld0586dm1Ed1JV03zXNefc4WY0ZM+aA8Yfq6+uDXJs2yb+DfeSRR4I1F198cS41QgwdO3ZMxN/4xjeCNSNGjCi6z/z584Oc75bV7cqU2Ya1NjvHkxAAAAAAAEAUmhAAAAAAAEAUmhAAAAAAAEAUmhAAAAAAAEAUBlPnYNeuXUUHeqUNq246lKnaB5CQzUEHHZRpqFcWq1evzqEiSPfss89WugRqYGjmkCFDctu/6fDDWbNm5bY31WXAgAGJeNiwYRWrBSAPp556atFc2rB1yCLt9xhZft9RKBSi1gXN0dDQEORuuOGGRHzGGWdk2uuJJ55IxBdddFGwZt++fR+5RlquM888MxF369atrtZ5EgIAAAAAAIhCEwIAAAAAAIhCEwIAAAAAAIhCEwIAAAAAAIjCYOocdO7cuehgYcjqkksuCXJt27Ytaa9f//rXOVRELQ7cymLZsmW510Lt6NChQ5CbNm1akMs67K2pLVu2BLlbb721pL2oPf3790/EQ4cOrVgt1Ibzzz8/Ed91110Vq4WWbevWrUHupZdeSsR9+/Yt6edYKFXaEOr6+vqi69LWQEvx3e9+t+h3xDRPPfVU0d/zvP/++82sjpbk4x//eJC74447iv78m+aee+6pq1aehAAAAAAAAKLQhAAAAAAAAKLQhAAAAAAAAKIwEyIHTWdAtGvXruR3hm3YsCG3umid1q1bF+QKhUKQ8/5M8jJ58uRM6373u98lYu+xpDn69OkT5CZOnJjb/hdccEGQW7t2bW77A+RpwIABlS6BVmLPnj1BbufOnSXtdffddyfiF154IVjzyiuvlLQ3taWxsTHTnIim69J+zoVKOPvss4Nc9+7dS9or7SxNO7upHj169Cjpu92mTZuC3DPPPFNXrTwJAQAAAAAARKEJAQAAAAAARKEJAQAAAAAARKEJAQAAAAAARGEwdQ6uvPLKkq574403cq+F6hzWWuoQ6gULFuRQEdWmX79+ibh3796ZrluyZEkuQxCpTR07dkzEl19+eW57/+///m+QM0iTrD73uc8FuYcffrikvV599dUcKqIWde3atdIl0Eq8++67QW7Dhg2JeNCgQZn2+tjHPpaIu3TpEqzxeUoWaUOo036Gbbpu+fLlUeuCNGlnZNp3v86dOxfd65FHHgly9913XzOqozU655xzglyhUCh63R133BHk1q1bV1etPAkBAAAAAABEoQkBAAAAAABEoQkBAAAAAABEoQkBAAAAAABEYTD1R5Q2XKmhoaHodfPnzw9y+/bty60uqscRRxxR0nW7d+8OcgZkkqZnz54HHBgMMUyYMCERjx8/vqR9duzYEeS+/e1vB7lt27aVtD+1Z+7cuUGusbGx6HW/+tWvgtyll16aW120znvnuuuuq0gtAJWU9rmZNqy66bq0oayQt+nTpyfiM844I9PvYd55550g9/Wvf73oYOpdu3aVWCmtQadOnYJc2j2Vxcsvv1xXSzwJAQAAAAAARKEJAQAAAAAARKEJAQAAAAAARKEJAQAAAAAARGEw9Uc0ZcqUINe3b9+i102cODHIFQqF3Oqielx44YUlXfeb3/wmyK1fvz6Hiqg2H3zwQUnXvfLKK7nXQnVKG3Y+ePDgXPZetWpVkHv44Ydz2Rv2Z8mSJZkGEG/atKlMFdESLF26tOgg1ixDzqGlGDZsWJBbvnx5RWqhdUkbQl1fX59pHeTphBNOCHLXXHNNIv6Lv/iLTHvdeOONQe7ee+9tRnVUg7POOivInXzyySXtNX/+/Lpa4hMAAAAAAACIQhMCAAAAAACIQhMCAAAAAACIwkyIA2jXLvzPM3r06KLXpb0P+PXXX8+tLoDm6Nq1a9GzLs3mzZsjVUS1zX+49dZbg9yIESNy+fceeuihXPaB5r77/8UXX6xILbRsTWdAlDoDLu091NOnTy+5LoA8jRs3ruj8m7T5D+bkEFvazK4sMyDS5s75rkfW+UlpM3Camu57nCchAAAAAACAODQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKAymPoDzzjsvyJ144olBrunAuQkTJgRrdu/enXN1VIumA2zSBnhBS7BmzZpKl0ALdOSRRwa5r371q7ntP3/+/EQ8Z86cunKbPXt2Ij7qqKMyXTdq1Kgg5/sAkEWXLl0qXQKtyP/93//lss/SpUtz2Yfqd+qppx7wdyL7G9TqZ12a4/DDD0/Et99+e7Dm/PPPL7rPW2+9FeQuvfTSIPfKK6985Bqpfuecc06QSzsDm5o5c2ZdrfMJAAAAAAAARKEJAQAAAAAARKEJAQAAAAAARKEJAQAAAAAARGEw9QFcd911mYaNbNq0KREvWLAgal1Ul759+ybi0047rWK1ABxIhw4dgtzUqVNz2/8Pf/hDkJs+fXoifuedd+rK7Zvf/GYi7tixY6br9u7dG6kisvrLv/zLRPyLX/wiWNO2bdui+6QN1wRoKR588MFEPH78+IrVQm1o+nuRxsbGTEOob7vttqh10TodcsghQW7MmDFBrunZdsIJJ2Ta/6GHHkrE//Iv/xKsMYSa/Wk6tLx3794lDabGkxAAAAAAAEAkmhAAAAAAAEAUmhAAAAAAAEAUZkL8mc6dO5f0bv6FCxcWfac17E/Wd4sX493jQGyf+cxngtxXvvKVkvZK+6y8/PLLg9zKlSvrKu3ZZ5+tdAlkMGDAgCA3Y8aMRNyzZ89gTdqckabf7dauXZtLjVS/pu9AT3tPehbLli3LqSKA5jnllFOKzkpKm/+QNk9pxYoVOVdHa9OpU6cgN3PmzCB30UUXlbT/008/HeS+9a1vJeKXXnqppL2pTZMnTy7puieffDIRb968ua7WeRICAAAAAACIQhMCAAAAAACIQhMCAAAAAACIQhMCAAAAAACIwmDqP/O5z30uEXfo0CHTda+99lqkiqgFY8eOzWWfWbNm5bIPwP58/vOfz22v3/3ud0Fu3rx5ue1P7Um7P08++eSi123cuDHIXXbZZbnVRW1pOoi6UCiUtM/zzz+fU0XUgn/6p3+qdAlUsXHjxgW5pmdb07Nvf8OqSz0TqR4XXnhhbkOoN23aFOSuuOKKIPfqq6+WtD+1J21w+hFHHJGI6+vrgzV79+4NctOmTUvE+/btq6t1noQAAAAAAACi0IQAAAAAAACi0IQAAAAAAACi0IQAAAAAAACiMJj6zxx77LFF1/zhD38Icj/72c8iVUQtOOmkkypdAjVm0aJFifjdd98tOnyJ2tS+fftE3K9fv9z2/o//+I/c9oLmmDBhQqVLgMBVV12VaTgsfKhr16657DNq1Kgg9/LLLwe5t99+O5d/j9YhbQhr01zaEOos11H9PvvZzx5wWO9H0fTsufrqq4M1mzdvLnl/OOecc4Lc0UcfnYgLhUKwZuXKlUFu1apVOVfX+nkSAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiKJmB1OnDUQ67bTTil43Z86cTANIIM2QIUOC3NChQytSC7XrnXfeScQffPBBpuuanpErVqzItS5anoMOOigRn3322SXv9fjjjyfi+++/v+S9YMSIEUEubThhFosWLcqhIviTxx57LBFfcMEFFauF2vHss88m4tGjR5e0z0033RTk/vM//zPIGUxdW9KGsDbNNTY2BmvShlWn7UXr1L59+yD3wAMPBLmRI0cm4kMPPTTT/uvWrQtyw4cPT8RbtmzJtBdkdfHFF5d03ezZs3OvpRp5EgIAAAAAAIhCEwIAAAAAAIhCEwIAAAAAAIiiZmdC9O3bN8hledf1008/HakiasHHP/7xINeuXc3+b0gL8dOf/jTIjR07NsiddNJJZaqIajRv3rxEvHPnzorVQut3+OGHZ5r39eKLL+bynnTIatmyZYn4wgsvLGmfT33qU0Guc+fOQW779u0l7U91mT9/fiKeOnVqpuuanpv33HNPsObNN99sZnW0dsuXLw9yF110UdH5D2mfy2k5WqdvfOMbQe7zn/98SXulfZalzfoyA4LYv58bNGhQ0et27NgR5JYuXZpbXdXMkxAAAAAAAEAUmhAAAAAAAEAUmhAAAAAAAEAUmhAAAAAAAEAUNTsRd+DAgUXXbNy4McgtWrQoUkXw0RQKhUT86quvVqwWWrcnnngi02Dq8847LxEfdthhwZr33nsv5+qopL179ybi3/72tyUPLP/e976XiCdNmhSsufvuu4PckCFDEvHjjz8erHnwwQcz1UDr1HT45f4GyV177bVB7rHHHotWF2T5ftY0zmro0KFBrmvXrkHOYGo+9Pvf/z4Rr1+/PljTq1evINf0/vzyl78crFm5cmWQmzFjRomV0hrdcccdQe473/lOIm5sbAzWpA2rLvVMpPLatm2biIcNG1bSPj//+c+D3PTp04PcsmXLStofsurRo0eQ69mzZ9Hrpk6dGuRWr16dW13VzJMQAAAAAABAFJoQAAAAAABAFJoQAAAAAABAFJoQAAAAAABAFDU7mHrAgAFF1/zoRz8Kcps2bYpUEbUgbXhg0yFeaQO80sycOTMRG9xEqRYvXpxpXefOnRPx6aefHqyZP39+bnVReXv27EnEv/zlL0seTH3IIYck4j59+gRrbrvttiA3Z86cRLx8+fJM/x7V46GHHgpyzz33XJD753/+5zJVBNm/673//vvBmvbt25exImrBxo0bE/ELL7yQaTB1FoceemjJdVG96uvri/4M23TN/nK0DsOHDz9gnNXs2bODnN9lUAkvv/xykFu3bl2Q6927d5kqqn6ehAAAAAAAAKLQhAAAAAAAAKLQhAAAAAAAAKKo2ZkQu3btCnI7d+5MxDNmzChjRdSC//7v/w5yDz74YCL+4he/mOkdiT/4wQ9yro5atWPHjiA3a9asIDd27NhEfPPNNwdrVq5cGeS2bNnS7BppGW688caic20+NG7cuKJ7bd26NchNmzYtyN19991F/z1qT//+/YPcsGHDgtySJUvKVBGkf37269cvWDNx4sSi+6TNOHnrrbeaWR214qtf/WqQmzp1apA79thjE/HChQszzWuCpvdF2ne/tDkRhUIhal20vN+znXXWWYl4xYoVZawI9m/btm1B7vvf/36Qu/322xPxFVdcEax59NFHi85rwpMQAAAAAABAJJoQAAAAAABAFJoQAAAAAABAFJoQAAAAAABAFPWFjJOB6uvr66rJ4MGDg9x3vvOdRPyP//iPwZrnnnsual2tRbkGSlXbfUfLv+/cc39y0EEHBbnrr78+EU+ePDlY86UvfSnIzZ49u661ctZRCbV+382bNy8Rn3POOcGaBQsWBLm0IXEG+WbnM5Zyq/Wzjspw1lFuzjoqwX1Xmk6dOgW5iRMnJuLx48cHa8aNGxfk7r333rpaUyhy33kSAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiKJmB1PTPIbcUAkGyVFuzjoqwX1HJfiMpdycdVSCs45yc9ZRCe47KsFgagAAAAAAoCI0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCjqC4VCIc7WAAAAAABALfMkBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEEW7rAvr6+vjVECrVCgUyvLvuO8o933nnuPPOeuoBPcdleAzlnJz1lEJzjrKzVlHJbjvaIn3nSchAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKNrF2RbI6umnn07Eq1atCtZcd911ZawIAIBKOvfcc4PcQw89FOSGDh0a5FavXh2tLgBobX7/+98n4lGjRgVrfvOb35SxIlqzH//4x0HukEMOCXITJkxIxOvXr6+rdZ6EAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAoqgvFAqFTAvr6+NUUAWmTp2aiKdMmZLpuuHDhwe5xYsX17UGGW+bZquF+67pYOqBAwcGaz75yU8GuY0bN9bVmnLcd7Vwz5199tmJeNq0acGaj33sY0Fu4sSJifjRRx+tq3bOuvzceeedifhrX/tasOa5554rOpz19ddfr6t27ruW56/+6q+C3JIlS4LcxRdfHOSWLVtW1xr4jG1Z0s66gw8+OMgNGjSo1X5HdNa1/M/qD/3d3/1dkDvxxBOD3K5du+paA2dd+fTq1SvI/fKXv0zEt912W7Dm3//934NcY2NjXWvlrCuvfv36Bbm1a9cm4q1bt2b6+bc1c9/Fc9999wW5sWPHBrmhQ4ce8Hd/1ajYfedJCAAAAAAAIApNCAAAAAAAIApNCAAAAAAAIIp2cbYli4aGhlY7E4J4Dj300Ez3ygMPPFCmiqg2xx9/fCL+27/920zXXXbZZTU3E4J474dMe7dv2vybxx9/PBGff/75wZpamBNBZfXt2zfIHXPMMUHu2GOPbbUzIaisM888MxF369YtWJP2DuvWMv+BlqlNm+TfJHbq1CnTufbMM88EuZNPPjkR79mzJ5caaR06dOgQ5NLmf3Xv3j0R33777cGahx9+OMi9+eabza6R2jBs2LCicwvSPmMhb2k/K9Q6T0IAAAAAAABRaEIAAAAAAABRaEIAAAAAAABRaEIAAAAAAABRGEydgylTplS6BIDounTpcsBhhvsbNgzNMXDgwER83nnnBWvuuuuuMlZELZowYUKQW79+fZB79NFHy1QR1T6YOm3IK+TtE5/4RCK+4oorMl13wgknBLnhw4cn4oULFzazOlqypmfUyJEjgzUjRozIbZirwdQ0R6FQOGAMMXzxi19MxHPmzKmrdZ6EAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAojCY+iNqaGiodAkAzfLEE0+UNNR3yJAhRYdm/vGPf2xmdQCVd9pppyXiwYMHB2vShq46A8nrZ4z6+vpgzdKlS8tYEbVgwYIFlS6BVurMM89MxF26dAnWXH311SWdY0OHDg1yzz777EeukdrUrVu3INf0M/UHP/hBGSuitTv44IMT8bHHHpvpuu7duyfizp07B2u2b99eV0s8CQEAAAAAAEShCQEAAAAAAEShCQEAAAAAAERhJkQFZ0IsXrw4t72obl/+8peD3AMPPFCRWmj9du/eXekSAFq0E088MRG3axd+ZZ4zZ04ZK6LaFQqFA8YfWrVqVRkrohb069ev6H2XZufOnUHunXfeya0uqmOeyFVXXVXS3rNnzy7pOvjQ6NGjg1zWsw3SNJ3lkDa3Js2gQYMS8THHHBOsMRMCAAAAAAAgB5oQAAAAAABAFJoQAAAAAABAFJoQAAAAAABAFAZTf0Snn356bnsZTM2Htm7dWnTNIYccUpZaqA1//OMfE/Frr70WrDnuuOPKWBFAyzJx4sRE/OqrrwZrHn/88TJWRDXp0qVLkDvyyCOLXveTn/wkUkXUguOPPz63vRYuXBjkli9fntv+VIdzzz230iVQ5Xr27BnkevToEeTq6+sT8Q9/+MOodVFddu7cmYjXrFkTrBk4cGCQmz9/fiJet25dXa3zJAQAAAAAABCFJgQAAAAAABCFJgQAAAAAABCFJgQAAAAAABCFwdQfUUNDQ0nXTZs2LfdaqA5Nhwz+/d//fbCmf//+RXPPP/98hOqoRvv27UvEO3bsqFgt1I5t27ZVugRINWbMmKKDDtMGrr733ntR66J69e7dO1Ouqc2bN0eqiFpw0UUXlXRd2vfEO+64I4eKqCb9+vULcqNGjSp6XWNjY6SKqAVdu3YNcl26dAlyhUKhTBVRjZoONm/fvn2m61auXJmIG513noQAAAAAAADi0IQAAAAAAACi0IQAAAAAAACi0IQAAAAAAACiMJj6AKZOnVrpEqgBzz33XCLetWtXsObQQw/NlIMs9uzZk4gfe+yxYM3AgQOL7nP11VcHuTvvvLOZ1VGtpk+fnoh9xtJSdOzYseiaNWvWlKUWakNDQ0PRoYcG/9Ic/fv3D3LXXnttSXtt2bIlyP3qV78qaS+qV5s24d+3tm3btuh1999/f5B78803c6uL2tP083R/OciqU6dOifiTn/xkpus+/elPR6qo9fIkBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIWZEAcwZcqUSpdADc6EeO2114I1J5xwQpA7++yzE/GKFSsiVEctGDJkSEnX9enTJ/daqO13Bzc2NlakFmpblrMsbXYOZNGlS5cgd8011wS5QqFwwBg+ijPPPDPIHX300UWvS5tNl3a/ArRUaZ+fb7311gFjaK60uSNz586tSC0tmSchAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKAymLpOpU6dWugRaiZdeeinTYOpRo0Yl4ltuuSVYs3fv3pyrg//v17/+daVLoBVLG0KdZRBr3759I1VELejYsWOQO++884LcypUrE/FTTz0VtS6qV6dOnYJc9+7di173yCOPRKqIWnD99deXdN327duDnPOPLD7xiU9kGtSa5bseNEfafbdhw4YDxnAgb7/9diJeuHBhsGbkyJFB7uSTT07EP/7xj+tqnSchAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKDQhAAAAAACAKAymjjA8etq0abnsQ21avnx5kLvwwguD3GmnnVZ08KHB1OQ50Ktp7tRTTw3W3HfffVHrgmuuuSbI3XzzzUFu69atZaqI1mTEiBFB7lOf+lSQu+eeexLx+++/H7UuqteVV16Zad2TTz6ZiH/7299Gqohq9OlPfzoRH3nkkZm+27Vpk/ybxFtuuSVCddSCyy67rKQh1A8++GCkiqgFkyZNCnKGn5O3tm3bJuLDDjss02ds9+7do9bVGnkSAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiKJmZ0I0NDQEudNPP71FzZagNs2cOTPIeT8rMW3evLmkd2n26NEjUkXw0dxwww1Bbty4cRWphZYtbcZS2nl36623lqkiqk3TnyemTJkSrGlsbAxy3/rWtxLxvn37IlRHtbr++uuLzopLO+ua3mc7duyIUB3VqFu3bol49OjRmd6R3vQ+3LhxY4TqqBXnn39+prPuhz/8YZkqoho1nbX6xhtvZLrvjjvuuKLzmt5+++26WuJJCAAAAAAAIApNCAAAAAAAIApNCAAAAAAAIApNCAAAAAAAIAqDqYvksli8eHEOFcGfDBw4sKTrLrnkkiA3Y8aMHCqi2i1dujTIjR07tiK1UDvatGmTaVhrFmmDD+FDvXr1SsRnnHFGsGbevHlB7qWXXopaF9Vr0KBBRc+1tOGFkNVhhx0W5E455ZSS9po9e3Yivvfee0uui9rS9J47/PDDM511ixYtSsSvvPJKhOqoFWn3WFru+eefL1NFVKN9+/Yl4t27d2e6bsCAAYn4qKOOCtYYTA0AAAAAAJADTQgAAAAAACAKTQgAAAAAACAKTQgAAAAAACCKmh1Mffrpp+e217Rp03LbC9asWVPSdTfddFOQM5gaaKnSPjsnT55c0l6GvLI/l19+eSLu3r17sObuu+8uY0VUu4svvrjomrlz5wa5tWvXRqqIavOlL30pyPXo0aOkvX72s5/lUBG1aPjw4SVd99577yXiDz74IKeKqEX19fWZ1i1btix6LdS2tHvRz6ghT0IAAAAAAABRaEIAAAAAAABRaEIAAAAAAABRaEIAAAAAAABR1MRg6qlTpwa5hoaG3AZpLl68uKS9IM3OnTuD3NKlS4PcsGHDEnGXLl2CNYMHDw5yTz/9dLNrBGiubdu2VboEakCvXr0OOBDzQwZTU6pzzz03yJ100kmJeMeOHcGaf/3Xfw1yafcmpLniiity2+vee+/NbS/IMqj13/7t3ypSC9UpbfCvYcDE9l//9V9BbuzYsUWvO/roo4Pciy++WFdLPAkBAAAAAABEoQkBAAAAAABEoQkBAAAAAABEURMzIaZMmRJ1vgTkae/evUFuw4YNRa/r0KFDkBs5cmSQMxMCgGp0xBFHBLmzzjorEd93333Bmq1bt0ati+o1adKkINeuXfLHq+3btwdrVq9eHbUuqke3bt2C3GGHHVbSXg888EAOFUF23s1P3prOxWzTJvy76sbGxjJWRC164YUXSrru8ssvD3JLliypqyWehAAAAAAAAKLQhAAAAAAAAKLQhAAAAAAAAKLQhAAAAAAAAKKousHUDQ0Nue01fPjw3PaC5vje974X5L7whS+U9f8HgDx997vfDXLXXXddkDv++OOL7jVu3Ljc6qL1+od/+Icgd8wxxyTibdu2lbEianHoatPc/Pnzy1gR1eZv/uZvgtxxxx1X0l4333xzDhUBVE6/fv2KDqE2EB1aLk9CAAAAAAAAUWhCAAAAAAAAUWhCAAAAAAAAUWhCAAAAAAAAURhMfQCLFy/ObS9oDsOVgFqQZcgr7E+fPn2C3N69exPxvHnzylgR1NX99Kc/rXQJ1KBZs2YFufXr11ekFoC81NfXJ+I2bcK/q04bVg15evfdd4Pchg0bglyPHj2K/qxy8MEHB7ndu3fXVStPQgAAAAAAAFFoQgAAAAAAAFFoQgAAAAAAAFFU3UyI5jADgpbqzTffDHJ33XVXIr7qqquCNffff3/UuqgO//M//5PpnYY9e/YsU0XUqhkzZgS5W2+9NRF///vfL2NFtHaLFi1KxKtXr65YLdSGVatWJeL58+dXrBZq1/bt24Oc96QDrd3atWuLnmtz584tY0XUojfeeCPIfeUrXyn6c8js2bODNXv27KmrJZ6EAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAotCEAAAAAAAAoqgvFAqFTAvr6+tag4aGhiD31FNPZRpCPW3atKJr+JOMt02ztZb7juq579xzfzJmzJggd+211ybiPn36BGt69+4d5Hbs2FHXWjnrymvUqFFB7kc/+lEiHjFiRLBmzZo1ddXEfVea8ePHB7lt27Yl4lmzZpWxotbFZyzl5qwrLu27VtrPqFu2bEnEn/3sZ4M1b7/9ds7VtU7Ounx069YtEf/iF78I1vz85z8Pcl//+tcT8QcffFBX7Zx1VIL7jpZ433kSAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiEITAgAAAAAAiKLqBlNTHobcUAkGyVFuzjoqwX1HJfiMpdycdVSCs45yc9ZRCe47KsFgagAAAAAAoCI0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCg0IQAAAAAAgCjqC4VCIc7WAAAAAABALfMkBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAEIUmBAAAAAAAUBfD/wP4FOXCzSxywgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_images.shape: torch.Size([13484, 28, 28])\n",
      "Number of batches in new training set:  211\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 假设 X_train 和 y_train 都是 numpy 数组\n",
    "# 注意：如果你的像素值范围在 0~255，建议在转换为 tensor 时进行归一化\n",
    "X_train_tensor= torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "print(\"X_train_tensor.shape:\", X_train_tensor.shape)\n",
    "print(\"y_train_tensor.shape:\", y_train_tensor.shape)\n",
    "\n",
    "# 假设 X_train_tensor 的形状为 (N, 784)，每个样本是一个扁平化的 28x28 图像\n",
    "reconstructed_images = []  # 用于保存恢复后的图像\n",
    "\n",
    "for i in range(len(X_train_tensor)):\n",
    "    flattened_img = X_train_tensor[i]        # 取出第 i 个样本，形状 (784,)\n",
    "    original_img = flattened_img.view(28, 28)  # 恢复为 (28, 28) 图像\n",
    "    reconstructed_images.append(original_img)  # 存入列表\n",
    "\n",
    "print(\"总共恢复的图像数量：\", len(reconstructed_images))\n",
    "\n",
    "# 可视化恢复后的图像\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, img in enumerate(reconstructed_images[:20]):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 创建 Dataset\n",
    "reconstructed_images = torch.stack(reconstructed_images)  # 将列表转换为张量\n",
    "print(\"reconstructed_images.shape:\", reconstructed_images.shape)  # (N, 28, 28)\n",
    "final_train_datasets = TensorDataset(reconstructed_images.unsqueeze(1).float(), y_train_tensor)\n",
    "\n",
    "# 使用新的 Dataset 构建新的 DataLoader\n",
    "new_train_loader = DataLoader(final_train_datasets, batch_size=64, shuffle=True)\n",
    "print(\"Number of batches in new training set: \", len(new_train_loader))\n",
    "\n",
    "# 获取一个 batch\n",
    "images, labels = next(iter(new_train_loader))\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.0293, Train Accuracy: 0.9931, Test Loss: 0.1377, Test Accuracy: 0.9709\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.9709\n",
      "TP: 1135.0\n",
      "FP: 63.0\n",
      "FN: 0.0\n",
      "TN: 965.0\n",
      "Accuracy: 0.9709\n",
      "Misclassification rate: 0.0291\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9387\n",
      "Precision: 0.9474\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9689\n",
      "F-measure: 0.9730\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9575\n",
      "InvF0.5-measure: 0.9890\n",
      "AGF: 0.9731\n",
      "Balanced Accuracy: 0.9694\n",
      "Matthew's Correlation Coefficient: 0.9431\n",
      "Cohen's Kappa: 0.9414\n",
      "Youden's Index: 0.9387\n",
      "Positive Likelihood Ratio: 16.3175\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 2/50, Train Loss: 0.0036, Train Accuracy: 0.9991, Test Loss: 0.1545, Test Accuracy: 0.9699\n",
      "Epoch: 3/50, Train Loss: 0.0013, Train Accuracy: 0.9999, Test Loss: 0.0648, Test Accuracy: 0.9843\n",
      "==> New best model saved at epoch 3 with Test Accuracy: 0.9843\n",
      "TP: 1134.0\n",
      "FP: 33.0\n",
      "FN: 1.0\n",
      "TN: 995.0\n",
      "Accuracy: 0.9843\n",
      "Misclassification rate: 0.0157\n",
      "Sensitivity (Recall): 0.9991\n",
      "Specificity: 0.9679\n",
      "Precision: 0.9717\n",
      "Negative Predictive Value: 0.9990\n",
      "G-mean: 0.9834\n",
      "F-measure: 0.9852\n",
      "Discriminant Power: 5.7557\n",
      "F2-measure: 0.9771\n",
      "InvF0.5-measure: 0.9935\n",
      "AGF: 0.9853\n",
      "Balanced Accuracy: 0.9835\n",
      "Matthew's Correlation Coefficient: 0.9689\n",
      "Cohen's Kappa: 0.9684\n",
      "Youden's Index: 0.9670\n",
      "Positive Likelihood Ratio: 31.1241\n",
      "Negative Likelihood Ratio: 0.0009\n",
      "Epoch: 4/50, Train Loss: 0.0006, Train Accuracy: 0.9999, Test Loss: 0.1737, Test Accuracy: 0.9676\n",
      "Epoch: 5/50, Train Loss: 0.0003, Train Accuracy: 0.9999, Test Loss: 0.1861, Test Accuracy: 0.9723\n",
      "Epoch: 6/50, Train Loss: 0.0001, Train Accuracy: 0.9999, Test Loss: 0.2055, Test Accuracy: 0.9695\n",
      "Epoch: 7/50, Train Loss: 0.0001, Train Accuracy: 1.0000, Test Loss: 0.2121, Test Accuracy: 0.9718\n",
      "Epoch: 8/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2216, Test Accuracy: 0.9713\n",
      "Epoch: 9/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2392, Test Accuracy: 0.9699\n",
      "Epoch: 10/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2478, Test Accuracy: 0.9699\n",
      "Epoch: 11/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2630, Test Accuracy: 0.9690\n",
      "Epoch: 12/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2537, Test Accuracy: 0.9704\n",
      "Epoch: 13/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2795, Test Accuracy: 0.9676\n",
      "Epoch: 14/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2828, Test Accuracy: 0.9686\n",
      "Epoch: 15/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2877, Test Accuracy: 0.9686\n",
      "Epoch: 16/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2832, Test Accuracy: 0.9695\n",
      "Epoch: 17/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2882, Test Accuracy: 0.9690\n",
      "Epoch: 18/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2945, Test Accuracy: 0.9690\n",
      "Epoch: 19/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2866, Test Accuracy: 0.9695\n",
      "Epoch: 20/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2925, Test Accuracy: 0.9695\n",
      "Epoch: 21/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3026, Test Accuracy: 0.9690\n",
      "Epoch: 22/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2963, Test Accuracy: 0.9695\n",
      "Epoch: 23/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3040, Test Accuracy: 0.9690\n",
      "Epoch: 24/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3006, Test Accuracy: 0.9695\n",
      "Epoch: 25/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3059, Test Accuracy: 0.9690\n",
      "Epoch: 26/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3167, Test Accuracy: 0.9690\n",
      "Epoch: 27/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3251, Test Accuracy: 0.9690\n",
      "Epoch: 28/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3214, Test Accuracy: 0.9690\n",
      "Epoch: 29/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3255, Test Accuracy: 0.9690\n",
      "Epoch: 30/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3290, Test Accuracy: 0.9690\n",
      "Epoch: 31/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3424, Test Accuracy: 0.9686\n",
      "Epoch: 32/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3221, Test Accuracy: 0.9699\n",
      "Epoch: 33/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3415, Test Accuracy: 0.9686\n",
      "Epoch: 34/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3364, Test Accuracy: 0.9690\n",
      "Epoch: 35/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3372, Test Accuracy: 0.9690\n",
      "Epoch: 36/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3462, Test Accuracy: 0.9690\n",
      "Epoch: 37/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3470, Test Accuracy: 0.9690\n",
      "Epoch: 38/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3441, Test Accuracy: 0.9690\n",
      "Epoch: 39/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3498, Test Accuracy: 0.9690\n",
      "Epoch: 40/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3510, Test Accuracy: 0.9690\n",
      "Epoch: 41/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3587, Test Accuracy: 0.9690\n",
      "Epoch: 42/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3521, Test Accuracy: 0.9699\n",
      "Epoch: 43/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3578, Test Accuracy: 0.9695\n",
      "Epoch: 44/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3672, Test Accuracy: 0.9686\n",
      "Epoch: 45/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3625, Test Accuracy: 0.9699\n",
      "Epoch: 46/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3627, Test Accuracy: 0.9699\n",
      "Epoch: 47/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3733, Test Accuracy: 0.9686\n",
      "Epoch: 48/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3717, Test Accuracy: 0.9699\n",
      "Epoch: 49/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3729, Test Accuracy: 0.9699\n",
      "Epoch: 50/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3795, Test Accuracy: 0.9690\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 50\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(new_train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST17_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 3 in the final training set\": len(mnist1_train_data),\n",
    "            \"Number of label 4 in the final training set (after downsampling)\": len(fraction_mnist7_train_data),\n",
    "            \"Number of label 3 in the final test set\": len(mnist1_test_data),\n",
    "            \"Number of label 4 in the final test set\": len(mnist7_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"SMOTE_CNNBinaryMNIST17_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
