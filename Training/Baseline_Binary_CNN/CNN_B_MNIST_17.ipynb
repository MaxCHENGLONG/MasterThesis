{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST Label 1 and label 7 /  1->1 7->0 / 1 is positive 7 is negative CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 1 in the final training set:  6742\n",
      "Number of label 7 in the final training set (after downsampling):  33\n",
      "Number of label 1 in the final test set:  1135\n",
      "Number of label 7 in the final test set:  1028\n",
      "Total samples in final training set:  6775\n",
      "Total samples in final test set:  2163\n",
      "Number of batches in training set:  106\n",
      "Number of batches in test set:  34\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist17_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist17_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist17_transforms, download=True)\n",
    "\n",
    "# 选取标签为 1 和 7 的索引\n",
    "indices1_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 1]\n",
    "indices7_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 7]\n",
    "\n",
    "indices1_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 1]\n",
    "indices7_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 7]\n",
    "\n",
    "# 获取训练集中标签为 1 和 7 的数据\n",
    "mnist1_train_data = full_train_datasets.data[indices1_train]\n",
    "mnist1_train_labels = torch.ones(len(indices1_train), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_train_data = full_train_datasets.data[indices7_train]\n",
    "mnist7_train_labels = torch.zeros(len(indices7_train), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 1 和 7 的数据\n",
    "mnist1_test_data = full_test_datasets.data[indices1_test]\n",
    "mnist1_test_labels = torch.ones(len(indices1_test), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_test_data = full_test_datasets.data[indices7_test]\n",
    "mnist7_test_labels = torch.zeros(len(indices7_test), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(0.005 * len(mnist1_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_7 = np.random.choice(len(mnist7_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist7_train_data = mnist7_train_data[selected_indices_7]\n",
    "fraction_mnist7_train_labels = mnist7_train_labels[selected_indices_7]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist1_train_data, fraction_mnist7_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist1_train_labels, fraction_mnist7_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist1_test_data, mnist7_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist1_test_labels, mnist7_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 1 in the final training set: \", len(mnist1_train_data))\n",
    "print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data))\n",
    "print(\"Number of label 1 in the final test set: \", len(mnist1_test_data))\n",
    "print(\"Number of label 7 in the final test set: \", len(mnist7_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
      "          0.3451, 0.8353, 0.9922, 0.4863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
      "          0.9882, 0.9882, 0.9882, 0.7059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
      "          0.9882, 0.9882, 0.9882, 0.4118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882,\n",
      "          0.9882, 0.9882, 0.8314, 0.0784, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.6667,\n",
      "          0.9882, 0.9882, 0.6392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.9882,\n",
      "          0.9882, 0.9333, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1608, 0.9059, 0.9882,\n",
      "          0.9882, 0.6392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8784, 0.9922, 0.9882,\n",
      "          0.9882, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9451, 0.9922, 0.9882,\n",
      "          0.9255, 0.1882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.9882, 0.9922, 0.9882,\n",
      "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.2000, 0.9490, 0.9922, 1.0000, 0.8980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4275, 0.9882, 0.9882, 0.9922, 0.6235,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2078, 0.9373, 0.9882, 0.9882, 0.8941, 0.1608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6471, 0.9882, 0.9882, 0.9882, 0.4745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0706, 0.8471, 0.9882, 0.9882, 0.9882, 0.1373, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4235, 0.9882, 0.9882, 0.9882, 0.4941, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1961, 0.9451, 0.9882, 0.9882, 0.9882, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2392, 0.9882, 0.9882, 0.9882, 0.8235, 0.0275, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6667, 0.9882, 0.9882, 0.9882, 0.1333, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4863, 0.9882, 0.9882, 0.6275, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Train Loss: 0.0506, Train Accuracy: 0.9951, Test Loss: 1.4340, Test Accuracy: 0.5691\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.5691\n",
      "TP: 1135.0\n",
      "FP: 932.0\n",
      "FN: 0.0\n",
      "TN: 96.0\n",
      "Accuracy: 0.5691\n",
      "Misclassification rate: 0.4309\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.0934\n",
      "Precision: 0.5491\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.3056\n",
      "F-measure: 0.7089\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.6035\n",
      "InvF0.5-measure: 0.8589\n",
      "AGF: 0.7200\n",
      "Balanced Accuracy: 0.5467\n",
      "Matthew's Correlation Coefficient: 0.2264\n",
      "Cohen's Kappa: 0.0976\n",
      "Youden's Index: 0.0934\n",
      "Positive Likelihood Ratio: 1.1030\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 2/20, Train Loss: 0.0084, Train Accuracy: 0.9975, Test Loss: 0.2266, Test Accuracy: 0.9390\n",
      "==> New best model saved at epoch 2 with Test Accuracy: 0.9390\n",
      "TP: 1135.0\n",
      "FP: 132.0\n",
      "FN: 0.0\n",
      "TN: 896.0\n",
      "Accuracy: 0.9390\n",
      "Misclassification rate: 0.0610\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8716\n",
      "Precision: 0.8958\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9336\n",
      "F-measure: 0.9450\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9149\n",
      "InvF0.5-measure: 0.9773\n",
      "AGF: 0.9456\n",
      "Balanced Accuracy: 0.9358\n",
      "Matthew's Correlation Coefficient: 0.8836\n",
      "Cohen's Kappa: 0.8769\n",
      "Youden's Index: 0.8716\n",
      "Positive Likelihood Ratio: 7.7879\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 3/20, Train Loss: 0.0019, Train Accuracy: 0.9993, Test Loss: 0.1301, Test Accuracy: 0.9635\n",
      "==> New best model saved at epoch 3 with Test Accuracy: 0.9635\n",
      "TP: 1135.0\n",
      "FP: 79.0\n",
      "FN: 0.0\n",
      "TN: 949.0\n",
      "Accuracy: 0.9635\n",
      "Misclassification rate: 0.0365\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9232\n",
      "Precision: 0.9349\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9608\n",
      "F-measure: 0.9664\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9473\n",
      "InvF0.5-measure: 0.9863\n",
      "AGF: 0.9666\n",
      "Balanced Accuracy: 0.9616\n",
      "Matthew's Correlation Coefficient: 0.9290\n",
      "Cohen's Kappa: 0.9265\n",
      "Youden's Index: 0.9232\n",
      "Positive Likelihood Ratio: 13.0127\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 4/20, Train Loss: 0.0009, Train Accuracy: 0.9999, Test Loss: 0.1429, Test Accuracy: 0.9653\n",
      "==> New best model saved at epoch 4 with Test Accuracy: 0.9653\n",
      "TP: 1135.0\n",
      "FP: 75.0\n",
      "FN: 0.0\n",
      "TN: 953.0\n",
      "Accuracy: 0.9653\n",
      "Misclassification rate: 0.0347\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9270\n",
      "Precision: 0.9380\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9628\n",
      "F-measure: 0.9680\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9498\n",
      "InvF0.5-measure: 0.9870\n",
      "AGF: 0.9682\n",
      "Balanced Accuracy: 0.9635\n",
      "Matthew's Correlation Coefficient: 0.9325\n",
      "Cohen's Kappa: 0.9302\n",
      "Youden's Index: 0.9270\n",
      "Positive Likelihood Ratio: 13.7067\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 5/20, Train Loss: 0.0005, Train Accuracy: 0.9999, Test Loss: 0.2964, Test Accuracy: 0.9417\n",
      "Epoch: 6/20, Train Loss: 0.0003, Train Accuracy: 0.9999, Test Loss: 0.2606, Test Accuracy: 0.9501\n",
      "Epoch: 7/20, Train Loss: 0.0003, Train Accuracy: 0.9997, Test Loss: 0.4193, Test Accuracy: 0.9325\n",
      "Epoch: 8/20, Train Loss: 0.0002, Train Accuracy: 1.0000, Test Loss: 0.1624, Test Accuracy: 0.9695\n",
      "==> New best model saved at epoch 8 with Test Accuracy: 0.9695\n",
      "TP: 1135.0\n",
      "FP: 66.0\n",
      "FN: 0.0\n",
      "TN: 962.0\n",
      "Accuracy: 0.9695\n",
      "Misclassification rate: 0.0305\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9358\n",
      "Precision: 0.9450\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9674\n",
      "F-measure: 0.9717\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9555\n",
      "InvF0.5-measure: 0.9885\n",
      "AGF: 0.9719\n",
      "Balanced Accuracy: 0.9679\n",
      "Matthew's Correlation Coefficient: 0.9404\n",
      "Cohen's Kappa: 0.9386\n",
      "Youden's Index: 0.9358\n",
      "Positive Likelihood Ratio: 15.5758\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 9/20, Train Loss: 0.0001, Train Accuracy: 1.0000, Test Loss: 0.2596, Test Accuracy: 0.9556\n",
      "Epoch: 10/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2570, Test Accuracy: 0.9570\n",
      "Epoch: 11/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2574, Test Accuracy: 0.9579\n",
      "Epoch: 12/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2675, Test Accuracy: 0.9575\n",
      "Epoch: 13/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2650, Test Accuracy: 0.9579\n",
      "Epoch: 14/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2508, Test Accuracy: 0.9602\n",
      "Epoch: 15/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2727, Test Accuracy: 0.9584\n",
      "Epoch: 16/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2681, Test Accuracy: 0.9593\n",
      "Epoch: 17/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2869, Test Accuracy: 0.9584\n",
      "Epoch: 18/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2914, Test Accuracy: 0.9584\n",
      "Epoch: 19/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2963, Test Accuracy: 0.9584\n",
      "Epoch: 20/20, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.3094, Test Accuracy: 0.9579\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 20\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST17_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        # metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.txt\"\n",
    "        # with open(metrics_results_path, \"w\") as f:\n",
    "        #     print(\"Number of label 1 in the final training set: \", len(mnist1_train_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data), file=f)\n",
    "        #     print(\"Number of label 1 in the final test set: \", len(mnist1_test_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final test set: \", len(mnist7_test_data), file=f)\n",
    "\n",
    "        #     print(\"Total samples in final training set: \", len(Final_train_datasets), file=f)\n",
    "        #     print(\"Total samples in final test set: \", len(Final_test_datasets), file=f)\n",
    "\n",
    "        #     print(\"Number of batches in training set: \", len(train_loader), file=f)\n",
    "        #     print(\"Number of batches in test set: \", len(test_loader), file=f)\n",
    "        #     print(f\"TP: {TP}\", file=f)\n",
    "        #     print(f\"FP: {FP}\", file=f)\n",
    "        #     print(f\"FN: {FN}\", file=f)\n",
    "        #     print(f\"TN: {TN}\", file=f)\n",
    "        #     print(f\"Accuracy: {Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Misclassification rate: {misclassification_rate:.4f}\", file=f)\n",
    "        #     print(f\"Sensitivity (Recall): {Sensitivity:.4f}\", file=f)\n",
    "        #     print(f\"Specificity: {Specificity:.4f}\", file=f)\n",
    "        #     print(f\"Precision: {Precision:.4f}\", file=f)\n",
    "        #     print(f\"Negative Predictive Value: {Negative_Predictive_Value:.4f}\", file=f)\n",
    "        #     print(f\"G-mean: {Gmean:.4f}\", file=f)\n",
    "        #     print(f\"F-measure: {Fmean:.4f}\", file=f)\n",
    "        #     print(f\"Discriminant Power (DP): {DPower:.4f}\", file=f)\n",
    "        #     print(f\"F2-measure: {F2measure:.4f}\", file=f)\n",
    "        #     print(f\"InvF0.5-measure: {InvF_05:.4f}\", file=f)\n",
    "        #     print(f\"AGF: {AGFmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Balanced Accuracy: {Balanced_Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Matthew's Correlation Coefficient (MCC): {MCCmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Cohen's Kappa: {Kappa:.4f}\", file=f)\n",
    "        #     print(f\"Youden's Index: {Youden_Index:.4f}\", file=f)\n",
    "        #     print(f\"Positive Likelihood Ratio (LR+): {LR_pos:.4f}\", file=f)\n",
    "        #     print(f\"Negative Likelihood Ratio (LR-): {LR_neg:.4f}\", file=f)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 1 in the final training set\": len(mnist1_train_data),\n",
    "            \"Number of label 7 in the final training set (after downsampling)\": len(fraction_mnist7_train_data),\n",
    "            \"Number of label 1 in the final test set\": len(mnist1_test_data),\n",
    "            \"Number of label 7 in the final test set\": len(mnist7_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
