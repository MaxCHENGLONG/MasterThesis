{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST Label 1 and label 7 /  1->1 7->0 / 1 is positive 7 is negative CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/max/MasterThesis/Training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 1 in the final training set:  6742\n",
      "Number of label 7 in the final training set (after downsampling):  1348\n",
      "Number of label 1 in the final test set:  1135\n",
      "Number of label 7 in the final test set:  1028\n",
      "Total samples in final training set:  8090\n",
      "Total samples in final test set:  2163\n",
      "Number of batches in training set:  127\n",
      "Number of batches in test set:  34\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist17_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist17_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist17_transforms, download=True)\n",
    "\n",
    "# 选取标签为 1 和 7 的索引\n",
    "indices1_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 1]\n",
    "indices7_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 7]\n",
    "\n",
    "indices1_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 1]\n",
    "indices7_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 7]\n",
    "\n",
    "# 获取训练集中标签为 1 和 7 的数据\n",
    "mnist1_train_data = full_train_datasets.data[indices1_train]\n",
    "mnist1_train_labels = torch.ones(len(indices1_train), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_train_data = full_train_datasets.data[indices7_train]\n",
    "mnist7_train_labels = torch.zeros(len(indices7_train), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 1 和 7 的数据\n",
    "mnist1_test_data = full_test_datasets.data[indices1_test]\n",
    "mnist1_test_labels = torch.ones(len(indices1_test), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_test_data = full_test_datasets.data[indices7_test]\n",
    "mnist7_test_labels = torch.zeros(len(indices7_test), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(0.20 * len(mnist1_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_7 = np.random.choice(len(mnist7_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist7_train_data = mnist7_train_data[selected_indices_7]\n",
    "fraction_mnist7_train_labels = mnist7_train_labels[selected_indices_7]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist1_train_data, fraction_mnist7_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist1_train_labels, fraction_mnist7_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist1_test_data, mnist7_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist1_test_labels, mnist7_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 1 in the final training set: \", len(mnist1_train_data))\n",
    "print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data))\n",
    "print(\"Number of label 1 in the final test set: \", len(mnist1_test_data))\n",
    "print(\"Number of label 7 in the final test set: \", len(mnist7_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3373,\n",
      "          0.7725, 1.0000, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922,\n",
      "          0.9843, 0.9922, 0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9961,\n",
      "          0.9922, 0.9961, 0.9922, 0.6627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6588, 0.9922,\n",
      "          0.9843, 0.9922, 0.9843, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.7725, 0.9961,\n",
      "          0.9922, 0.9961, 0.9922, 0.6627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7725, 0.9843, 0.9922,\n",
      "          0.9843, 0.9922, 0.9843, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9961, 0.9922, 0.9961,\n",
      "          0.9922, 0.9961, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.6588, 0.9922, 0.9843, 0.9922,\n",
      "          0.9843, 0.9922, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1137, 0.7725, 0.9961, 0.9922, 0.9961,\n",
      "          0.9922, 0.6627, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.7725, 0.9843, 0.9922, 0.9843, 0.9922,\n",
      "          0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.9961, 0.9922, 0.9961,\n",
      "          0.7686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4471, 0.9922, 0.9843, 0.9922, 0.9843, 0.7686,\n",
      "          0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6627, 0.9961, 0.9922, 0.9961, 0.9922, 0.4471,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6588, 0.9922, 0.9843, 0.9922, 0.9843, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6627, 0.9961, 0.9922, 0.9961, 0.7686, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.2196, 0.9922, 0.9843, 0.9922, 0.3255, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.8863, 0.2196, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9922, 0.9843, 0.6588, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9961, 0.9922, 0.4471, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.9922, 0.9843, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Train Loss: 0.0818, Train Accuracy: 0.9672, Test Loss: 0.0880, Test Accuracy: 0.9732\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.9732\n",
      "TP: 1135.0\n",
      "FP: 58.0\n",
      "FN: 0.0\n",
      "TN: 970.0\n",
      "Accuracy: 0.9732\n",
      "Misclassification rate: 0.0268\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9436\n",
      "Precision: 0.9514\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9714\n",
      "F-measure: 0.9751\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9607\n",
      "InvF0.5-measure: 0.9899\n",
      "AGF: 0.9752\n",
      "Balanced Accuracy: 0.9718\n",
      "Matthew's Correlation Coefficient: 0.9475\n",
      "Cohen's Kappa: 0.9461\n",
      "Youden's Index: 0.9436\n",
      "Positive Likelihood Ratio: 17.7241\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 2/20, Train Loss: 0.0131, Train Accuracy: 0.9968, Test Loss: 0.0310, Test Accuracy: 0.9912\n",
      "==> New best model saved at epoch 2 with Test Accuracy: 0.9912\n",
      "TP: 1134.0\n",
      "FP: 18.0\n",
      "FN: 1.0\n",
      "TN: 1010.0\n",
      "Accuracy: 0.9912\n",
      "Misclassification rate: 0.0088\n",
      "Sensitivity (Recall): 0.9991\n",
      "Specificity: 0.9825\n",
      "Precision: 0.9844\n",
      "Negative Predictive Value: 0.9990\n",
      "G-mean: 0.9908\n",
      "F-measure: 0.9917\n",
      "Discriminant Power: 6.0982\n",
      "F2-measure: 0.9873\n",
      "InvF0.5-measure: 0.9961\n",
      "AGF: 0.9917\n",
      "Balanced Accuracy: 0.9908\n",
      "Matthew's Correlation Coefficient: 0.9825\n",
      "Cohen's Kappa: 0.9824\n",
      "Youden's Index: 0.9816\n",
      "Positive Likelihood Ratio: 57.0608\n",
      "Negative Likelihood Ratio: 0.0009\n",
      "Epoch: 3/20, Train Loss: 0.0107, Train Accuracy: 0.9972, Test Loss: 0.0115, Test Accuracy: 0.9963\n",
      "==> New best model saved at epoch 3 with Test Accuracy: 0.9963\n",
      "TP: 1134.0\n",
      "FP: 7.0\n",
      "FN: 1.0\n",
      "TN: 1021.0\n",
      "Accuracy: 0.9963\n",
      "Misclassification rate: 0.0037\n",
      "Sensitivity (Recall): 0.9991\n",
      "Specificity: 0.9932\n",
      "Precision: 0.9939\n",
      "Negative Predictive Value: 0.9990\n",
      "G-mean: 0.9962\n",
      "F-measure: 0.9965\n",
      "Discriminant Power: 6.6248\n",
      "F2-measure: 0.9949\n",
      "InvF0.5-measure: 0.9981\n",
      "AGF: 0.9965\n",
      "Balanced Accuracy: 0.9962\n",
      "Matthew's Correlation Coefficient: 0.9926\n",
      "Cohen's Kappa: 0.9926\n",
      "Youden's Index: 0.9923\n",
      "Positive Likelihood Ratio: 146.7278\n",
      "Negative Likelihood Ratio: 0.0009\n",
      "Epoch: 4/20, Train Loss: 0.0069, Train Accuracy: 0.9981, Test Loss: 0.0188, Test Accuracy: 0.9940\n",
      "Epoch: 5/20, Train Loss: 0.0060, Train Accuracy: 0.9977, Test Loss: 0.0334, Test Accuracy: 0.9884\n",
      "Epoch: 6/20, Train Loss: 0.0072, Train Accuracy: 0.9975, Test Loss: 0.0152, Test Accuracy: 0.9954\n",
      "Epoch: 7/20, Train Loss: 0.0056, Train Accuracy: 0.9974, Test Loss: 0.0112, Test Accuracy: 0.9958\n",
      "Epoch: 8/20, Train Loss: 0.0041, Train Accuracy: 0.9981, Test Loss: 0.0122, Test Accuracy: 0.9972\n",
      "==> New best model saved at epoch 8 with Test Accuracy: 0.9972\n",
      "TP: 1135.0\n",
      "FP: 6.0\n",
      "FN: 0.0\n",
      "TN: 1022.0\n",
      "Accuracy: 0.9972\n",
      "Misclassification rate: 0.0028\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9942\n",
      "Precision: 0.9947\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9971\n",
      "F-measure: 0.9974\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9958\n",
      "InvF0.5-measure: 0.9989\n",
      "AGF: 0.9974\n",
      "Balanced Accuracy: 0.9971\n",
      "Matthew's Correlation Coefficient: 0.9945\n",
      "Cohen's Kappa: 0.9944\n",
      "Youden's Index: 0.9942\n",
      "Positive Likelihood Ratio: 171.3333\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 9/20, Train Loss: 0.0051, Train Accuracy: 0.9980, Test Loss: 0.0210, Test Accuracy: 0.9949\n",
      "Epoch: 10/20, Train Loss: 0.0044, Train Accuracy: 0.9983, Test Loss: 0.0184, Test Accuracy: 0.9940\n",
      "Epoch: 11/20, Train Loss: 0.0016, Train Accuracy: 0.9994, Test Loss: 0.0159, Test Accuracy: 0.9949\n",
      "Epoch: 12/20, Train Loss: 0.0017, Train Accuracy: 0.9995, Test Loss: 0.0115, Test Accuracy: 0.9968\n",
      "Epoch: 13/20, Train Loss: 0.0014, Train Accuracy: 0.9993, Test Loss: 0.0253, Test Accuracy: 0.9945\n",
      "Epoch: 14/20, Train Loss: 0.0020, Train Accuracy: 0.9994, Test Loss: 0.0116, Test Accuracy: 0.9963\n",
      "Epoch: 15/20, Train Loss: 0.0006, Train Accuracy: 0.9999, Test Loss: 0.0105, Test Accuracy: 0.9968\n",
      "Epoch: 16/20, Train Loss: 0.0012, Train Accuracy: 0.9995, Test Loss: 0.0070, Test Accuracy: 0.9986\n",
      "==> New best model saved at epoch 16 with Test Accuracy: 0.9986\n",
      "TP: 1135.0\n",
      "FP: 3.0\n",
      "FN: 0.0\n",
      "TN: 1025.0\n",
      "Accuracy: 0.9986\n",
      "Misclassification rate: 0.0014\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9971\n",
      "Precision: 0.9974\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9985\n",
      "F-measure: 0.9987\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9979\n",
      "InvF0.5-measure: 0.9995\n",
      "AGF: 0.9987\n",
      "Balanced Accuracy: 0.9985\n",
      "Matthew's Correlation Coefficient: 0.9972\n",
      "Cohen's Kappa: 0.9972\n",
      "Youden's Index: 0.9971\n",
      "Positive Likelihood Ratio: 342.6667\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 17/20, Train Loss: 0.0017, Train Accuracy: 0.9994, Test Loss: 0.0164, Test Accuracy: 0.9949\n",
      "Epoch: 18/20, Train Loss: 0.0017, Train Accuracy: 0.9991, Test Loss: 0.0165, Test Accuracy: 0.9949\n",
      "Epoch: 19/20, Train Loss: 0.0007, Train Accuracy: 0.9996, Test Loss: 0.0190, Test Accuracy: 0.9949\n",
      "Epoch: 20/20, Train Loss: 0.0002, Train Accuracy: 1.0000, Test Loss: 0.0170, Test Accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 20\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST17_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        # metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.txt\"\n",
    "        # with open(metrics_results_path, \"w\") as f:\n",
    "        #     print(\"Number of label 1 in the final training set: \", len(mnist1_train_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data), file=f)\n",
    "        #     print(\"Number of label 1 in the final test set: \", len(mnist1_test_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final test set: \", len(mnist7_test_data), file=f)\n",
    "\n",
    "        #     print(\"Total samples in final training set: \", len(Final_train_datasets), file=f)\n",
    "        #     print(\"Total samples in final test set: \", len(Final_test_datasets), file=f)\n",
    "\n",
    "        #     print(\"Number of batches in training set: \", len(train_loader), file=f)\n",
    "        #     print(\"Number of batches in test set: \", len(test_loader), file=f)\n",
    "        #     print(f\"TP: {TP}\", file=f)\n",
    "        #     print(f\"FP: {FP}\", file=f)\n",
    "        #     print(f\"FN: {FN}\", file=f)\n",
    "        #     print(f\"TN: {TN}\", file=f)\n",
    "        #     print(f\"Accuracy: {Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Misclassification rate: {misclassification_rate:.4f}\", file=f)\n",
    "        #     print(f\"Sensitivity (Recall): {Sensitivity:.4f}\", file=f)\n",
    "        #     print(f\"Specificity: {Specificity:.4f}\", file=f)\n",
    "        #     print(f\"Precision: {Precision:.4f}\", file=f)\n",
    "        #     print(f\"Negative Predictive Value: {Negative_Predictive_Value:.4f}\", file=f)\n",
    "        #     print(f\"G-mean: {Gmean:.4f}\", file=f)\n",
    "        #     print(f\"F-measure: {Fmean:.4f}\", file=f)\n",
    "        #     print(f\"Discriminant Power (DP): {DPower:.4f}\", file=f)\n",
    "        #     print(f\"F2-measure: {F2measure:.4f}\", file=f)\n",
    "        #     print(f\"InvF0.5-measure: {InvF_05:.4f}\", file=f)\n",
    "        #     print(f\"AGF: {AGFmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Balanced Accuracy: {Balanced_Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Matthew's Correlation Coefficient (MCC): {MCCmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Cohen's Kappa: {Kappa:.4f}\", file=f)\n",
    "        #     print(f\"Youden's Index: {Youden_Index:.4f}\", file=f)\n",
    "        #     print(f\"Positive Likelihood Ratio (LR+): {LR_pos:.4f}\", file=f)\n",
    "        #     print(f\"Negative Likelihood Ratio (LR-): {LR_neg:.4f}\", file=f)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 1 in the final training set\": len(mnist1_train_data),\n",
    "            \"Number of label 7 in the final training set (after downsampling)\": len(fraction_mnist7_train_data),\n",
    "            \"Number of label 1 in the final test set\": len(mnist1_test_data),\n",
    "            \"Number of label 7 in the final test set\": len(mnist7_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
