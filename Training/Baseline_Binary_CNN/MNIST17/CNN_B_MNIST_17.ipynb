{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST Label 1 and label 7 /  1->1 7->0 / 1 is positive 7 is negative CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/max/MasterThesis/Training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 1 in the final training set:  6742\n",
      "Number of label 7 in the final training set (after downsampling):  33\n",
      "Number of label 1 in the final test set:  1135\n",
      "Number of label 7 in the final test set:  1028\n",
      "Total samples in final training set:  6775\n",
      "Total samples in final test set:  2163\n",
      "Number of batches in training set:  106\n",
      "Number of batches in test set:  34\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist17_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist17_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist17_transforms, download=True)\n",
    "\n",
    "# 选取标签为 1 和 7 的索引\n",
    "indices1_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 1]\n",
    "indices7_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 7]\n",
    "\n",
    "indices1_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 1]\n",
    "indices7_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 7]\n",
    "\n",
    "# 获取训练集中标签为 1 和 7 的数据\n",
    "mnist1_train_data = full_train_datasets.data[indices1_train]\n",
    "mnist1_train_labels = torch.ones(len(indices1_train), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_train_data = full_train_datasets.data[indices7_train]\n",
    "mnist7_train_labels = torch.zeros(len(indices7_train), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 1 和 7 的数据\n",
    "mnist1_test_data = full_test_datasets.data[indices1_test]\n",
    "mnist1_test_labels = torch.ones(len(indices1_test), dtype=torch.long)  # 标签 1 保持不变\n",
    "\n",
    "mnist7_test_data = full_test_datasets.data[indices7_test]\n",
    "mnist7_test_labels = torch.zeros(len(indices7_test), dtype=torch.long)  # 标签 7 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(0.005 * len(mnist1_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_7 = np.random.choice(len(mnist7_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist7_train_data = mnist7_train_data[selected_indices_7]\n",
    "fraction_mnist7_train_labels = mnist7_train_labels[selected_indices_7]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist1_train_data, fraction_mnist7_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist1_train_labels, fraction_mnist7_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist1_test_data, mnist7_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist1_test_labels, mnist7_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 1 in the final training set: \", len(mnist1_train_data))\n",
    "print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data))\n",
    "print(\"Number of label 1 in the final test set: \", len(mnist1_test_data))\n",
    "print(\"Number of label 7 in the final test set: \", len(mnist7_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.8588, 0.9922, 0.2431,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.5843,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8392, 0.9882, 0.8510,\n",
      "          0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.9882, 0.9922,\n",
      "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.9882, 0.9922,\n",
      "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3451, 0.9882, 0.9922,\n",
      "          0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9882, 0.9922,\n",
      "          0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9882, 0.9922,\n",
      "          0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2824, 0.9882, 0.9922,\n",
      "          0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.9882, 0.9922,\n",
      "          0.7529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7608, 0.9922, 1.0000,\n",
      "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9490, 0.9882, 0.8941,\n",
      "          0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.5843,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.5843,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.7020,\n",
      "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.9922,\n",
      "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9882, 0.9882, 0.9922,\n",
      "          0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.7686, 0.9882, 0.8471,\n",
      "          0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.9882, 0.5843,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4157, 0.6392, 0.2392,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbx0lEQVR4nO3dDUxV5x3H8T++4UsFiqiAIsW32tWXblYt86VYiS91rliX6WYyXYxGhabq1I5lvm1LWN1mGzuHTdZJTVvtbKq2dqGxqLB1aKedY26tFYcDp6h1AwQnOjjL8xjuuAq6ixf+997z/SRPLuft3ofD4fzuc85zzglzHMcRAADaWLu2/kAAAAwCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIuEdnzpyRsLAw+elPf+q39zx06JB9T/MKhCoCCK6Uk5Njd/BHjx6VUHTy5ElZvny5fPnLX5bOnTvb39UEJRBICCAgBBUWFsrmzZvlypUr8tBDD2lXB2gSAQSEoK9+9atSUVEhf/7zn2Xu3Lna1QGaRAABzbh+/bqsXbtWRo4cKZGRkdKtWzcZP368HDx4sNllXnjhBUlMTJQuXbrI448/LidOnLhtnk8//VS+9rWvSXR0tD089uijj8o777xz1/pcvXrVLvv555/fdV7z3t27d/8/fktADwEENKOqqkp++ctfSkpKijz//POyfv16uXTpkkyZMkWOHz9+2/zbt2+3h73S09MlMzPThs8TTzwhFy5c8Mzzl7/8RR577DH55JNP5Lvf/a787Gc/s8GWlpYmu3fvvmN9PvroI3s47ec//3mr/L5AW+vQ5p8IBIn777/fnrjv1KmTZ9zChQtlyJAh8tJLL8krr7ziNX9xcbGcOnVK+vTpY4enTp0qY8aMseG1adMmO+7ZZ5+Vfv36yR/+8AcJDw+345YuXSrjxo2T5557TmbOnNmmvyOgiRYQ0Iz27dt7wqe+vl7++c9/yn/+8x97yOzjjz++bX7TimkIH2P06NE2gH7zm9/YYbP8gQMH5Otf/7rtHGAOpZly+fJl26oy4fWPf/yj2fqYlph5fqRpiQGhgAAC7uDVV1+V4cOH23M1PXr0kJ49e8p7770nlZWVt807aNCg28YNHjzY0/3ZtJBMgKxZs8a+T+Oybt06O8/Fixfb4LcCAgOH4IBmvPbaazJ//nzbslm1apX06tXLtoqysrLk9OnTPr+faUUZK1eutC2epgwcOPCe6w0ECwIIaMZbb70l/fv3l7ffftteyNmgobVyK3MI7VafffaZPPDAA/Zn815Gx44dJTU1tdXqDQQLDsEBzTCtHcMcNmtw5MgRe5FnU/bs2eN1Dsf0WjPzT5s2zQ6bFpQ5j/Pyyy/L+fPnb1ve9LDzVzdsIBjQAoKr/epXv5Lc3Nzbxpveal/5ylds68f0TJs+fbqUlJTI1q1b5Qtf+IJUV1c3efjM9GZbsmSJ1NbWyosvvmjPG61evdozz5YtW+w8w4YNsz3qTKvIdNM2oXb27Fn505/+1GxdTaBNnDjRtsDu1hHBnKMyPfWMDz/80L6a7ttRUVG2ZGRk+LSegNZAAMHVsrOzmxxvzv2YUl5eblss77//vg0ec15o165dTd4k9Fvf+pa0a9fOBo/pTGB6wZmdflxcnGce8x7m/nMbNmyw96MzPeBMy+iLX/yivejVX/71r3/Zzg6NmWuODHOhLAGEQBDmND6+AABAG+EcEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQEXDXAZn7ZZ07d84+TKvx7U8AAMHBXN1j7vgeHx9vr40LmgAy4ZOQkKBdDQDAPSorK5O+ffsGzyE4HiMMAKHhbvvzVgsgc88rcxdg8xwV81Aucx+r/weH3QAgNNxtf94qAfTmm2/KihUr7E0TzZMjR4wYYZ9/wsO2AAAeTisYPXq0k56e7hmuq6tz4uPjnaysrLsuW1lZae5NR6FQKBQJ7mL253fi9xbQ9evX5dixY14P3DK9IMxwU89RMbetr6qq8ioAgNDn9wAyD8uqq6uT3r17e403w+bW9rcyjzeOjIz0FHrAAYA7qPeCy8zMtA/Paiim2x4AIPT5/TqgmJgY+yhj85THxsxwbGzsbfOHh4fbAgBwF7+3gDp16iQjR46UvLw8r7sbmOHk5GR/fxwAIEi1yp0QTBfsefPmyaOPPmofS2weUVxTUyPf/va3W+PjAABBqFUCaPbs2XLp0iX7jHvT8eCRRx6R3Nzc2zomAADcK8z0xZYAYrphm95wAIDgZjqWRUREBG4vOACAOxFAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQ0UHnY4HANHjwYJ+Xee+993xepn///j4vM3HiRJ+XKSgo8HkZoK3QAgIAqCCAAAChEUDr16+XsLAwrzJkyBB/fwwAIMi1yjmghx9+WD744IP/fUgHTjUBALy1SjKYwImNjW2NtwYAhIhWOQd06tQpiY+Ptz195s6dK6Wlpc3OW1tbK1VVVV4FABD6/B5AY8aMkZycHMnNzZXs7GwpKSmR8ePHy5UrV5qcPysrSyIjIz0lISHB31UCAASgMMdxnNb8gIqKCklMTJRNmzbJggULmmwBmdLAtIAIIWjhOiDAfyorKyUiIqLZ6a3eOyAqKsr+UxcXFzc5PTw83BYAgLu0+nVA1dXVcvr0aYmLi2vtjwIAuDmAVq5cKfn5+XLmzBn5/e9/LzNnzpT27dvLN77xDX9/FAAgiPn9ENzZs2dt2Fy+fFl69uwp48aNk8OHD9ufAQBotQDauXOnv98SaDMjR470eZmkpCSfl2lJ35/Zs2f7vAydEBDIuBccAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFa3+QDogmBQWFvq8zGeffdYmT15NTU31eZmWPl24rKysRcsBvqAFBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQwd2wgUbOnDnj8zKXLl1qk7thDxw40OdlIiMjfV7G4G7YaAu0gAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKjrofCwQOrKzs31eZuzYsdIWoqKi2uRzgJagBQQAUEEAAQCCI4AKCgpkxowZEh8fL2FhYbJnzx6v6Y7jyNq1ayUuLk66dOkiqampcurUKX/WGQDgxgCqqamRESNGyJYtW5qcvnHjRtm8ebNs3bpVjhw5It26dZMpU6bItWvX/FFfAIBbOyFMmzbNlqaY1s+LL74o3//+9+Wpp56y47Zv3y69e/e2LaU5c+bce40BACHBr+eASkpKpLy83B52axAZGSljxoyRwsLCJpepra2VqqoqrwIACH1+DSATPoZp8TRmhhum3SorK8uGVENJSEjwZ5UAAAFKvRdcZmamVFZWekpZWZl2lQAAwRZAsbGx9vXChQte481ww7RbhYeHS0REhFcBAIQ+vwZQUlKSDZq8vDzPOHNOx/SGS05O9udHAQDc1guuurpaiouLvToeHD9+XKKjo6Vfv36ybNky+dGPfiSDBg2ygbRmzRp7zVBaWpq/6w4AcFMAHT16VCZOnOgZXrFihX2dN2+e5OTkyOrVq+21QosWLZKKigoZN26c5ObmSufOnf1bcwBAUAtzzMU7AcQcsjO94YBgMXToUJ+XMUcNfGXuPOKr3/72t9ISKSkpLVoOaMx0LLvTeX31XnAAAHcigAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKjrofCwQOvr27atdBSAo0QICAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACggpuRAvcoMzNTuwpAUKIFBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAU3IwXuUVhYWJss066d798XMzIyfF4GaCu0gAAAKgggAEBwBFBBQYHMmDFD4uPj7WGEPXv2eE2fP3++Hd+4TJ061Z91BgC4MYBqampkxIgRsmXLlmbnMYFz/vx5T9mxY8e91hMA4PZOCNOmTbPlTsLDwyU2NvZe6gUACHGtcg7o0KFD0qtXL3nwwQdlyZIlcvny5Wbnra2tlaqqKq8CAAh9fg8gc/ht+/btkpeXJ88//7zk5+fbFlNdXV2T82dlZUlkZKSnJCQk+LtKAAA3XAc0Z84cz8/Dhg2T4cOHy4ABA2yraNKkSbfNn5mZKStWrPAMmxYQIQQAoa/Vu2H3799fYmJipLi4uNnzRREREV4FABD6Wj2Azp49a88BxcXFtfZHAQBC+RBcdXW1V2umpKREjh8/LtHR0bZs2LBBZs2aZXvBnT59WlavXi0DBw6UKVOm+LvuAAA3BdDRo0dl4sSJnuGG8zfz5s2T7OxsKSoqkldffVUqKirsxaqTJ0+WH/7wh/ZQGwAALQ6glJQUcRyn2envv/++r28JBIzp06f7vMwjjzzi8zJ3+h+60+FsX129etXnZYC2wr3gAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAACh8UhuIJi15Im8Xbt2lbbwzjvv+LzM3/72t1apC+APtIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACo66HwsAF/169fP52W6d+/eos+6cuVKi5YDfEELCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgApuRgoEiSeffNLnZRITE1v0WSdOnGjRcoAvaAEBAFQQQACAwA+grKwsGTVqlH3GSK9evSQtLU1OnjzpNc+1a9ckPT1devToIffdd5/MmjVLLly44O96AwDcFED5+fk2XA4fPiz79++XGzduyOTJk6WmpsYzz/Lly+Xdd9+VXbt22fnPnTsnTz/9dGvUHQDglk4Iubm5XsM5OTm2JXTs2DGZMGGCVFZWyiuvvCJvvPGGPPHEE3aebdu2yUMPPWRD67HHHvNv7QEA7jwHZALHiI6Otq8miEyrKDU11TPPkCFD7KOECwsLm3yP2tpaqaqq8ioAgNDX4gCqr6+XZcuWydixY2Xo0KF2XHl5uXTq1EmioqK85u3du7ed1tx5pcjISE9JSEhoaZUAAG4IIHMuyFwrsHPnznuqQGZmpm1JNZSysrJ7ej8AQAhfiJqRkSH79u2TgoIC6du3r2d8bGysXL9+XSoqKrxaQaYXnJnWlPDwcFsAAO7iUwvIcRwbPrt375YDBw5IUlKS1/SRI0dKx44dJS8vzzPOdNMuLS2V5ORk/9UaAOCuFpA57GZ6uO3du9deC9RwXsecu+nSpYt9XbBggaxYscJ2TIiIiJBnnnnGhg894AAALQ6g7Oxs+5qSkuI13nS1nj9/vv35hRdekHbt2tkLUE0PtylTpsgvfvELXz4GAOACHXw9BHc3nTt3li1bttgCAEBzuBccAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQACB4nogKhKq33nrL52WWLl3q8zIteUDjqVOnfF7GPJ0YCFS0gAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKjgZqRAIzdu3PB5mfr6emkLeXl5Pi9z9uzZVqkL4A+0gAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKjgZqTAPdq5c6fPy5SWlvq8zI4dO3xeBghktIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoCHMcx5EAUlVVJZGRkdrVAADco8rKSomIiGh2Oi0gAIAKAggAEPgBlJWVJaNGjZLu3btLr169JC0tTU6ePOk1T0pKioSFhXmVxYsX+7veAAA3BVB+fr6kp6fL4cOHZf/+/XLjxg2ZPHmy1NTUeM23cOFCOX/+vKds3LjR3/UGALjpiai5ublewzk5ObYldOzYMZkwYYJnfNeuXSU2NtZ/tQQAhJx299rDwYiOjvYa//rrr0tMTIwMHTpUMjMz5erVq82+R21tre351rgAAFzAaaG6ujpn+vTpztixY73Gv/zyy05ubq5TVFTkvPbaa06fPn2cmTNnNvs+69atM93AKRQKhSKhVSorK++YIy0OoMWLFzuJiYlOWVnZHefLy8uzFSkuLm5y+rVr12wlG4p5P+2VRqFQKBRp9QDy6RxQg4yMDNm3b58UFBRI37597zjvmDFj7GtxcbEMGDDgtunh4eG2AADcxacAMi2mZ555Rnbv3i2HDh2SpKSkuy5z/Phx+xoXF9fyWgIA3B1Apgv2G2+8IXv37rXXApWXl9vx5tY5Xbp0kdOnT9vpTz75pPTo0UOKiopk+fLltofc8OHDW+t3AAAEI1/O+zR3nG/btm12emlpqTNhwgQnOjraCQ8PdwYOHOisWrXqrscBGzPzah+3pFAoFIrcc7nbvp+bkQIAWgU3IwUABCQCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgIqACyDHcbSrAABog/15wAXQlStXtKsAAGiD/XmYE2BNjvr6ejl37px0795dwsLCvKZVVVVJQkKClJWVSUREhLgV6+Em1sNNrIebWA+Bsx5MrJjwiY+Pl3btmm/ndJAAYyrbt2/fO85jVqqbN7AGrIebWA83sR5uYj0ExnqIjIy86zwBdwgOAOAOBBAAQEVQBVB4eLisW7fOvroZ6+Em1sNNrIebWA/Btx4CrhMCAMAdgqoFBAAIHQQQAEAFAQQAUEEAAQBUEEAAABVBE0BbtmyRBx54QDp37ixjxoyRjz76SLtKbW79+vX29kSNy5AhQyTUFRQUyIwZM+xtPczvvGfPHq/ppiPn2rVrJS4uTrp06SKpqaly6tQpcdt6mD9//m3bx9SpUyWUZGVlyahRo+ytunr16iVpaWly8uRJr3muXbsm6enp0qNHD7nvvvtk1qxZcuHCBXHbekhJSblte1i8eLEEkqAIoDfffFNWrFhh+7Z//PHHMmLECJkyZYpcvHhR3Obhhx+W8+fPe8rvfvc7CXU1NTX2b26+hDRl48aNsnnzZtm6dascOXJEunXrZrcPsyNy03owTOA03j527NghoSQ/P9+Gy+HDh2X//v1y48YNmTx5sl03DZYvXy7vvvuu7Nq1y85v7i359NNPi9vWg7Fw4UKv7cH8rwQUJwiMHj3aSU9P9wzX1dU58fHxTlZWluMm69atc0aMGOG4mdlkd+/e7Rmur693YmNjnZ/85CeecRUVFU54eLizY8cOxy3rwZg3b57z1FNPOW5y8eJFuy7y8/M9f/uOHTs6u3bt8szzySef2HkKCwsdt6wH4/HHH3eeffZZJ5AFfAvo+vXrcuzYMXtYpfENS81wYWGhuI05tGQOwfTv31/mzp0rpaWl4mYlJSVSXl7utX2YmyCaw7Ru3D4OHTpkD8k8+OCDsmTJErl8+bKEssrKSvsaHR1tX82+wrQGGm8P5jB1v379Qnp7qLxlPTR4/fXXJSYmRoYOHSqZmZly9epVCSQBdzfsW33++edSV1cnvXv39hpvhj/99FNxE7NTzcnJsTsX05zesGGDjB8/Xk6cOGGPBbuRCR+jqe2jYZpbmMNv5lBTUlKSnD59Wr73ve/JtGnT7I63ffv2EmrMo1uWLVsmY8eOtTtYw/zNO3XqJFFRUa7ZHuqbWA/GN7/5TUlMTLRfWIuKiuS5556z54nefvttCRQBH0D4H7MzaTB8+HAbSGYD+/Wvfy0LFixQrRv0zZkzx/PzsGHD7DYyYMAA2yqaNGmShBpzDsR8+XLDedCWrIdFixZ5bQ+mk47ZDsyXE7NdBIKAPwRnmo/m29utvVjMcGxsrLiZ+ZY3ePBgKS4uFrdq2AbYPm5nDtOa/59Q3D4yMjJk3759cvDgQa/nh5m/uTlsX1FR4YrtIaOZ9dAU84XVCKTtIeADyDSnR44cKXl5eV5NTjOcnJwsblZdXW2/zZhvNm5lDjeZHUvj7cM8EdL0hnP79nH27Fl7DiiUtg/T/8LsdHfv3i0HDhywf//GzL6iY8eOXtuDOexkzpWG0vbg3GU9NOX48eP2NaC2BycI7Ny50/ZqysnJcf761786ixYtcqKiopzy8nLHTb7zne84hw4dckpKSpwPP/zQSU1NdWJiYmwPmFB25coV549//KMtZpPdtGmT/fnvf/+7nf7jH//Ybg979+51ioqKbE+wpKQk59///rfjlvVgpq1cudL29DLbxwcffOB86UtfcgYNGuRcu3bNCRVLlixxIiMj7f/B+fPnPeXq1aueeRYvXuz069fPOXDggHP06FEnOTnZllCy5C7robi42PnBD35gf3+zPZj/jf79+zsTJkxwAklQBJDx0ksv2Y2qU6dOtlv24cOHHbeZPXu2ExcXZ9dBnz597LDZ0ELdwYMH7Q731mK6HTd0xV6zZo3Tu3dv+0Vl0qRJzsmTJx03rQez45k8ebLTs2dP2w05MTHRWbhwYch9SWvq9zdl27ZtnnnMF4+lS5c6999/v9O1a1dn5syZdufspvVQWlpqwyY6Otr+TwwcONBZtWqVU1lZ6QQSngcEAFAR8OeAAAChiQACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAACi4b9W8JGlP3lSFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.0583, Train Accuracy: 0.9951, Test Loss: 1.7637, Test Accuracy: 0.5247\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.5247\n",
      "TP: 1135.0\n",
      "FP: 1028.0\n",
      "FN: 0.0\n",
      "TN: 0.0\n",
      "Accuracy: 0.5247\n",
      "Misclassification rate: 0.4753\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.0000\n",
      "Precision: 0.5247\n",
      "Negative Predictive Value: inf\n",
      "G-mean: 0.0000\n",
      "F-measure: 0.6883\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.5799\n",
      "InvF0.5-measure: 0.8466\n",
      "AGF: 0.7007\n",
      "Balanced Accuracy: 0.5000\n",
      "Matthew's Correlation Coefficient: -999999999.0000\n",
      "Cohen's Kappa: 0.0000\n",
      "Youden's Index: 0.0000\n",
      "Positive Likelihood Ratio: 1.0000\n",
      "Negative Likelihood Ratio: -99999999.0000\n",
      "Epoch: 2/50, Train Loss: 0.0119, Train Accuracy: 0.9963, Test Loss: 0.2230, Test Accuracy: 0.9519\n",
      "==> New best model saved at epoch 2 with Test Accuracy: 0.9519\n",
      "TP: 1135.0\n",
      "FP: 104.0\n",
      "FN: 0.0\n",
      "TN: 924.0\n",
      "Accuracy: 0.9519\n",
      "Misclassification rate: 0.0481\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8988\n",
      "Precision: 0.9161\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9481\n",
      "F-measure: 0.9562\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9317\n",
      "InvF0.5-measure: 0.9820\n",
      "AGF: 0.9565\n",
      "Balanced Accuracy: 0.9494\n",
      "Matthew's Correlation Coefficient: 0.9074\n",
      "Cohen's Kappa: 0.9031\n",
      "Youden's Index: 0.8988\n",
      "Positive Likelihood Ratio: 9.8846\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 3/50, Train Loss: 0.0055, Train Accuracy: 0.9984, Test Loss: 0.1919, Test Accuracy: 0.9496\n",
      "Epoch: 4/50, Train Loss: 0.0034, Train Accuracy: 0.9985, Test Loss: 0.1734, Test Accuracy: 0.9575\n",
      "==> New best model saved at epoch 4 with Test Accuracy: 0.9575\n",
      "TP: 1135.0\n",
      "FP: 92.0\n",
      "FN: 0.0\n",
      "TN: 936.0\n",
      "Accuracy: 0.9575\n",
      "Misclassification rate: 0.0425\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9105\n",
      "Precision: 0.9250\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9542\n",
      "F-measure: 0.9610\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9391\n",
      "InvF0.5-measure: 0.9840\n",
      "AGF: 0.9613\n",
      "Balanced Accuracy: 0.9553\n",
      "Matthew's Correlation Coefficient: 0.9177\n",
      "Cohen's Kappa: 0.9144\n",
      "Youden's Index: 0.9105\n",
      "Positive Likelihood Ratio: 11.1739\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 5/50, Train Loss: 0.0025, Train Accuracy: 0.9991, Test Loss: 0.1723, Test Accuracy: 0.9519\n",
      "Epoch: 6/50, Train Loss: 0.0019, Train Accuracy: 0.9997, Test Loss: 0.0744, Test Accuracy: 0.9792\n",
      "==> New best model saved at epoch 6 with Test Accuracy: 0.9792\n",
      "TP: 1135.0\n",
      "FP: 45.0\n",
      "FN: 0.0\n",
      "TN: 983.0\n",
      "Accuracy: 0.9792\n",
      "Misclassification rate: 0.0208\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9562\n",
      "Precision: 0.9619\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9779\n",
      "F-measure: 0.9806\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9693\n",
      "InvF0.5-measure: 0.9921\n",
      "AGF: 0.9806\n",
      "Balanced Accuracy: 0.9781\n",
      "Matthew's Correlation Coefficient: 0.9590\n",
      "Cohen's Kappa: 0.9582\n",
      "Youden's Index: 0.9562\n",
      "Positive Likelihood Ratio: 22.8444\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 7/50, Train Loss: 0.0020, Train Accuracy: 0.9994, Test Loss: 0.6893, Test Accuracy: 0.8544\n",
      "Epoch: 8/50, Train Loss: 0.0027, Train Accuracy: 0.9990, Test Loss: 0.0929, Test Accuracy: 0.9769\n",
      "Epoch: 9/50, Train Loss: 0.0014, Train Accuracy: 0.9996, Test Loss: 0.1409, Test Accuracy: 0.9663\n",
      "Epoch: 10/50, Train Loss: 0.0007, Train Accuracy: 0.9997, Test Loss: 0.1931, Test Accuracy: 0.9616\n",
      "Epoch: 11/50, Train Loss: 0.0005, Train Accuracy: 0.9999, Test Loss: 0.1036, Test Accuracy: 0.9797\n",
      "==> New best model saved at epoch 11 with Test Accuracy: 0.9797\n",
      "TP: 1135.0\n",
      "FP: 44.0\n",
      "FN: 0.0\n",
      "TN: 984.0\n",
      "Accuracy: 0.9797\n",
      "Misclassification rate: 0.0203\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9572\n",
      "Precision: 0.9627\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9784\n",
      "F-measure: 0.9810\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9699\n",
      "InvF0.5-measure: 0.9923\n",
      "AGF: 0.9810\n",
      "Balanced Accuracy: 0.9786\n",
      "Matthew's Correlation Coefficient: 0.9599\n",
      "Cohen's Kappa: 0.9591\n",
      "Youden's Index: 0.9572\n",
      "Positive Likelihood Ratio: 23.3636\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 12/50, Train Loss: 0.0004, Train Accuracy: 0.9999, Test Loss: 0.0840, Test Accuracy: 0.9843\n",
      "==> New best model saved at epoch 12 with Test Accuracy: 0.9843\n",
      "TP: 1135.0\n",
      "FP: 34.0\n",
      "FN: 0.0\n",
      "TN: 994.0\n",
      "Accuracy: 0.9843\n",
      "Misclassification rate: 0.0157\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9669\n",
      "Precision: 0.9709\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9833\n",
      "F-measure: 0.9852\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9766\n",
      "InvF0.5-measure: 0.9940\n",
      "AGF: 0.9853\n",
      "Balanced Accuracy: 0.9835\n",
      "Matthew's Correlation Coefficient: 0.9689\n",
      "Cohen's Kappa: 0.9684\n",
      "Youden's Index: 0.9669\n",
      "Positive Likelihood Ratio: 30.2353\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 13/50, Train Loss: 0.0012, Train Accuracy: 0.9996, Test Loss: 0.0558, Test Accuracy: 0.9880\n",
      "==> New best model saved at epoch 13 with Test Accuracy: 0.9880\n",
      "TP: 1135.0\n",
      "FP: 26.0\n",
      "FN: 0.0\n",
      "TN: 1002.0\n",
      "Accuracy: 0.9880\n",
      "Misclassification rate: 0.0120\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9747\n",
      "Precision: 0.9776\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9873\n",
      "F-measure: 0.9887\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9820\n",
      "InvF0.5-measure: 0.9954\n",
      "AGF: 0.9887\n",
      "Balanced Accuracy: 0.9874\n",
      "Matthew's Correlation Coefficient: 0.9762\n",
      "Cohen's Kappa: 0.9759\n",
      "Youden's Index: 0.9747\n",
      "Positive Likelihood Ratio: 39.5385\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 14/50, Train Loss: 0.0004, Train Accuracy: 1.0000, Test Loss: 0.1024, Test Accuracy: 0.9810\n",
      "Epoch: 15/50, Train Loss: 0.0001, Train Accuracy: 1.0000, Test Loss: 0.1625, Test Accuracy: 0.9713\n",
      "Epoch: 16/50, Train Loss: 0.0001, Train Accuracy: 1.0000, Test Loss: 0.1456, Test Accuracy: 0.9750\n",
      "Epoch: 17/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1530, Test Accuracy: 0.9750\n",
      "Epoch: 18/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1574, Test Accuracy: 0.9750\n",
      "Epoch: 19/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1537, Test Accuracy: 0.9760\n",
      "Epoch: 20/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1647, Test Accuracy: 0.9750\n",
      "Epoch: 21/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1635, Test Accuracy: 0.9755\n",
      "Epoch: 22/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1675, Test Accuracy: 0.9755\n",
      "Epoch: 23/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1721, Test Accuracy: 0.9755\n",
      "Epoch: 24/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1763, Test Accuracy: 0.9755\n",
      "Epoch: 25/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1851, Test Accuracy: 0.9746\n",
      "Epoch: 26/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1808, Test Accuracy: 0.9755\n",
      "Epoch: 27/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1826, Test Accuracy: 0.9755\n",
      "Epoch: 28/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1807, Test Accuracy: 0.9764\n",
      "Epoch: 29/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1893, Test Accuracy: 0.9755\n",
      "Epoch: 30/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1861, Test Accuracy: 0.9760\n",
      "Epoch: 31/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1892, Test Accuracy: 0.9760\n",
      "Epoch: 32/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1923, Test Accuracy: 0.9760\n",
      "Epoch: 33/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1954, Test Accuracy: 0.9760\n",
      "Epoch: 34/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1940, Test Accuracy: 0.9760\n",
      "Epoch: 35/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.1980, Test Accuracy: 0.9760\n",
      "Epoch: 36/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2022, Test Accuracy: 0.9760\n",
      "Epoch: 37/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2039, Test Accuracy: 0.9760\n",
      "Epoch: 38/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2036, Test Accuracy: 0.9760\n",
      "Epoch: 39/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2078, Test Accuracy: 0.9760\n",
      "Epoch: 40/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2057, Test Accuracy: 0.9764\n",
      "Epoch: 41/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2099, Test Accuracy: 0.9764\n",
      "Epoch: 42/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2123, Test Accuracy: 0.9764\n",
      "Epoch: 43/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2077, Test Accuracy: 0.9769\n",
      "Epoch: 44/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2118, Test Accuracy: 0.9764\n",
      "Epoch: 45/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2213, Test Accuracy: 0.9760\n",
      "Epoch: 46/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2221, Test Accuracy: 0.9764\n",
      "Epoch: 47/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2261, Test Accuracy: 0.9755\n",
      "Epoch: 48/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2228, Test Accuracy: 0.9764\n",
      "Epoch: 49/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2188, Test Accuracy: 0.9769\n",
      "Epoch: 50/50, Train Loss: 0.0000, Train Accuracy: 1.0000, Test Loss: 0.2191, Test Accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 50\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST17_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        # metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.txt\"\n",
    "        # with open(metrics_results_path, \"w\") as f:\n",
    "        #     print(\"Number of label 1 in the final training set: \", len(mnist1_train_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data), file=f)\n",
    "        #     print(\"Number of label 1 in the final test set: \", len(mnist1_test_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final test set: \", len(mnist7_test_data), file=f)\n",
    "\n",
    "        #     print(\"Total samples in final training set: \", len(Final_train_datasets), file=f)\n",
    "        #     print(\"Total samples in final test set: \", len(Final_test_datasets), file=f)\n",
    "\n",
    "        #     print(\"Number of batches in training set: \", len(train_loader), file=f)\n",
    "        #     print(\"Number of batches in test set: \", len(test_loader), file=f)\n",
    "        #     print(f\"TP: {TP}\", file=f)\n",
    "        #     print(f\"FP: {FP}\", file=f)\n",
    "        #     print(f\"FN: {FN}\", file=f)\n",
    "        #     print(f\"TN: {TN}\", file=f)\n",
    "        #     print(f\"Accuracy: {Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Misclassification rate: {misclassification_rate:.4f}\", file=f)\n",
    "        #     print(f\"Sensitivity (Recall): {Sensitivity:.4f}\", file=f)\n",
    "        #     print(f\"Specificity: {Specificity:.4f}\", file=f)\n",
    "        #     print(f\"Precision: {Precision:.4f}\", file=f)\n",
    "        #     print(f\"Negative Predictive Value: {Negative_Predictive_Value:.4f}\", file=f)\n",
    "        #     print(f\"G-mean: {Gmean:.4f}\", file=f)\n",
    "        #     print(f\"F-measure: {Fmean:.4f}\", file=f)\n",
    "        #     print(f\"Discriminant Power (DP): {DPower:.4f}\", file=f)\n",
    "        #     print(f\"F2-measure: {F2measure:.4f}\", file=f)\n",
    "        #     print(f\"InvF0.5-measure: {InvF_05:.4f}\", file=f)\n",
    "        #     print(f\"AGF: {AGFmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Balanced Accuracy: {Balanced_Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Matthew's Correlation Coefficient (MCC): {MCCmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Cohen's Kappa: {Kappa:.4f}\", file=f)\n",
    "        #     print(f\"Youden's Index: {Youden_Index:.4f}\", file=f)\n",
    "        #     print(f\"Positive Likelihood Ratio (LR+): {LR_pos:.4f}\", file=f)\n",
    "        #     print(f\"Negative Likelihood Ratio (LR-): {LR_neg:.4f}\", file=f)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 1 in the final training set\": len(mnist1_train_data),\n",
    "            \"Number of label 7 in the final training set (after downsampling)\": len(fraction_mnist7_train_data),\n",
    "            \"Number of label 1 in the final test set\": len(mnist1_test_data),\n",
    "            \"Number of label 7 in the final test set\": len(mnist7_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
