{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary MNIST Label 3 and label 4 /  3->1 4->0 / 3 is positive 4 is negative CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/max/MasterThesis/Training/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of label 3 in the final training set:  6131\n",
      "Number of label 4 in the final training set (after downsampling):  30\n",
      "Number of label 3 in the final test set:  1010\n",
      "Number of label 4 in the final test set:  982\n",
      "Total samples in final training set:  6161\n",
      "Total samples in final test set:  1992\n",
      "Number of batches in training set:  97\n",
      "Number of batches in test set:  32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理\n",
    "mnist34_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "full_train_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=True, transform=mnist34_transforms, download=True)\n",
    "full_test_datasets = datasets.MNIST(root=\"/Users/max/MasterThesisData/MNIST\", train=False, transform=mnist34_transforms, download=True)\n",
    "\n",
    "# 选取标签为 3 和 4 的索引\n",
    "indices3_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 3]\n",
    "indices4_train = [i for i in range(len(full_train_datasets)) if full_train_datasets.targets[i] == 4]\n",
    "\n",
    "indices3_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 3]\n",
    "indices4_test = [i for i in range(len(full_test_datasets)) if full_test_datasets.targets[i] == 4]\n",
    "\n",
    "# 获取训练集中标签为 3 和 4 的数据\n",
    "mnist3_train_data = full_train_datasets.data[indices3_train]\n",
    "mnist3_train_labels = torch.ones(len(indices3_train), dtype=torch.long)  # 标签 3 映射为 1 \n",
    "\n",
    "mnist4_train_data = full_train_datasets.data[indices4_train]\n",
    "mnist4_train_labels = torch.zeros(len(indices4_train), dtype=torch.long)  # 标签 4 映射为 0\n",
    "\n",
    "# 获取测试集中标签为 3 和 4 的数据\n",
    "mnist3_test_data = full_test_datasets.data[indices3_test]\n",
    "mnist3_test_labels = torch.ones(len(indices3_test), dtype=torch.long)  # 标签 3 映射为 1 \n",
    "\n",
    "mnist4_test_data = full_test_datasets.data[indices4_test]\n",
    "mnist4_test_labels = torch.zeros(len(indices4_test), dtype=torch.long)  # 标签 4 映射为 0\n",
    "\n",
    "# we can set the imbalanced ratio 0.005, 0.01, 0.02, 0.05, 0.1, 0.2\n",
    "fraction = int(0.005 * len(mnist3_train_data))  ### control the fraction of the data to be used\n",
    "selected_indices_4 = np.random.choice(len(mnist4_train_data), fraction, replace=False)\n",
    "\n",
    "fraction_mnist4_train_data = mnist4_train_data[selected_indices_4]\n",
    "fraction_mnist4_train_labels = mnist4_train_labels[selected_indices_4]\n",
    "\n",
    "# 创建最终的训练和测试数据集\n",
    "Final_train_data = torch.cat([mnist3_train_data, fraction_mnist4_train_data], dim=0)\n",
    "Final_train_labels = torch.cat([mnist3_train_labels, fraction_mnist4_train_labels], dim=0)\n",
    "\n",
    "Final_test_data = torch.cat([mnist3_test_data, mnist4_test_data], dim=0)\n",
    "Final_test_labels = torch.cat([mnist3_test_labels, mnist4_test_labels], dim=0)\n",
    "\n",
    "# 创建 TensorDataset\n",
    "Final_train_datasets = TensorDataset(Final_train_data.unsqueeze(1).float() / 255, Final_train_labels)\n",
    "Final_test_datasets = TensorDataset(Final_test_data.unsqueeze(1).float() / 255, Final_test_labels)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(Final_train_datasets, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Final_test_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "# 打印信息\n",
    "print(\"Number of label 3 in the final training set: \", len(mnist3_train_data))\n",
    "print(\"Number of label 4 in the final training set (after downsampling): \", len(fraction_mnist4_train_data))\n",
    "print(\"Number of label 3 in the final test set: \", len(mnist3_test_data))\n",
    "print(\"Number of label 4 in the final test set: \", len(mnist4_test_data))\n",
    "\n",
    "print(\"Total samples in final training set: \", len(Final_train_datasets))\n",
    "print(\"Total samples in final test set: \", len(Final_test_datasets))\n",
    "\n",
    "print(\"Number of batches in training set: \", len(train_loader))\n",
    "print(\"Number of batches in test set: \", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.4824, 0.9647,\n",
      "          0.5137, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.7020, 0.9961, 0.9961,\n",
      "          0.9961, 0.9176, 0.2941, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0588, 0.6471, 0.9490, 0.9961, 0.9961, 0.9529,\n",
      "          0.6510, 0.9686, 1.0000, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3882, 0.9961, 0.9961, 0.8784, 0.5333, 0.0314,\n",
      "          0.0000, 0.9176, 0.9961, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1765, 0.5882, 0.4235, 0.0392, 0.0000, 0.0000,\n",
      "          0.0000, 0.9176, 0.9961, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1882, 0.9804, 0.9961, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6471, 0.9961, 0.9647, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
      "          0.9451, 0.9961, 0.5255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.8745,\n",
      "          0.9961, 0.7765, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1922, 0.4941, 0.7725, 0.9765, 0.9961,\n",
      "          0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0784, 0.9098, 0.9961, 0.9961, 0.9961, 0.9373,\n",
      "          0.9961, 0.8157, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0706, 0.9059, 0.9608, 0.6275, 0.1882, 0.1765,\n",
      "          0.9490, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1059, 0.1059, 0.0000, 0.0000, 0.0000,\n",
      "          0.6157, 0.9961, 0.7765, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.5725, 0.9961, 0.7490, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.8706, 0.9961, 0.6392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4941,\n",
      "          0.9922, 0.9961, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5373, 0.1686, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4235, 0.9529,\n",
      "          0.9961, 0.6549, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.8353, 0.4902, 0.2706,\n",
      "          0.0000, 0.0000, 0.0000, 0.1490, 0.4667, 0.9059, 0.9922, 0.9961,\n",
      "          0.6510, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.7176, 0.9961, 0.9961,\n",
      "          0.9686, 0.9686, 0.9686, 0.9843, 0.9961, 0.9961, 0.9294, 0.3216,\n",
      "          0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.2863, 0.7020,\n",
      "          0.9961, 0.9961, 0.9961, 0.9451, 0.6706, 0.3255, 0.0118, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 获取一个 batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 查看 Tensor 形状\n",
    "print(f\"Images shape: {images.shape}\")  # 形状为 (batch_size, channels, height, width)\n",
    "print(f\"Labels shape: {labels.shape}\")  # 形状为 (batch_size,)\n",
    "\n",
    "# 查看第一个样本的 Tensor 值\n",
    "print(f\"First image tensor:\\n{images[0]}\")  # 打印第一个样本的 Tensor 数据\n",
    "print(f\"First image label: {labels[0]}\")  # 打印第一个样本的标签\n",
    "\n",
    "# 如果需要转换回 NumPy 并可视化：\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 转换为 NumPy 并显示\n",
    "plt.imshow(images[0].squeeze().numpy(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " # 指定图片大小，图像大小为20宽、5高的绘图(单位为英寸inch)\n",
    "plt.figure(figsize=(20, 5)) \n",
    "for i, imgs in enumerate(images[:20]):\n",
    "    # 维度缩减\n",
    "    npimg = np.squeeze(imgs.numpy())\n",
    "    # 将整个figure分成2行10列，绘制第i+1个子图。\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(npimg, cmap=plt.cm.binary)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryCNN1                               --\n",
       "├─Conv2d: 1-1                            320\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            18,496\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            102,464\n",
       "├─Linear: 1-6                            130\n",
       "=================================================================\n",
       "Total params: 121,410\n",
       "Trainable params: 121,410\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from CNN1 import BinaryCNN1\n",
    "# 将模型转移到GPU中（我们模型运行均在GPU中进行）\n",
    "model = BinaryCNN1().to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.0512, Train Accuracy: 0.9951, Test Loss: 2.3123, Test Accuracy: 0.5070\n",
      "==> New best model saved at epoch 1 with Test Accuracy: 0.5070\n",
      "TP: 1010.0\n",
      "FP: 982.0\n",
      "FN: 0.0\n",
      "TN: 0.0\n",
      "Accuracy: 0.5070\n",
      "Misclassification rate: 0.4930\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.0000\n",
      "Precision: 0.5070\n",
      "Negative Predictive Value: inf\n",
      "G-mean: 0.0000\n",
      "F-measure: 0.6729\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.5625\n",
      "InvF0.5-measure: 0.8372\n",
      "AGF: 0.6862\n",
      "Balanced Accuracy: 0.5000\n",
      "Matthew's Correlation Coefficient: -999999999.0000\n",
      "Cohen's Kappa: 0.0000\n",
      "Youden's Index: 0.0000\n",
      "Positive Likelihood Ratio: 1.0000\n",
      "Negative Likelihood Ratio: -99999999.0000\n",
      "Epoch: 2/50, Train Loss: 0.0104, Train Accuracy: 0.9951, Test Loss: 0.7510, Test Accuracy: 0.5070\n",
      "Epoch: 3/50, Train Loss: 0.0054, Train Accuracy: 0.9951, Test Loss: 0.4010, Test Accuracy: 0.5070\n",
      "Epoch: 4/50, Train Loss: 0.0054, Train Accuracy: 0.9951, Test Loss: 0.5155, Test Accuracy: 0.5070\n",
      "Epoch: 5/50, Train Loss: 0.0041, Train Accuracy: 0.9951, Test Loss: 0.4669, Test Accuracy: 0.5070\n",
      "Epoch: 6/50, Train Loss: 0.0039, Train Accuracy: 0.9951, Test Loss: 0.5055, Test Accuracy: 0.5070\n",
      "Epoch: 7/50, Train Loss: 0.0036, Train Accuracy: 0.9951, Test Loss: 0.5656, Test Accuracy: 0.5070\n",
      "Epoch: 8/50, Train Loss: 0.0035, Train Accuracy: 0.9951, Test Loss: 0.5429, Test Accuracy: 0.5070\n",
      "Epoch: 9/50, Train Loss: 0.0034, Train Accuracy: 0.9984, Test Loss: 0.4896, Test Accuracy: 0.8760\n",
      "==> New best model saved at epoch 9 with Test Accuracy: 0.8760\n",
      "TP: 1010.0\n",
      "FP: 247.0\n",
      "FN: 0.0\n",
      "TN: 735.0\n",
      "Accuracy: 0.8760\n",
      "Misclassification rate: 0.1240\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.7485\n",
      "Precision: 0.8035\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.8651\n",
      "F-measure: 0.8910\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.8364\n",
      "InvF0.5-measure: 0.9534\n",
      "AGF: 0.8930\n",
      "Balanced Accuracy: 0.8742\n",
      "Matthew's Correlation Coefficient: 0.7755\n",
      "Cohen's Kappa: 0.7511\n",
      "Youden's Index: 0.7485\n",
      "Positive Likelihood Ratio: 3.9757\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 10/50, Train Loss: 0.0033, Train Accuracy: 0.9997, Test Loss: 0.4661, Test Accuracy: 0.9021\n",
      "==> New best model saved at epoch 10 with Test Accuracy: 0.9021\n",
      "TP: 1010.0\n",
      "FP: 195.0\n",
      "FN: 0.0\n",
      "TN: 787.0\n",
      "Accuracy: 0.9021\n",
      "Misclassification rate: 0.0979\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8014\n",
      "Precision: 0.8382\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.8952\n",
      "F-measure: 0.9120\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.8662\n",
      "InvF0.5-measure: 0.9628\n",
      "AGF: 0.9132\n",
      "Balanced Accuracy: 0.9007\n",
      "Matthew's Correlation Coefficient: 0.8196\n",
      "Cohen's Kappa: 0.8036\n",
      "Youden's Index: 0.8014\n",
      "Positive Likelihood Ratio: 5.0359\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 11/50, Train Loss: 0.0032, Train Accuracy: 1.0000, Test Loss: 0.5207, Test Accuracy: 0.8971\n",
      "Epoch: 12/50, Train Loss: 0.0032, Train Accuracy: 0.9998, Test Loss: 0.4822, Test Accuracy: 0.9011\n",
      "Epoch: 13/50, Train Loss: 0.0031, Train Accuracy: 1.0000, Test Loss: 0.4904, Test Accuracy: 0.8996\n",
      "Epoch: 14/50, Train Loss: 0.0030, Train Accuracy: 1.0000, Test Loss: 0.4859, Test Accuracy: 0.9021\n",
      "Epoch: 15/50, Train Loss: 0.0029, Train Accuracy: 1.0000, Test Loss: 0.4866, Test Accuracy: 0.9187\n",
      "==> New best model saved at epoch 15 with Test Accuracy: 0.9187\n",
      "TP: 1010.0\n",
      "FP: 162.0\n",
      "FN: 0.0\n",
      "TN: 820.0\n",
      "Accuracy: 0.9187\n",
      "Misclassification rate: 0.0813\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8350\n",
      "Precision: 0.8618\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9138\n",
      "F-measure: 0.9258\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.8863\n",
      "InvF0.5-measure: 0.9689\n",
      "AGF: 0.9267\n",
      "Balanced Accuracy: 0.9175\n",
      "Matthew's Correlation Coefficient: 0.8483\n",
      "Cohen's Kappa: 0.8369\n",
      "Youden's Index: 0.8350\n",
      "Positive Likelihood Ratio: 6.0617\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 16/50, Train Loss: 0.0028, Train Accuracy: 1.0000, Test Loss: 0.4660, Test Accuracy: 0.9302\n",
      "==> New best model saved at epoch 16 with Test Accuracy: 0.9302\n",
      "TP: 1010.0\n",
      "FP: 139.0\n",
      "FN: 0.0\n",
      "TN: 843.0\n",
      "Accuracy: 0.9302\n",
      "Misclassification rate: 0.0698\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.8585\n",
      "Precision: 0.8790\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9265\n",
      "F-measure: 0.9356\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9008\n",
      "InvF0.5-measure: 0.9732\n",
      "AGF: 0.9363\n",
      "Balanced Accuracy: 0.9292\n",
      "Matthew's Correlation Coefficient: 0.8687\n",
      "Cohen's Kappa: 0.8601\n",
      "Youden's Index: 0.8585\n",
      "Positive Likelihood Ratio: 7.0647\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 17/50, Train Loss: 0.0028, Train Accuracy: 1.0000, Test Loss: 0.5013, Test Accuracy: 0.9066\n",
      "Epoch: 18/50, Train Loss: 0.0027, Train Accuracy: 1.0000, Test Loss: 0.4861, Test Accuracy: 0.9116\n",
      "Epoch: 19/50, Train Loss: 0.0026, Train Accuracy: 1.0000, Test Loss: 0.4522, Test Accuracy: 0.9147\n",
      "Epoch: 20/50, Train Loss: 0.0028, Train Accuracy: 1.0000, Test Loss: 0.4693, Test Accuracy: 0.9091\n",
      "Epoch: 21/50, Train Loss: 0.0025, Train Accuracy: 1.0000, Test Loss: 0.5512, Test Accuracy: 0.8725\n",
      "Epoch: 22/50, Train Loss: 0.0024, Train Accuracy: 1.0000, Test Loss: 0.3419, Test Accuracy: 0.9563\n",
      "==> New best model saved at epoch 22 with Test Accuracy: 0.9563\n",
      "TP: 1010.0\n",
      "FP: 87.0\n",
      "FN: 0.0\n",
      "TN: 895.0\n",
      "Accuracy: 0.9563\n",
      "Misclassification rate: 0.0437\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9114\n",
      "Precision: 0.9207\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9547\n",
      "F-measure: 0.9587\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9355\n",
      "InvF0.5-measure: 0.9831\n",
      "AGF: 0.9590\n",
      "Balanced Accuracy: 0.9557\n",
      "Matthew's Correlation Coefficient: 0.9160\n",
      "Cohen's Kappa: 0.9125\n",
      "Youden's Index: 0.9114\n",
      "Positive Likelihood Ratio: 11.2874\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 23/50, Train Loss: 0.0023, Train Accuracy: 1.0000, Test Loss: 0.4131, Test Accuracy: 0.9388\n",
      "Epoch: 24/50, Train Loss: 0.0022, Train Accuracy: 1.0000, Test Loss: 0.3806, Test Accuracy: 0.9463\n",
      "Epoch: 25/50, Train Loss: 0.0021, Train Accuracy: 1.0000, Test Loss: 0.3609, Test Accuracy: 0.9508\n",
      "Epoch: 26/50, Train Loss: 0.0021, Train Accuracy: 1.0000, Test Loss: 0.4014, Test Accuracy: 0.9342\n",
      "Epoch: 27/50, Train Loss: 0.0020, Train Accuracy: 1.0000, Test Loss: 0.4158, Test Accuracy: 0.9232\n",
      "Epoch: 28/50, Train Loss: 0.0021, Train Accuracy: 1.0000, Test Loss: 0.3110, Test Accuracy: 0.9568\n",
      "==> New best model saved at epoch 28 with Test Accuracy: 0.9568\n",
      "TP: 1010.0\n",
      "FP: 86.0\n",
      "FN: 0.0\n",
      "TN: 896.0\n",
      "Accuracy: 0.9568\n",
      "Misclassification rate: 0.0432\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9124\n",
      "Precision: 0.9215\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9552\n",
      "F-measure: 0.9592\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9362\n",
      "InvF0.5-measure: 0.9833\n",
      "AGF: 0.9595\n",
      "Balanced Accuracy: 0.9562\n",
      "Matthew's Correlation Coefficient: 0.9170\n",
      "Cohen's Kappa: 0.9135\n",
      "Youden's Index: 0.9124\n",
      "Positive Likelihood Ratio: 11.4186\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 29/50, Train Loss: 0.0019, Train Accuracy: 1.0000, Test Loss: 0.3961, Test Accuracy: 0.9332\n",
      "Epoch: 30/50, Train Loss: 0.0018, Train Accuracy: 1.0000, Test Loss: 0.3347, Test Accuracy: 0.9533\n",
      "Epoch: 31/50, Train Loss: 0.0017, Train Accuracy: 1.0000, Test Loss: 0.2870, Test Accuracy: 0.9649\n",
      "==> New best model saved at epoch 31 with Test Accuracy: 0.9649\n",
      "TP: 1010.0\n",
      "FP: 70.0\n",
      "FN: 0.0\n",
      "TN: 912.0\n",
      "Accuracy: 0.9649\n",
      "Misclassification rate: 0.0351\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9287\n",
      "Precision: 0.9352\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9637\n",
      "F-measure: 0.9665\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9475\n",
      "InvF0.5-measure: 0.9863\n",
      "AGF: 0.9667\n",
      "Balanced Accuracy: 0.9644\n",
      "Matthew's Correlation Coefficient: 0.9319\n",
      "Cohen's Kappa: 0.9296\n",
      "Youden's Index: 0.9287\n",
      "Positive Likelihood Ratio: 14.0286\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 32/50, Train Loss: 0.0016, Train Accuracy: 1.0000, Test Loss: 0.3989, Test Accuracy: 0.9252\n",
      "Epoch: 33/50, Train Loss: 0.0016, Train Accuracy: 1.0000, Test Loss: 0.3310, Test Accuracy: 0.9483\n",
      "Epoch: 34/50, Train Loss: 0.0015, Train Accuracy: 1.0000, Test Loss: 0.2670, Test Accuracy: 0.9684\n",
      "==> New best model saved at epoch 34 with Test Accuracy: 0.9684\n",
      "TP: 1010.0\n",
      "FP: 63.0\n",
      "FN: 0.0\n",
      "TN: 919.0\n",
      "Accuracy: 0.9684\n",
      "Misclassification rate: 0.0316\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 0.9358\n",
      "Precision: 0.9413\n",
      "Negative Predictive Value: 1.0000\n",
      "G-mean: 0.9674\n",
      "F-measure: 0.9698\n",
      "Discriminant Power: Infinity\n",
      "F2-measure: 0.9525\n",
      "InvF0.5-measure: 0.9877\n",
      "AGF: 0.9699\n",
      "Balanced Accuracy: 0.9679\n",
      "Matthew's Correlation Coefficient: 0.9386\n",
      "Cohen's Kappa: 0.9367\n",
      "Youden's Index: 0.9358\n",
      "Positive Likelihood Ratio: 15.5873\n",
      "Negative Likelihood Ratio: 0.0000\n",
      "Epoch: 35/50, Train Loss: 0.0014, Train Accuracy: 1.0000, Test Loss: 0.3334, Test Accuracy: 0.9508\n",
      "Epoch: 36/50, Train Loss: 0.0014, Train Accuracy: 1.0000, Test Loss: 0.2894, Test Accuracy: 0.9664\n",
      "Epoch: 37/50, Train Loss: 0.0013, Train Accuracy: 1.0000, Test Loss: 0.3280, Test Accuracy: 0.9558\n",
      "Epoch: 38/50, Train Loss: 0.0013, Train Accuracy: 1.0000, Test Loss: 0.3471, Test Accuracy: 0.9523\n",
      "Epoch: 39/50, Train Loss: 0.0012, Train Accuracy: 1.0000, Test Loss: 0.3112, Test Accuracy: 0.9593\n",
      "Epoch: 40/50, Train Loss: 0.0012, Train Accuracy: 1.0000, Test Loss: 0.2884, Test Accuracy: 0.9644\n",
      "Epoch: 41/50, Train Loss: 0.0011, Train Accuracy: 1.0000, Test Loss: 0.2897, Test Accuracy: 0.9639\n",
      "Epoch: 42/50, Train Loss: 0.0011, Train Accuracy: 1.0000, Test Loss: 0.2821, Test Accuracy: 0.9649\n",
      "Epoch: 43/50, Train Loss: 0.0011, Train Accuracy: 1.0000, Test Loss: 0.2706, Test Accuracy: 0.9654\n",
      "Epoch: 44/50, Train Loss: 0.0010, Train Accuracy: 1.0000, Test Loss: 0.2917, Test Accuracy: 0.9613\n",
      "Epoch: 45/50, Train Loss: 0.0009, Train Accuracy: 1.0000, Test Loss: 0.2971, Test Accuracy: 0.9613\n",
      "Epoch: 46/50, Train Loss: 0.0009, Train Accuracy: 1.0000, Test Loss: 0.3207, Test Accuracy: 0.9578\n",
      "Epoch: 47/50, Train Loss: 0.0009, Train Accuracy: 1.0000, Test Loss: 0.2644, Test Accuracy: 0.9634\n",
      "Epoch: 48/50, Train Loss: 0.0008, Train Accuracy: 1.0000, Test Loss: 0.3025, Test Accuracy: 0.9593\n",
      "Epoch: 49/50, Train Loss: 0.0008, Train Accuracy: 1.0000, Test Loss: 0.3012, Test Accuracy: 0.9588\n",
      "Epoch: 50/50, Train Loss: 0.0008, Train Accuracy: 1.0000, Test Loss: 0.3191, Test Accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and loss function\n",
    "import torch.optim as optimizer\n",
    "from self_metrics import Binary_got_metrics\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizer.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# model training\n",
    "def train(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Compute prediction error\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= size\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "def test(dataloader, model, loss_function):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    # 1(1) is positive, 0(7) is negative\n",
    "    # TP: 1 classified as 1\n",
    "    # TN: 0 classified as 0\n",
    "    # FP: 0 classified as 1\n",
    "    # FN: 1 classified as 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            prediction = model(images)\n",
    "            test_loss += loss_function(prediction, labels).item()\n",
    "            test_accuracy += (prediction.argmax(1) == labels).type(torch.float).sum().item()\n",
    "            TP += ((prediction.argmax(1) == 1) & (labels == 1)).type(torch.float).sum().item()\n",
    "            TN += ((prediction.argmax(1) == 0) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FP += ((prediction.argmax(1) == 1) & (labels == 0)).type(torch.float).sum().item()\n",
    "            FN += ((prediction.argmax(1) == 0) & (labels == 1)).type(torch.float).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= size\n",
    "    return test_loss, test_accuracy, TP, TN, FP, FN\n",
    "\n",
    "# training the model\n",
    "epochs = 50\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_loss_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "best_model_TP = 0\n",
    "best_model_TN = 0\n",
    "best_model_FP = 0\n",
    "best_model_FN = 0\n",
    "best_test_accuracy = 0.0 # for saving the best model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = train(train_loader, model, loss_function, optimizer)\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy,TP, TN, FP, FN  = test(test_loader, model, loss_function)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\") \n",
    "\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model_TP = TP\n",
    "        best_model_TN = TN\n",
    "        best_model_FP = FP\n",
    "        best_model_FN = FN\n",
    "        save_path = f\"BinaryMNIST34_{fraction}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"==> New best model saved at epoch {epoch+1} with Test Accuracy: {test_accuracy:.4f}\")\n",
    "        #print(f\"==> TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "        Accuracy, misclassification_rate, Sensitivity, Specificity, Precision, Negative_Predictive_Value, Gmean, Fmean, DPower, F2measure, InvF_05, AGFmeasure, Balanced_Accuracy, MCCmeasure, Kappa, Youden_Index, LR_pos, LR_neg = Binary_got_metrics(best_model_TP, best_model_FP, best_model_FN, best_model_TN)\n",
    "        # metrics_results_path = f\"BinaryMNIST17_{fraction}_metrics_results.txt\"\n",
    "        # with open(metrics_results_path, \"w\") as f:\n",
    "        #     print(\"Number of label 1 in the final training set: \", len(mnist1_train_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final training set (after downsampling): \", len(fraction_mnist7_train_data), file=f)\n",
    "        #     print(\"Number of label 1 in the final test set: \", len(mnist1_test_data), file=f)\n",
    "        #     print(\"Number of label 7 in the final test set: \", len(mnist7_test_data), file=f)\n",
    "\n",
    "        #     print(\"Total samples in final training set: \", len(Final_train_datasets), file=f)\n",
    "        #     print(\"Total samples in final test set: \", len(Final_test_datasets), file=f)\n",
    "\n",
    "        #     print(\"Number of batches in training set: \", len(train_loader), file=f)\n",
    "        #     print(\"Number of batches in test set: \", len(test_loader), file=f)\n",
    "        #     print(f\"TP: {TP}\", file=f)\n",
    "        #     print(f\"FP: {FP}\", file=f)\n",
    "        #     print(f\"FN: {FN}\", file=f)\n",
    "        #     print(f\"TN: {TN}\", file=f)\n",
    "        #     print(f\"Accuracy: {Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Misclassification rate: {misclassification_rate:.4f}\", file=f)\n",
    "        #     print(f\"Sensitivity (Recall): {Sensitivity:.4f}\", file=f)\n",
    "        #     print(f\"Specificity: {Specificity:.4f}\", file=f)\n",
    "        #     print(f\"Precision: {Precision:.4f}\", file=f)\n",
    "        #     print(f\"Negative Predictive Value: {Negative_Predictive_Value:.4f}\", file=f)\n",
    "        #     print(f\"G-mean: {Gmean:.4f}\", file=f)\n",
    "        #     print(f\"F-measure: {Fmean:.4f}\", file=f)\n",
    "        #     print(f\"Discriminant Power (DP): {DPower:.4f}\", file=f)\n",
    "        #     print(f\"F2-measure: {F2measure:.4f}\", file=f)\n",
    "        #     print(f\"InvF0.5-measure: {InvF_05:.4f}\", file=f)\n",
    "        #     print(f\"AGF: {AGFmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Balanced Accuracy: {Balanced_Accuracy:.4f}\", file=f)\n",
    "        #     print(f\"Matthew's Correlation Coefficient (MCC): {MCCmeasure:.4f}\", file=f)\n",
    "        #     print(f\"Cohen's Kappa: {Kappa:.4f}\", file=f)\n",
    "        #     print(f\"Youden's Index: {Youden_Index:.4f}\", file=f)\n",
    "        #     print(f\"Positive Likelihood Ratio (LR+): {LR_pos:.4f}\", file=f)\n",
    "        #     print(f\"Negative Likelihood Ratio (LR-): {LR_neg:.4f}\", file=f)\n",
    "        import json\n",
    "\n",
    "        # 构造一个包含所有指标数据的字典\n",
    "        metrics_dict = {\n",
    "            \"Number of label 3 in the final training set\": len(mnist3_train_data),\n",
    "            \"Number of label 4 in the final training set (after downsampling)\": len(fraction_mnist4_train_data),\n",
    "            \"Number of label 3 in the final test set\": len(mnist3_test_data),\n",
    "            \"Number of label 4 in the final test set\": len(mnist4_test_data),\n",
    "            \"Total samples in final training set\": len(Final_train_datasets),\n",
    "            \"Total samples in final test set\": len(Final_test_datasets),\n",
    "            \"Number of batches in training set\": len(train_loader),\n",
    "            \"Number of batches in test set\": len(test_loader),\n",
    "            \"TP\": TP,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"TN\": TN,\n",
    "            \"Accuracy\": round(Accuracy, 4),\n",
    "            \"Misclassification rate\": round(misclassification_rate, 4),\n",
    "            \"Sensitivity (Recall)\": round(Sensitivity, 4),\n",
    "            \"Specificity\": round(Specificity, 4),\n",
    "            \"Precision\": round(Precision, 4),\n",
    "            \"Negative Predictive Value\": round(Negative_Predictive_Value, 4),\n",
    "            \"G-mean\": round(Gmean, 4),\n",
    "            \"F-measure\": round(Fmean, 4),\n",
    "            \"Discriminant Power (DP)\": round(DPower, 4),\n",
    "            \"F2-measure\": round(F2measure, 4),\n",
    "            \"InvF0.5-measure\": round(InvF_05, 4),\n",
    "            \"AGF\": round(AGFmeasure, 4),\n",
    "            \"Balanced Accuracy\": round(Balanced_Accuracy, 4),\n",
    "            \"Matthew's Correlation Coefficient (MCC)\": round(MCCmeasure, 4),\n",
    "            \"Cohen's Kappa\": round(Kappa, 4),\n",
    "            \"Youden's Index\": round(Youden_Index, 4),\n",
    "            \"Positive Likelihood Ratio (LR+)\": round(LR_pos, 4),\n",
    "            \"Negative Likelihood Ratio (LR-)\": round(LR_neg, 4)\n",
    "        }\n",
    "\n",
    "        # 指定 JSON 文件保存路径\n",
    "        metrics_results_path = f\"BinaryMNIST34_{fraction}_metrics_results.json\"\n",
    "\n",
    "        # 将字典保存为 JSON 文件\n",
    "        with open(metrics_results_path, \"w\") as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
