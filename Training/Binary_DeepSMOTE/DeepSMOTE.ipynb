{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections  # 导入collections模块，用于统计和操作容器数据，如Counter\n",
    "import torch  # 导入PyTorch库，用于深度学习任务\n",
    "import torch.nn as nn  # 从torch中导入神经网络模块，简化模型构建\n",
    "from torch.utils.data import TensorDataset  # 导入TensorDataset，用于将Tensor数据打包成数据集\n",
    "import numpy as np  # 导入NumPy库，用于高效的数值计算和数组操作\n",
    "from sklearn.neighbors import NearestNeighbors  # 导入最近邻算法，用于在SMOTE中寻找相邻样本\n",
    "import time  # 导入time模块，用于计时\n",
    "import os  # 导入os模块，用于文件和目录操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'dim_h': 64, 'n_channel': 1, 'n_z': 300, 'sigma': 1.0, 'lambda': 0.01, 'lr': 0.0002, 'epochs': 50, 'batch_size': 64, 'save': True, 'train': True, 'dataset': 'mnist34', 'fraction': 0.005}\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # 打印当前PyTorch使用的CUDA版本，例如显示\"10.1\"\n",
    "\n",
    "t3 = time.time()  # 记录程序开始时的时间，用于后续计算总运行时间\n",
    "##############################################################################\n",
    "\"\"\"args for AE\"\"\"\n",
    "# 以下部分设置自动编码器（AE）的相关参数\n",
    "args = {}  # 创建一个空字典，用于存放模型和训练的参数\n",
    "args['dim_h'] = 64         # 设置隐藏层通道数的基础因子，后续卷积层的通道数会成倍增加\n",
    "args['n_channel'] = 1  #3    # 输入数据的通道数，1表示灰度图（3则为彩色图）；这里选用灰度图\n",
    "args['n_z'] = 300 #600     # 潜在空间（编码空间）的维度数，决定编码器输出特征向量的大小\n",
    "args['sigma'] = 1.0        # 潜在空间中使用的方差参数，可用于正则化\n",
    "args['lambda'] = 0.01      # 判别器损失的权重超参数（如在对抗训练中使用）\n",
    "args['lr'] = 0.0002        # Adam优化器的学习率，决定参数更新的步长\n",
    "args['epochs'] = 50       # 训练过程中遍历数据集的轮数\n",
    "args['batch_size'] = 64   # 每个训练批次的样本数量\n",
    "args['save'] = True        # 如果为True，则在每个训练轮结束时保存模型权重\n",
    "args['train'] = True       # 若为True则进行训练，否则加载已保存的模型进行测试\n",
    "args['dataset'] = 'mnist34'  #'fmnist' # 指定使用的数据集，这里选择MNIST数据集 mnist34 mnist17 fashionmnist34 cifar10\n",
    "args['fraction'] = 0.005   # 用于训练的数据集的子集比例，可用于快速测试\n",
    "\n",
    "##############################################################################\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the MNIST dataset with labels 3 and 4.\n",
      "Imbalanced Ratio:  0.005\n",
      "Number of label 3 in the final training set:  6131\n",
      "Number of label 4 in the final training set (after downsampling):  30\n",
      "Number of label 3 in the final test set:  1010\n",
      "Number of label 4 in the final test set:  982\n",
      "Total samples in final training set:  6161\n",
      "Total samples in final test set:  1992\n",
      "Number of batches in training set:  97\n",
      "Number of batches in test set:  32\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9255,\n",
      "          0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.9059, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 0.6980, 0.9725, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9098, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.9725, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.6235, 0.5569, 0.5569, 0.5569, 0.5569, 0.6471,\n",
      "          0.9922, 0.9922, 0.9882, 0.3647, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7882, 0.9922, 0.9922, 0.6118,\n",
      "          0.3882, 0.0745, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
      "          0.7137, 0.9922, 0.9922, 0.3804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.0980, 0.0980, 0.0078,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6902, 0.9922, 0.9451, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.4667,\n",
      "          0.9569, 0.9922, 0.6784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.7490, 0.9922,\n",
      "          0.9922, 0.8627, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1059, 0.3098, 0.3098, 0.7490, 0.9922, 0.9922,\n",
      "          0.9922, 0.8863, 0.3098, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.7412, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.8706, 0.7529, 0.2706, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2784, 0.9608, 0.9922, 0.9922, 0.9255, 0.7373, 0.7373,\n",
      "          0.3843, 0.5686, 0.7686, 0.9922, 0.9922, 0.9804, 0.4863, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0941, 0.6863, 0.7608, 0.3569, 0.1882, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0353, 0.2549, 0.5725, 0.9922, 0.9882, 0.3608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.6824, 0.9922, 0.8510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.3804, 0.9922, 0.9922,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6000, 0.4275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.9922, 0.9922, 0.9137,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549,\n",
      "          0.9098, 0.6784, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0824, 0.1961, 0.9922, 0.9098, 0.1725,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3686,\n",
      "          0.9843, 0.9922, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1490, 0.6118, 0.8471, 0.9843, 0.8627, 0.1765, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.8941, 0.9922, 0.8588, 0.5882, 0.1804, 0.0784, 0.0392, 0.1843,\n",
      "          0.5882, 0.8588, 0.9922, 0.9922, 0.8745, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6039, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7725, 0.9922,\n",
      "          0.9922, 0.9922, 0.9882, 0.6235, 0.1765, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1765, 0.9137, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9882, 0.8863, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1765, 0.6510, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAd1UlEQVR4nO3dC1BU5/nH8QcvIFEBERFQvOAlpvFS65V4iUYL2tR661RbZ6oZR0eDmajxUtp6+yczNDbVjNaqaa3EmBhjJ2hiO3S84iRRU02MMU2sWBI03q2AaEUD5z/v60BZBc1B2GfZ/X5m3sHdPc/u4XjY377nvPueIMdxHAEAwMvqePsFAQAwCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIOABffnllxIUFCQvvfRStT3n3r177XOan4C/IoAQkNLT0+0b/KFDh8QfHT9+XGbNmiWPPfaYNGjQwP6uJigBX0IAAX5o//79smLFCrl69ao88sgj2qsDVIgAAvzQj370I8nLy5NPP/1UJkyYoL06QIUIIKASN2/elIULF0qPHj0kPDxcGjZsKAMGDJA9e/ZUWrN8+XJp3bq1hIaGyuOPPy7Hjh27a5kvvvhCfvzjH0tkZKQ9PNazZ09555137rs+169ft7WXLl2677LmuRs3bvwtfktADwEEVKKgoED+9Kc/yaBBg+TFF1+UxYsXy8WLFyU5OVmOHDly1/IbNmywh71SUlIkNTXVhs8TTzwh58+fL1vms88+k759+8rnn38uv/jFL+R3v/udDbZRo0ZJRkbGPdfnww8/tIfTfv/739fI7wt4Wz2vvyJQSzRp0sSeuA8ODi67b8qUKdKpUydZuXKlrFu3zmP57OxsOXHihLRo0cLeHjZsmPTp08eG17Jly+x9zz77rLRq1Ur+8Y9/SEhIiL3v6aeflv79+8v8+fNl9OjRXv0dAU30gIBK1K1btyx8SkpK5D//+Y9888039pDZRx99dNfyphdTGj5G7969bQD97W9/s7dN/e7du+UnP/mJHRxgDqWZdvnyZdurMuH19ddfV7o+pidmrh9pemKAPyCAgHt49dVXpWvXrvZcTdOmTaVZs2by17/+VfLz8+9atkOHDnfd17Fjx7Lhz6aHZAJkwYIF9nnKt0WLFtllLly44IXfCvANHIIDKrFx40aZNGmS7dnMnTtXoqOjba8oLS1NTp486fr5TC/KmDNnju3xVKR9+/YPvN5AbUEAAZX4y1/+IgkJCfL222/bL3KWKu2t3MkcQrvTv/71L2nTpo39t3kuo379+jJ06NAaW2+gtuAQHFAJ09sxzGGzUgcPHrRf8qzI1q1bPc7hmFFrZvnhw4fb26YHZc7jrF27Vs6ePXtXvRlhV13DsIHagB4QAtqf//xnyczMvOt+M1rthz/8oe39mJFpTz75pOTk5MiaNWvkO9/5jhQWFlZ4+MyMZps+fboUFRXJyy+/bM8bzZs3r2yZVatW2WW6dOliR9SZXpEZpm1C7fTp0/LJJ59Uuq4m0AYPHmx7YPcbiGDOUZmResb7779vf5rh2xEREbbNmDHD1XYCagIBhIC2evXqCu83535MO3funO2x/P3vf7fBY84LbdmypcJJQn/+859LnTp1bPCYwQRmFJx504+NjS1bxjyHmX9uyZIldj46MwLO9Iy6d+9uv/RaXa5cuWIHO5RnvnNkmC/KEkDwBUFO+eMLAAB4CeeAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKn/sekJkv68yZM/ZiWuWnPwEA1A7m2z1mxve4uDj73bhaE0AmfOLj47VXAwDwgE6dOiUtW7asPYfguIwwAPiH+72f11gAmTmvzCzA5joq5qJcZh6rb4PDbgDgH+73fl4jAbR582aZPXu2nTTRXDmyW7du9vonXGwLAFDGqQG9e/d2UlJSym4XFxc7cXFxTlpa2n1r8/Pzzdx0NBqNRpPa3cz7+b1Uew/o5s2bcvjwYY8LbplREOZ2RddRMdPWFxQUeDQAgP+r9gAyF8sqLi6W5s2be9xvbpup7e9kLm8cHh5e1hgBBwCBQX0UXGpqqr14Vmkzw/YAAP6v2r8HFBUVZS9lbK7yWJ65HRMTc9fyISEhtgEAAku194CCg4OlR48esmvXLo/ZDcztxMTE6n45AEAtVSMzIZgh2BMnTpSePXvayxKbSxRfu3ZNnnrqqZp4OQBALVQjATRu3Di5ePGivca9GXjw3e9+VzIzM+8amAAACFxBZiy2+BAzDNuMhgMA1G5mYFlYWJjvjoIDAAQmAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACrq6bwsfMnly5erVBcZGVnt64Lqdf78+SrVLVmyxHXN6tWrq/RaCFz0gAAAKgggAIB/BNDixYslKCjIo3Xq1Km6XwYAUMvVyDmgRx99VHbu3Pm/F6nHqSYAgKcaSQYTODExMTXx1AAAP1Ej54BOnDghcXFxkpCQIBMmTJDc3NxKly0qKpKCggKPBgDwf9UeQH369JH09HTJzMy0wzJzcnJkwIABcvXq1QqXT0tLk/Dw8LIWHx9f3asEAPBBQY7jODX5Anl5edK6dWtZtmyZTJ48ucIekGmlTA+IEPIuvgfkv/geEDTl5+dLWFhYpY/X+OiAiIgI6dixo2RnZ1f4eEhIiG0AgMBS498DKiwslJMnT0psbGxNvxQAIJADaM6cOZKVlSVffvmlfPDBBzJ69GipW7eu/PSnP63ulwIA1GLVfgju9OnTNmzMeYVmzZpJ//795cCBA/bfAAB4bRCCW2YQghkN528ee+wx1zWpqamua5KSklzX1K9f33UN/NvFixdd1yxcuNB1zdq1a13XwH8GITAXHABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABVMRuol5a/6+m0xSehtGzZscF1z5coV8TfNmzd3XTN+/Hjxlqq8lUyaNMl1zWuvvea6BjqYjBQA4JMIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACrq6bxs4Pnkk09c1/Ts2VO8Yf369VWq++CDD1zXbN261XVNXl6e65ri4mLxN/Xquf9zbdKkSZVeKzk52XVNUFCQV34n+A96QAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQwE6CXDBkyxHVNo0aNxBvOnz9fpbqSkpJqXxdU7ptvvnFdc/PmTfGWwsJC1zUnTpyokXVB7UAPCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAomI/WSq1eveqUGtUN0dLTrmqeeesp1zdChQ8Vbdu7c6brmvffeq5F1Qe1ADwgAoIIAAgDUjgDat2+fjBgxQuLi4iQoKEi2bt3q8bjjOLJw4UKJjY2V0NBQewiAa34AAB44gK5duybdunWTVatWVfj40qVLZcWKFbJmzRo5ePCgNGzYUJKTk+XGjRtuXwoA4MdcD0IYPny4bRUxvZ+XX35Zfv3rX8vIkSPtfRs2bJDmzZvbntL48eMffI0BAH6hWs8B5eTkyLlz5zxG3oSHh0ufPn1k//79FdYUFRVJQUGBRwMA+L9qDSATPobp8ZRnbpc+dqe0tDQbUqUtPj6+OlcJAOCj1EfBpaamSn5+flk7deqU9ioBAGpbAMXExNif58+f97jf3C597E4hISESFhbm0QAA/q9aA6ht27Y2aHbt2lV2nzmnY0bDJSYmVudLAQACbRRcYWGhZGdneww8OHLkiERGRkqrVq1k5syZ8sILL0iHDh1sIC1YsMB+Z2jUqFHVve4AgEAKoEOHDsngwYPLbs+ePdv+nDhxoqSnp8u8efPsd4WmTp0qeXl50r9/f8nMzJQGDRpU75oDAGq1IMd8eceHmEN2ZjQc4M8Ti7711luuawYOHCjeYo5suNW9e3fXNXztwr+ZgWX3Oq+vPgoOABCYCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAC143IMgLe1aNHCdU3Pnj3FW2bNmuXTM1tXRXBwsOua8pdp+bY+/vhj1zW5ubmua+Cb6AEBAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQEeQ4jiM+pKCgQMLDw7VXAz5k9+7drmsGDRpUI+uC6vXVV195ZTLSF154Qapix44dVarDbfn5+RIWFiaVoQcEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABZORwquSk5Nd12RkZLiuadCggXjLlStXXNccOXJEvGHjxo1Vquvevbvrmh49eriuSUxMFG8oLi6uUt2SJUu8NvGpP2IyUgCATyKAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCyUjhVTExMa5r1qxZ47qmadOmrmuq+lqfffaZz05G6k2hoaGua/r27eu6ZsyYMa5rUlJSpCqq8vY4ceJEr00a6+uYjBQA4JMIIABA7Qigffv2yYgRIyQuLk6CgoJk69atHo9PmjTJ3l++DRs2rDrXGQAQiAF07do16datm6xatarSZUzgnD17tqxt2rTpQdcTAOBn6rktGD58uG33EhISUqWTzQCAwFEj54D27t0r0dHR8vDDD8v06dPl8uXLlS5bVFRkR76VbwAA/1ftAWQOv23YsEF27dolL774omRlZdkeU2XXZE9LS7PDrktbfHx8da8SAMAfDsHdz/jx48v+3aVLF+natau0a9fO9oqGDBly1/Kpqakye/bsstumB0QIAYD/q/Fh2AkJCRIVFSXZ2dmVni8yX1Qq3wAA/q/GA+j06dP2HFBsbGxNvxQAwJ8PwRUWFnr0ZnJycuy0IpGRkbYtWbJExo4da0fBnTx5UubNmyft27eX5OTk6l53AEAgBdChQ4dk8ODBZbdLz9+Y+Y9Wr14tR48elVdffVXy8vLsl1WTkpLk+eeft4faAAAoxWSkAGqV4OBg1zWbN2+u0muNHDnSdU1l57vvpWPHjuKPmIwUAOCTCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAD+cUluAKhJJSUlrmveeecdr82Gba5/hm+HHhAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVTEaKKnvllVdc13z66aeua1auXOm6Bv4rIiLCdc26devEWy5duuS116rt6AEBAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQwWSkkLCwsCrVjRw50nVNVFSU65o1a9a4rrl165brGnhfs2bNXNfEx8eLt1y8eNF1zZAhQ2pkXfwRPSAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqmIwUMmrUqCrVNW3a1Cuv1a1bN9c1hw4dcl2D/+nYsaPrmvnz57uu6d+/v+uadu3aua7JyckRb024e+zYsSq9ViCiBwQAUEEAAQB8P4DS0tKkV69e0rhxY4mOjraHU44fP+6xzI0bNyQlJcUenmnUqJGMHTtWzp8/X93rDQAIpADKysqy4XLgwAHZsWOHvehXUlKSXLt2rWyZWbNmybvvvitbtmyxy585c0bGjBlTE+sOAAiUQQiZmZket9PT021P6PDhwzJw4EDJz8+XdevWyRtvvCFPPPGEXWb9+vXyyCOP2NDq27dv9a49ACAwzwGZwDEiIyPtTxNEplc0dOjQsmU6deokrVq1kv3791f4HEVFRVJQUODRAAD+r8oBVFJSIjNnzpR+/fpJ586d7X3nzp2T4OBgiYiI8Fi2efPm9rHKziuFh4eXNW9e7x0AUAsDyJwLMuPd33zzzQdagdTUVNuTKm2nTp16oOcDAPjxF1FnzJgh27dvl3379knLli3L7o+JiZGbN29KXl6eRy/IjIIzj1UkJCTENgBAYHHVA3Icx4ZPRkaG7N69W9q2bevxeI8ePaR+/fqya9eusvvMMO3c3FxJTEysvrUGAARWD8gcdjMj3LZt22a/C1R6XsecuwkNDbU/J0+eLLNnz7YDE8LCwuSZZ56x4cMIOABAlQNo9erV9uegQYM87jdDrSdNmmT/vXz5cqlTp479AqoZ4ZacnCx/+MMf3LwMACAABDnmuJoPMcOwTU8Kvu/rr792XRMbG+u65t///rfrGvNF6aoo/ZDlhvmytVvXr193XdOhQwfXNdOmTZOq+P73v++6JiEhQbzBHNJ3q02bNjWyLrg3M7DMHAmrDHPBAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUMBs2quyPf/yj6xpzvSiIHDhwwHWNr19TqypvJa+99prrmpdeesl1zbFjx1zX4MExGzYAwCcRQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQwWSkqLLOnTu7rtm9e7frmqioKNc1uK2qf95nzpxxXfP888+7rnnllVdc16D2YDJSAIBPIoAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoILJSOHzE5j+6le/cl0zbtw41zX+aPny5VWqe+6556p9XRB48pmMFADgiwggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKhgMlIAQI1gMlIAgE8igAAAvh9AaWlp0qtXL2ncuLFER0fLqFGj5Pjx4x7LDBo0SIKCgjzatGnTqnu9AQCBFEBZWVmSkpIiBw4ckB07dsitW7ckKSlJrl275rHclClT5OzZs2Vt6dKl1b3eAIBarp6bhTMzMz1up6en257Q4cOHZeDAgWX3P/TQQxITE1N9awkA8Dt1HnSEgxEZGelx/+uvvy5RUVH28supqaly/fr1Sp+jqKjIjnwr3wAAAcCpouLiYufJJ590+vXr53H/2rVrnczMTOfo0aPOxo0bnRYtWjijR4+u9HkWLVpkhoHTaDQaTfyr5efn3zNHqhxA06ZNc1q3bu2cOnXqnsvt2rXLrkh2dnaFj9+4ccOuZGkzz6e90Wg0Go0mNR5Ars4BlZoxY4Zs375d9u3bJy1btrznsn369LE/s7OzpV27dnc9HhISYhsAILC4CiDTY3rmmWckIyND9u7dK23btr1vzZEjR+zP2NjYqq8lACCwA8gMwX7jjTdk27Zt9rtA586ds/ebqXNCQ0Pl5MmT9vEf/OAH0rRpUzl69KjMmjXLjpDr2rVrTf0OAIDayM15n8qO861fv94+npub6wwcONCJjIx0QkJCnPbt2ztz586973HA8syy2sctaTQajSYP3O733s9kpACAGsFkpAAAn0QAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUOFzAeQ4jvYqAAC88H7ucwF09epV7VUAAHjh/TzI8bEuR0lJiZw5c0YaN24sQUFBHo8VFBRIfHy8nDp1SsLCwiRQsR1uYzvcxna4je3gO9vBxIoJn7i4OKlTp/J+Tj3xMWZlW7Zsec9lzEYN5B2sFNvhNrbDbWyH29gOvrEdwsPD77uMzx2CAwAEBgIIAKCiVgVQSEiILFq0yP4MZGyH29gOt7EdbmM71L7t4HODEAAAgaFW9YAAAP6DAAIAqCCAAAAqCCAAgAoCCACgotYE0KpVq6RNmzbSoEED6dOnj3z44Yfaq+R1ixcvttMTlW+dOnUSf7dv3z4ZMWKEndbD/M5bt271eNwM5Fy4cKHExsZKaGioDB06VE6cOCGBth0mTZp01/4xbNgw8SdpaWnSq1cvO1VXdHS0jBo1So4fP+6xzI0bNyQlJUWaNm0qjRo1krFjx8r58+cl0LbDoEGD7tofpk2bJr6kVgTQ5s2bZfbs2XZs+0cffSTdunWT5ORkuXDhggSaRx99VM6ePVvW3nvvPfF3165ds//n5kNIRZYuXSorVqyQNWvWyMGDB6Vhw4Z2/zBvRIG0HQwTOOX3j02bNok/ycrKsuFy4MAB2bFjh9y6dUuSkpLstik1a9Yseffdd2XLli12eTO35JgxYyTQtoMxZcoUj/3B/K34FKcW6N27t5OSklJ2u7i42ImLi3PS0tKcQLJo0SKnW7duTiAzu2xGRkbZ7ZKSEicmJsb57W9/W3ZfXl6eExIS4mzatMkJlO1gTJw40Rk5cqQTSC5cuGC3RVZWVtn/ff369Z0tW7aULfP555/bZfbv3+8EynYwHn/8cefZZ591fJnP94Bu3rwphw8ftodVyk9Yam7v379fAo05tGQOwSQkJMiECRMkNzdXAllOTo6cO3fOY/8wkyCaw7SBuH/s3bvXHpJ5+OGHZfr06XL58mXxZ/n5+fZnZGSk/WneK0xvoPz+YA5Tt2rVyq/3h/w7tkOp119/XaKioqRz586Smpoq169fF1/ic7Nh3+nSpUtSXFwszZs397jf3P7iiy8kkJg31fT0dPvmYrrTS5YskQEDBsixY8fsseBAZMLHqGj/KH0sUJjDb+ZQU9u2beXkyZPyy1/+UoYPH27feOvWrSv+xly6ZebMmdKvXz/7BmuY//Pg4GCJiIgImP2hpILtYPzsZz+T1q1b2w+sR48elfnz59vzRG+//bb4Cp8PIPyPeTMp1bVrVxtIZgd76623ZPLkyarrBn3jx48v+3eXLl3sPtKuXTvbKxoyZIj4G3MOxHz4CoTzoFXZDlOnTvXYH8wgHbMfmA8nZr/wBT5/CM50H82ntztHsZjbMTExEsjMp7yOHTtKdna2BKrSfYD9427mMK35+/HH/WPGjBmyfft22bNnj8f1w8z/uTlsn5eXFxD7w4xKtkNFzAdWw5f2B58PINOd7tGjh+zatcujy2luJyYmSiArLCy0n2bMJ5tAZQ43mTeW8vuHuSKkGQ0X6PvH6dOn7Tkgf9o/zPgL86abkZEhu3fvtv//5Zn3ivr163vsD+awkzlX6k/7g3Of7VCRI0eO2J8+tT84tcCbb75pRzWlp6c7//znP52pU6c6ERERzrlz55xA8txzzzl79+51cnJynPfff98ZOnSoExUVZUfA+LOrV686H3/8sW1ml122bJn991dffWUf/81vfmP3h23btjlHjx61I8Hatm3r/Pe//3UCZTuYx+bMmWNHepn9Y+fOnc73vvc9p0OHDs6NGzccfzF9+nQnPDzc/h2cPXu2rF2/fr1smWnTpjmtWrVydu/e7Rw6dMhJTEy0zZ9Mv892yM7Odv7v//7P/v5mfzB/GwkJCc7AgQMdX1IrAshYuXKl3amCg4PtsOwDBw44gWbcuHFObGys3QYtWrSwt82O5u/27Nlj33DvbGbYcelQ7AULFjjNmze3H1SGDBniHD9+3Amk7WDeeJKSkpxmzZrZYcitW7d2pkyZ4ncf0ir6/U1bv3592TLmg8fTTz/tNGnSxHnooYec0aNH2zfnQNoOubm5NmwiIyPt30T79u2duXPnOvn5+Y4v4XpAAAAVPn8OCADgnwggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCAAgGv4fKhKE8NCltLwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6161, 784)\n",
      "y_train.shape: (6161,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Get_datasets import get_datasets\n",
    "X_train,y_train ,X_test,y_test = get_datasets(dataname='mnist34',fraction=args['fraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Attention Block\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        \"\"\"\n",
    "        :param filters: 输入特征图的通道数(同时也是卷积输出的通道数)\n",
    "        \"\"\"\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        # 与 Keras 中的 Conv2D(filters, kernel_size=1, padding='same') 对应\n",
    "        # PyTorch 中 padding=0 就相当于 'same'（仅当 kernel_size=1 时）\n",
    "        self.query_conv = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "        self.key_conv   = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "        self.value_conv = nn.Conv2d(filters, filters, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 的形状一般是 (batch_size, filters, H, W)\n",
    "        \"\"\"\n",
    "        # 1. 分别得到 query, key, value\n",
    "        query = F.relu(self.query_conv(x))\n",
    "        key   = F.relu(self.key_conv(x))\n",
    "        value = F.relu(self.value_conv(x))\n",
    "\n",
    "        # 2. 计算注意力图: 先元素乘，再对通道维度 (dim=1) 求和\n",
    "        attention_map = query * key                  # 形状 (N, filters, H, W)\n",
    "        attention_map = torch.sum(attention_map, dim=1, keepdim=True)  \n",
    "        # 现在 attention_map 的形状是 (N, 1, H, W)\n",
    "\n",
    "        # 3. 对空间维度 (H, W) 做 softmax\n",
    "        # 先展平再 softmax，再 reshape 回去\n",
    "        N, _, H, W = attention_map.shape\n",
    "        attention_map = attention_map.view(N, 1, -1)         # (N, 1, H*W)\n",
    "        attention_map = F.softmax(attention_map, dim=-1)     # 在 H*W 上做 softmax\n",
    "        attention_map = attention_map.view(N, 1, H, W)       # (N, 1, H, W)\n",
    "\n",
    "        # 4. 注意力加权 value，并与原输入相加\n",
    "        attended_value = attention_map * value\n",
    "        output = x + attended_value\n",
    "\n",
    "        return output\n",
    "# 定义编码器模型\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入数据的通道数\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "        \n",
    "        # 使用卷积层提取图像特征\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),  \n",
    "            # 第一层卷积：输入通道数为n_channel，输出为dim_h，卷积核大小4，步幅2，填充1，无偏置\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 使用LeakyReLU激活函数，负半部斜率设为0.2\n",
    "            AttentionBlock(filters=self.dim_h),\n",
    "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),  \n",
    "            # 第二层卷积：通道数翻倍到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 对第二层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),  \n",
    "            # 第三层卷积：通道数增加到dim_h*4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            \n",
    "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),  \n",
    "            # 第四层卷积：通道数增加到dim_h*8\n",
    "            \n",
    "            #3d and 32 by 32\n",
    "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),  # 备用卷积层配置\n",
    "            nn.BatchNorm2d(self.dim_h * 8),  # 对第四层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True)  # 激活函数\n",
    "            # 注释中还有其他可能的卷积配置，这里使用的是标准配置\n",
    "        )\n",
    "        # 全连接层：将卷积层输出映射到潜在空间\n",
    "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)  \n",
    "        # 这里计算dim_h * (2**3)相当于dim_h*8，假设卷积层最后输出特征数为dim_h*8\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('enc')  # 调试打印，可查看编码器被调用\n",
    "        # print('input ', x.size())  # 打印输入尺寸，例如torch.Size([batch_size, channel, H, W])\n",
    "        x = self.conv(x)  # 将输入图像通过卷积层提取特征\n",
    "        x = x.squeeze()   # 去除多余的尺寸（例如将[batch_size, 1, N]变为[batch_size, N]）\n",
    "        # print('aft squeeze ', x.size())  # 调试打印压缩后的尺寸\n",
    "        x = self.fc(x)    # 通过全连接层映射到潜在空间维度\n",
    "        # print('out ', x.size())  # 打印最终输出尺寸，应为[batch_size, n_z]\n",
    "        return x  # 返回编码后的潜在表示\n",
    "\n",
    "# 定义解码器模型\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入通道数（用于输出重构图像）\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "\n",
    "        # 全连接层：将潜在向量映射到足够重构卷积特征图的尺寸\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),  # 将潜在向量转换为高维特征，尺寸为[batch_size, dim_h*8*7*7]\n",
    "            nn.ReLU()  # 使用ReLU激活函数\n",
    "        )\n",
    "\n",
    "        # 反卷积层（转置卷积）：将全连接层的输出转换为图像\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),  \n",
    "            # 第一层反卷积：将通道数从dim_h*8降到dim_h*4，卷积核大小4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),  \n",
    "            # 第二层反卷积：将通道数从dim_h*4降到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),  \n",
    "            # 第三层反卷积：将通道数降为1，同时上采样（步幅为2），恢复到原图大小\n",
    "            # nn.Sigmoid())  # 也可用Sigmoid激活函数使输出在[0,1]之间\n",
    "            nn.Tanh()  # 这里使用Tanh激活函数，将输出映射到[-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('dec')  # 调试打印，查看解码器调用\n",
    "        # print('input ', x.size())  # 打印输入潜在向量的尺寸\n",
    "        x = self.fc(x)  # 通过全连接层处理潜在向量\n",
    "        x = x.view(-1, self.dim_h * 8, 7, 7)  \n",
    "        # 将全连接层输出重塑为特征图，尺寸为[batch_size, dim_h*8, 7, 7]，为反卷积做准备\n",
    "        x = self.deconv(x)  # 通过反卷积层重构出图像\n",
    "        return x  # 返回重构图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "\"\"\"set models, loss functions\"\"\"\n",
    "# 以下函数用于控制模块参数是否参与梯度更新\n",
    "\n",
    "def free_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True  # 将该模块中所有参数设置为参与梯度计算（训练状态）\n",
    "\n",
    "def frozen_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False  # 将该模块中所有参数冻结，不进行梯度更新\n",
    "\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"functions to create SMOTE images\"\"\"\n",
    "# 以下函数用于生成SMOTE（Synthetic Minority Over-sampling Technique）图像\n",
    "\n",
    "def biased_get_class(c):\n",
    "    xbeg = dec_x[dec_y == c]  # 从全局训练图像dec_x中选择标签等于c的所有样本\n",
    "    ybeg = dec_y[dec_y == c]  # 从全局标签dec_y中选择标签等于c的所有样本\n",
    "    return xbeg, ybeg  # 返回该类别的图像和标签\n",
    "    # return xclass, yclass  # 注释掉的另一种返回方式\n",
    "\n",
    "def G_SM(X, y, n_to_sample, cl):\n",
    "    # 此函数根据SMOTE思想生成新的样本\n",
    "    # determining the number of samples to generate\n",
    "    # n_to_sample = 10  # 示例：生成10个样本\n",
    "\n",
    "    # fitting the model\n",
    "    n_neigh = 5 + 1  # 设置最近邻数为6（包括自身），实际选取邻居时会跳过自身\n",
    "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)  # 初始化最近邻模型，n_jobs=1指定使用单线程\n",
    "    nn.fit(X)  # 使用数据X拟合最近邻模型\n",
    "    dist, ind = nn.kneighbors(X)  # 对每个样本找到最近邻样本的距离和索引\n",
    "\n",
    "    # generating samples\n",
    "    base_indices = np.random.choice(list(range(len(X))), n_to_sample)  \n",
    "    # 随机选择n_to_sample个样本作为基样本\n",
    "    neighbor_indices = np.random.choice(list(range(1, n_neigh)), n_to_sample)  \n",
    "    # 为每个基样本随机选择一个邻居索引（范围从1到n_neigh-1，排除自身索引0）\n",
    "\n",
    "    X_base = X[base_indices]  # 选取基样本\n",
    "    X_neighbor = X[ind[base_indices, neighbor_indices]]  # 根据邻居索引选取对应的邻居样本\n",
    "\n",
    "    samples = X_base + np.multiply(np.random.rand(n_to_sample, 1),\n",
    "                                   X_neighbor - X_base)  \n",
    "    # 在基样本和邻居样本之间随机插值，生成新的合成样本\n",
    "\n",
    "    # use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
    "    return samples, [cl] * n_to_sample  \n",
    "    # 返回生成的样本以及对应的标签列表（所有样本标签均为cl）\n",
    "\n",
    "# xsamp, ysamp = SM(xclass, yclass)  # 注释：可用此行测试SMOTE函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): AttentionBlock(\n",
      "      (query_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (key_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=300, bias=True)\n",
      ")\n",
      "Decoder(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=25088, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "train image shape: (6161, 784)\n",
      "train label shape: (6161,)\n",
      "Counter({np.int64(1): 6131, np.int64(0): 30})\n",
      "train image shape: (6161, 1, 28, 28)\n",
      "(Features)Tensor Dec_X: torch.Size([6161, 1, 28, 28])\n",
      "(Labels)Tensor Dec_y: torch.Size([6161])\n",
      "train_loader: <torch.utils.data.dataloader.DataLoader object at 0x16e5441c0>\n",
      "Epoch: 0 \tTrain Loss: 0.179880 \tmse loss: 0.098729 \tmse2 loss: 0.081152\n",
      "Saving..\n",
      "Epoch: 1 \tTrain Loss: 0.043810 \tmse loss: 0.030473 \tmse2 loss: 0.013337\n",
      "Saving..\n",
      "Epoch: 2 \tTrain Loss: 0.027922 \tmse loss: 0.020647 \tmse2 loss: 0.007275\n",
      "Saving..\n",
      "Epoch: 3 \tTrain Loss: 0.020787 \tmse loss: 0.016243 \tmse2 loss: 0.004544\n",
      "Saving..\n",
      "Epoch: 4 \tTrain Loss: 0.015647 \tmse loss: 0.012844 \tmse2 loss: 0.002803\n",
      "Saving..\n",
      "Epoch: 5 \tTrain Loss: 0.013158 \tmse loss: 0.011096 \tmse2 loss: 0.002062\n",
      "Saving..\n",
      "Epoch: 6 \tTrain Loss: 0.011829 \tmse loss: 0.010048 \tmse2 loss: 0.001782\n",
      "Saving..\n",
      "Epoch: 7 \tTrain Loss: 0.010692 \tmse loss: 0.009177 \tmse2 loss: 0.001514\n",
      "Saving..\n",
      "Epoch: 8 \tTrain Loss: 0.009434 \tmse loss: 0.008261 \tmse2 loss: 0.001174\n",
      "Saving..\n",
      "Epoch: 9 \tTrain Loss: 0.008553 \tmse loss: 0.007542 \tmse2 loss: 0.001011\n",
      "Saving..\n",
      "Epoch: 10 \tTrain Loss: 0.007979 \tmse loss: 0.007090 \tmse2 loss: 0.000889\n",
      "Saving..\n",
      "Epoch: 11 \tTrain Loss: 0.007537 \tmse loss: 0.006695 \tmse2 loss: 0.000842\n",
      "Saving..\n",
      "Epoch: 12 \tTrain Loss: 0.007132 \tmse loss: 0.006349 \tmse2 loss: 0.000782\n",
      "Saving..\n",
      "Epoch: 13 \tTrain Loss: 0.006824 \tmse loss: 0.006073 \tmse2 loss: 0.000751\n",
      "Saving..\n",
      "Epoch: 14 \tTrain Loss: 0.006336 \tmse loss: 0.005693 \tmse2 loss: 0.000643\n",
      "Saving..\n",
      "Epoch: 15 \tTrain Loss: 0.006243 \tmse loss: 0.005566 \tmse2 loss: 0.000677\n",
      "Saving..\n",
      "Epoch: 16 \tTrain Loss: 0.005796 \tmse loss: 0.005247 \tmse2 loss: 0.000549\n",
      "Saving..\n",
      "Epoch: 17 \tTrain Loss: 0.005525 \tmse loss: 0.004996 \tmse2 loss: 0.000528\n",
      "Saving..\n",
      "Epoch: 18 \tTrain Loss: 0.005462 \tmse loss: 0.004888 \tmse2 loss: 0.000575\n",
      "Saving..\n",
      "Epoch: 19 \tTrain Loss: 0.005295 \tmse loss: 0.004747 \tmse2 loss: 0.000548\n",
      "Saving..\n",
      "Epoch: 20 \tTrain Loss: 0.005018 \tmse loss: 0.004547 \tmse2 loss: 0.000471\n",
      "Saving..\n",
      "Epoch: 21 \tTrain Loss: 0.005007 \tmse loss: 0.004514 \tmse2 loss: 0.000493\n",
      "Saving..\n",
      "Epoch: 22 \tTrain Loss: 0.004653 \tmse loss: 0.004218 \tmse2 loss: 0.000436\n",
      "Saving..\n",
      "Epoch: 23 \tTrain Loss: 0.004676 \tmse loss: 0.004198 \tmse2 loss: 0.000479\n",
      "Epoch: 24 \tTrain Loss: 0.004472 \tmse loss: 0.004036 \tmse2 loss: 0.000435\n",
      "Saving..\n",
      "Epoch: 25 \tTrain Loss: 0.004377 \tmse loss: 0.003935 \tmse2 loss: 0.000442\n",
      "Saving..\n",
      "Epoch: 26 \tTrain Loss: 0.004431 \tmse loss: 0.003948 \tmse2 loss: 0.000483\n",
      "Epoch: 27 \tTrain Loss: 0.004075 \tmse loss: 0.003695 \tmse2 loss: 0.000380\n",
      "Saving..\n",
      "Epoch: 28 \tTrain Loss: 0.004043 \tmse loss: 0.003657 \tmse2 loss: 0.000386\n",
      "Saving..\n",
      "Epoch: 29 \tTrain Loss: 0.004007 \tmse loss: 0.003609 \tmse2 loss: 0.000397\n",
      "Saving..\n",
      "Epoch: 30 \tTrain Loss: 0.003740 \tmse loss: 0.003411 \tmse2 loss: 0.000329\n",
      "Saving..\n",
      "Epoch: 31 \tTrain Loss: 0.003708 \tmse loss: 0.003355 \tmse2 loss: 0.000353\n",
      "Saving..\n",
      "Epoch: 32 \tTrain Loss: 0.003615 \tmse loss: 0.003273 \tmse2 loss: 0.000342\n",
      "Saving..\n",
      "Epoch: 33 \tTrain Loss: 0.003385 \tmse loss: 0.003095 \tmse2 loss: 0.000291\n",
      "Saving..\n",
      "Epoch: 34 \tTrain Loss: 0.003441 \tmse loss: 0.003112 \tmse2 loss: 0.000329\n",
      "Epoch: 35 \tTrain Loss: 0.003358 \tmse loss: 0.003029 \tmse2 loss: 0.000329\n",
      "Saving..\n",
      "Epoch: 36 \tTrain Loss: 0.003190 \tmse loss: 0.002906 \tmse2 loss: 0.000284\n",
      "Saving..\n",
      "Epoch: 37 \tTrain Loss: 0.003204 \tmse loss: 0.002902 \tmse2 loss: 0.000302\n",
      "Epoch: 38 \tTrain Loss: 0.003202 \tmse loss: 0.002891 \tmse2 loss: 0.000311\n",
      "Epoch: 39 \tTrain Loss: 0.003023 \tmse loss: 0.002747 \tmse2 loss: 0.000276\n",
      "Saving..\n",
      "Epoch: 40 \tTrain Loss: 0.002988 \tmse loss: 0.002719 \tmse2 loss: 0.000270\n",
      "Saving..\n",
      "Epoch: 41 \tTrain Loss: 0.003066 \tmse loss: 0.002749 \tmse2 loss: 0.000316\n",
      "Epoch: 42 \tTrain Loss: 0.002914 \tmse loss: 0.002634 \tmse2 loss: 0.000280\n",
      "Saving..\n",
      "Epoch: 43 \tTrain Loss: 0.002815 \tmse loss: 0.002556 \tmse2 loss: 0.000258\n",
      "Saving..\n",
      "Epoch: 44 \tTrain Loss: 0.002721 \tmse loss: 0.002476 \tmse2 loss: 0.000245\n",
      "Saving..\n",
      "Epoch: 45 \tTrain Loss: 0.002731 \tmse loss: 0.002479 \tmse2 loss: 0.000252\n",
      "Epoch: 46 \tTrain Loss: 0.002691 \tmse loss: 0.002438 \tmse2 loss: 0.000253\n",
      "Saving..\n",
      "Epoch: 47 \tTrain Loss: 0.002534 \tmse loss: 0.002309 \tmse2 loss: 0.000224\n",
      "Saving..\n",
      "Epoch: 48 \tTrain Loss: 0.002474 \tmse loss: 0.002262 \tmse2 loss: 0.000212\n",
      "Saving..\n",
      "Epoch: 49 \tTrain Loss: 0.002453 \tmse loss: 0.002235 \tmse2 loss: 0.000218\n",
      "Saving..\n",
      "DS_0.005_final_enc.pth\n",
      "DS_0.005_final_dec.pth\n",
      "\n",
      "total time(min): 149.21\n",
      "final time(min): 152.51\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(args)  # 创建编码器模型\n",
    "decoder = Decoder(args)  # 创建解码器模型\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 检测GPU是否可用\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)  # 将模型移动到GPU上\n",
    "train_on_gpu = torch.cuda.is_available()  # 检测GPU是否可用\n",
    "#Deconder loss function\n",
    "criterion = nn.MSELoss()  # 定义均方误差损失函数\n",
    "criterion = criterion.to(device)  # 将损失函数移动到GPU上\n",
    "\n",
    "dec_x = X_train  # 获取训练数据\n",
    "dec_y = y_train  # 获取训练标签\n",
    "print('train image shape:', dec_x.shape)  # 打印训练数据形状\n",
    "print('train label shape:', dec_y.shape)  # 打印训练标签形状\n",
    "#print('train image:', dec_x)  # 打印训练数据\n",
    "#print('train label:', dec_y)  # 打印训练标签\n",
    "print(collections.Counter(dec_y))  # 使用Counter统计每个类别的样本数量\n",
    "dec_x = dec_x.reshape(-1, 1, 28, 28)  # 将训练数据重塑为合适的形状\n",
    "print('train image shape:', dec_x.shape)  # 打印重塑后的训练数据形状\n",
    "batch_size = args['batch_size']  # 获取批次大小\n",
    "num_workers = 0  # 设置数据加载器的线程数\n",
    "tensor_x = torch.Tensor(dec_x)  # 将NumPy数组转换为PyTorch张量\n",
    "tensor_y = torch.tensor(dec_y, dtype = torch.long)  # 将NumPy数组转换为PyTorch张量\n",
    "print('(Features)Tensor Dec_X:',tensor_x.shape)\n",
    "print('(Labels)Tensor Dec_y:',tensor_y.shape)\n",
    "\n",
    "mnist_train  =  TensorDataset(tensor_x, tensor_y)  # 将特征和标签打包为数据集\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True)  # 创建数据加载器\n",
    "print('train_loader:',train_loader)\n",
    "classes = ('0','1') # binary classification\n",
    "best_loss = np.inf  # 初始化最佳损失为无穷大\n",
    "\n",
    "t0 = time.time()  # 记录当前时间，用于计算训练时间\n",
    "if args['train']:\n",
    "    fraction = args['fraction']  # 获取数据集子集比例\n",
    "    encoder_optim = torch.optim.Adam(encoder.parameters(), lr=args['lr'])  # 创建编码器的Adam优化器\n",
    "    decoder_optim = torch.optim.Adam(decoder.parameters(), lr=args['lr'])  # 创建解码器的Adam优化器\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        train_loss = 0.0  # 初始化训练损失为0\n",
    "        tmse_loss = 0.0 # 初始化均方误差损失为0\n",
    "        tdiscr_loss = 0.0 # 初始化判别器损失为0\n",
    "        encoder.train()  # 设置编码器为训练模式\n",
    "        decoder.train()\n",
    "        for images, labels in train_loader: # 从数据加载器中加载数据\n",
    "            encoder_optim.zero_grad()\n",
    "            decoder_optim.zero_grad()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labsn = labels.detach().cpu().numpy()  # 将标签转换为NumPy数组\n",
    "            #print('labsn:',labsn.shape, labsn)\n",
    "            z_hat = encoder(images) # 通过编码器生成潜在向量\n",
    "            x_hat = decoder(z_hat) # 通过解码器生成重构图像\n",
    "            mse_loss = criterion(x_hat, images) # 计算重构图像与原始图像的均方误差\n",
    "            #print('mse_loss:',mse_loss)\n",
    "            resx = [] \n",
    "            resy = []\n",
    "            tc = 0 # 固定类别\n",
    "            xbeg = dec_x[dec_y == tc]  # 从全局训练图像dec_x中选择标签等于c的所有样本\n",
    "            ybeg = dec_y[dec_y == tc]  # 从全局标签dec_y中选择标签等于c的所有样本\n",
    "            xlen = len(xbeg)\n",
    "            #print('xbeg:',xbeg.shape)\n",
    "            nsample = min(100, xlen)  # 生成样本数\n",
    "            ind = np.random.choice(list(range(xlen)), nsample, replace=False)  # 随机选择nsample个样本\n",
    "            xclass = xbeg[ind]  # 选择对应的图像\n",
    "            yclass = ybeg[ind]\n",
    "            xclen = len(xclass)\n",
    "            xcminus = np.arange(1,xclen) # 1 to xclen-1\n",
    "            xcplus = np.append(xcminus, 0 ) # 0 to xclen-2\n",
    "\n",
    "            xcnew = (xclass[[xcplus], :])  \n",
    "\n",
    "            xcnew = xcnew = xcnew.reshape(xcnew.shape[1], xcnew.shape[2], xcnew.shape[3], xcnew.shape[4]) # 1 to xclen-1, 0 to xclen-2\n",
    "            #print('xcnew:',xcnew.shape)\n",
    "\n",
    "            xcnew = torch.Tensor(xcnew)\n",
    "            xcnew = xcnew.to(device)\n",
    "            xclass = torch.Tensor(xclass)\n",
    "            xclass = xclass.to(device)\n",
    "            xclass = encoder(xclass)\n",
    "            xclass = xclass.detach().cpu().numpy()\n",
    "            xc_enc = (xclass[[xcplus],:])\n",
    "            xc_enc = np.squeeze(xc_enc)\n",
    "            xc_enc = torch.Tensor(xc_enc)\n",
    "            xc_enc = xc_enc.to(device)\n",
    "            #print('xc_enc:',xc_enc.shape)\n",
    "            ximg = decoder(xc_enc)\n",
    "            mse_loss2 = criterion(ximg, xcnew)\n",
    "            #print('mse_loss2:',mse_loss2)\n",
    "            combined_loss = mse_loss + mse_loss2\n",
    "            combined_loss.backward()\n",
    "\n",
    "            encoder_optim.step()\n",
    "            decoder_optim.step()\n",
    "\n",
    "            train_loss += combined_loss.item() * images.size(0)\n",
    "            tmse_loss += mse_loss.item() * images.size(0)\n",
    "            #print('train_loss:',train_loss)\n",
    "            #print('tmse_loss:',tmse_loss)\n",
    "            tdiscr_loss += mse_loss2.item() * images.size(0)\n",
    "            #print('tdiscr_loss:',tdiscr_loss)\n",
    "\n",
    "\n",
    "        # print training statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        tmse_loss = tmse_loss / len(train_loader.dataset)\n",
    "        tdiscr_loss = tdiscr_loss / len(train_loader.dataset)\n",
    "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
    "                  train_loss, tmse_loss, tdiscr_loss))  \n",
    "            # 打印当前epoch的损失信息\n",
    "        # store the best encoder and decoder models\n",
    "            # here, /crs5 is a reference to 5 way cross validation, but is not\n",
    "            # necessary for illustration purposes\n",
    "        if train_loss < best_loss:  \n",
    "            # 如果当前epoch的平均损失低于历史最佳损失，则保存模型\n",
    "            print('Saving..')\n",
    "            path_enc = 'DeepSMOTE_{}_bst_enc.pth'.format(fraction)\n",
    "            # 构造保存最佳编码器模型的文件路径\n",
    "            path_dec = 'DeepSMOTE_{}_bst_dec.pth'.format(fraction)\n",
    "            # 构造保存最佳解码器模型的文件路径\n",
    "            \n",
    "            torch.save(encoder.state_dict(), path_enc)  \n",
    "            # 保存编码器当前状态字典（权重参数）\n",
    "            torch.save(decoder.state_dict(), path_dec)  \n",
    "            # 保存解码器当前状态字典\n",
    "            \n",
    "            best_loss = train_loss  # 更新历史最佳损失值\n",
    "     # in addition, store the final model (may not be the best) for\n",
    "    # informational purposes\n",
    "    \n",
    "    path_enc = 'DS_{}_final_enc.pth'.format(fraction)  \n",
    "    # 构造保存最终编码器模型（可能不是最佳）的文件路径\n",
    "    path_dec = 'DS_{}_final_dec.pth'.format(fraction)  \n",
    "    # 构造保存最终解码器模型的文件路径\n",
    "    print(path_enc)\n",
    "    print(path_dec)\n",
    "    torch.save(encoder.state_dict(), path_enc)  # 保存最终编码器状态\n",
    "    torch.save(decoder.state_dict(), path_dec)  # 保存最终解码器状态\n",
    "    print()\n",
    "t1 = time.time()  # 记录当前fold训练结束时间\n",
    "print('total time(min): {:.2f}'.format((t1 - t0) / 60))  \n",
    "# 输出当前fold训练耗时（单位：分钟）\n",
    "\n",
    "t4 = time.time()  # 记录整个程序结束时的时间\n",
    "print('final time(min): {:.2f}'.format((t4 - t3) / 60))  \n",
    "# 输出整个程序运行的总耗时（单位：分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
