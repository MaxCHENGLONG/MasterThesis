{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections  # 导入collections模块，用于统计和操作容器数据，如Counter\n",
    "import torch  # 导入PyTorch库，用于深度学习任务\n",
    "import torch.nn as nn  # 从torch中导入神经网络模块，简化模型构建\n",
    "from torch.utils.data import TensorDataset  # 导入TensorDataset，用于将Tensor数据打包成数据集\n",
    "import numpy as np  # 导入NumPy库，用于高效的数值计算和数组操作\n",
    "from sklearn.neighbors import NearestNeighbors  # 导入最近邻算法，用于在SMOTE中寻找相邻样本\n",
    "import time  # 导入time模块，用于计时\n",
    "import os  # 导入os模块，用于文件和目录操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'dim_h': 64, 'n_channel': 1, 'n_z': 300, 'sigma': 1.0, 'lambda': 0.01, 'lr': 0.0002, 'epochs': 50, 'batch_size': 64, 'save': True, 'train': True, 'dataset': 'mnist34', 'fraction': 0.005}\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # 打印当前PyTorch使用的CUDA版本，例如显示\"10.1\"\n",
    "\n",
    "t3 = time.time()  # 记录程序开始时的时间，用于后续计算总运行时间\n",
    "##############################################################################\n",
    "\"\"\"args for AE\"\"\"\n",
    "# 以下部分设置自动编码器（AE）的相关参数\n",
    "args = {}  # 创建一个空字典，用于存放模型和训练的参数\n",
    "args['dim_h'] = 64         # 设置隐藏层通道数的基础因子，后续卷积层的通道数会成倍增加\n",
    "args['n_channel'] = 1  #3    # 输入数据的通道数，1表示灰度图（3则为彩色图）；这里选用灰度图\n",
    "args['n_z'] = 300 #600     # 潜在空间（编码空间）的维度数，决定编码器输出特征向量的大小\n",
    "args['sigma'] = 1.0        # 潜在空间中使用的方差参数，可用于正则化\n",
    "args['lambda'] = 0.01      # 判别器损失的权重超参数（如在对抗训练中使用）\n",
    "args['lr'] = 0.0002        # Adam优化器的学习率，决定参数更新的步长\n",
    "args['epochs'] = 50       # 训练过程中遍历数据集的轮数\n",
    "args['batch_size'] = 64   # 每个训练批次的样本数量\n",
    "args['save'] = True        # 如果为True，则在每个训练轮结束时保存模型权重\n",
    "args['train'] = True       # 若为True则进行训练，否则加载已保存的模型进行测试\n",
    "args['dataset'] = 'mnist34'  #'fmnist' # 指定使用的数据集，这里选择MNIST数据集 mnist34 mnist17 fashionmnist34 cifar10\n",
    "args['fraction'] = 0.005   # 用于训练的数据集的子集比例，可用于快速测试\n",
    "\n",
    "##############################################################################\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the MNIST dataset with labels 3 and 4.\n",
      "Imbalanced Ratio:  0.005\n",
      "Number of label 3 in the final training set:  6131\n",
      "Number of label 4 in the final training set (after downsampling):  30\n",
      "Number of label 3 in the final test set:  1010\n",
      "Number of label 4 in the final test set:  982\n",
      "Total samples in final training set:  6161\n",
      "Total samples in final test set:  1992\n",
      "Number of batches in training set:  97\n",
      "Number of batches in test set:  32\n",
      "Images shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n",
      "First image tensor:\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.5882, 0.9922, 1.0000, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 1.0000, 0.5843, 0.0392, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5490, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.8510, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5412, 0.9843, 0.9843, 0.5608, 0.5569,\n",
      "          0.6196, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.2784, 0.2784, 0.0000, 0.0000,\n",
      "          0.1451, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 0.2863, 0.2863,\n",
      "          0.3882, 0.9922, 0.9922, 1.0000, 0.9922, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0824, 0.5647, 0.8667, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0824, 0.7725, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.5647, 0.9843, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.5647, 0.9843, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4118, 0.7059, 0.8314, 0.7882, 0.7137, 0.3020,\n",
      "          0.0000, 0.0000, 0.7137, 1.0000, 0.9922, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.1176, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.7059, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.6510, 0.8549, 0.3647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0235, 0.1451, 0.7451, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.6667,\n",
      "          0.9843, 0.9922, 0.6627, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4510, 0.9843, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6510, 0.9843,\n",
      "          0.9843, 0.9922, 0.9843, 0.2392, 0.4039, 0.0000, 0.7137, 0.7059,\n",
      "          0.9451, 0.9843, 0.9843, 0.7882, 0.2784, 0.0392, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8549, 0.9922,\n",
      "          0.9922, 1.0000, 0.9922, 0.9922, 0.9922, 0.9922, 1.0000, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9843,\n",
      "          0.9843, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.9843, 0.9843, 0.5765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9843,\n",
      "          0.9843, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922, 0.9843,\n",
      "          0.7608, 0.1373, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.9843,\n",
      "          0.9843, 0.9922, 0.9843, 0.9216, 0.7412, 0.9843, 0.5608, 0.5569,\n",
      "          0.0784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.5804,\n",
      "          0.4784, 0.9922, 0.9843, 0.3373, 0.1216, 0.2784, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "First image label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6161, 784)\n",
      "y_train.shape: (6161,)\n",
      "X_test.shape: (1992, 784)\n",
      "y_test.shape: (1992,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Get_datasets import get_datasets\n",
    "X_train,y_train ,X_test,y_test = get_datasets(dataname='mnist34',fraction=args['fraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义编码器模型\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入数据的通道数\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "        \n",
    "        # 使用卷积层提取图像特征\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),  \n",
    "            # 第一层卷积：输入通道数为n_channel，输出为dim_h，卷积核大小4，步幅2，填充1，无偏置\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 使用LeakyReLU激活函数，负半部斜率设为0.2\n",
    "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),  \n",
    "            # 第二层卷积：通道数翻倍到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 对第二层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),  \n",
    "            # 第三层卷积：通道数增加到dim_h*4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # 激活函数\n",
    "            \n",
    "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),  \n",
    "            # 第四层卷积：通道数增加到dim_h*8\n",
    "            \n",
    "            #3d and 32 by 32\n",
    "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),  # 备用卷积层配置\n",
    "            nn.BatchNorm2d(self.dim_h * 8),  # 对第四层卷积输出进行批归一化\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True)  # 激活函数\n",
    "            # 注释中还有其他可能的卷积配置，这里使用的是标准配置\n",
    "        )\n",
    "        # 全连接层：将卷积层输出映射到潜在空间\n",
    "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)  \n",
    "        # 这里计算dim_h * (2**3)相当于dim_h*8，假设卷积层最后输出特征数为dim_h*8\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('enc')  # 调试打印，可查看编码器被调用\n",
    "        # print('input ', x.size())  # 打印输入尺寸，例如torch.Size([batch_size, channel, H, W])\n",
    "        x = self.conv(x)  # 将输入图像通过卷积层提取特征\n",
    "        x = x.squeeze()   # 去除多余的尺寸（例如将[batch_size, 1, N]变为[batch_size, N]）\n",
    "        # print('aft squeeze ', x.size())  # 调试打印压缩后的尺寸\n",
    "        x = self.fc(x)    # 通过全连接层映射到潜在空间维度\n",
    "        # print('out ', x.size())  # 打印最终输出尺寸，应为[batch_size, n_z]\n",
    "        return x  # 返回编码后的潜在表示\n",
    "\n",
    "# 定义解码器模型\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()  # 调用父类构造函数\n",
    "        self.n_channel = args['n_channel']  # 获取输入通道数（用于输出重构图像）\n",
    "        self.dim_h = args['dim_h']          # 获取隐藏层基本通道数\n",
    "        self.n_z = args['n_z']              # 获取潜在空间的维度数\n",
    "\n",
    "        # 全连接层：将潜在向量映射到足够重构卷积特征图的尺寸\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),  # 将潜在向量转换为高维特征，尺寸为[batch_size, dim_h*8*7*7]\n",
    "            nn.ReLU()  # 使用ReLU激活函数\n",
    "        )\n",
    "\n",
    "        # 反卷积层（转置卷积）：将全连接层的输出转换为图像\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),  \n",
    "            # 第一层反卷积：将通道数从dim_h*8降到dim_h*4，卷积核大小4\n",
    "            nn.BatchNorm2d(self.dim_h * 4),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),  \n",
    "            # 第二层反卷积：将通道数从dim_h*4降到dim_h*2\n",
    "            nn.BatchNorm2d(self.dim_h * 2),  # 批归一化\n",
    "            nn.ReLU(True),  # 激活函数\n",
    "            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),  \n",
    "            # 第三层反卷积：将通道数降为1，同时上采样（步幅为2），恢复到原图大小\n",
    "            # nn.Sigmoid())  # 也可用Sigmoid激活函数使输出在[0,1]之间\n",
    "            nn.Tanh()  # 这里使用Tanh激活函数，将输出映射到[-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # print('dec')  # 调试打印，查看解码器调用\n",
    "        # print('input ', x.size())  # 打印输入潜在向量的尺寸\n",
    "        x = self.fc(x)  # 通过全连接层处理潜在向量\n",
    "        x = x.view(-1, self.dim_h * 8, 7, 7)  \n",
    "        # 将全连接层输出重塑为特征图，尺寸为[batch_size, dim_h*8, 7, 7]，为反卷积做准备\n",
    "        x = self.deconv(x)  # 通过反卷积层重构出图像\n",
    "        return x  # 返回重构图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "\"\"\"set models, loss functions\"\"\"\n",
    "# 以下函数用于控制模块参数是否参与梯度更新\n",
    "\n",
    "def free_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True  # 将该模块中所有参数设置为参与梯度计算（训练状态）\n",
    "\n",
    "def frozen_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False  # 将该模块中所有参数冻结，不进行梯度更新\n",
    "\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"functions to create SMOTE images\"\"\"\n",
    "# 以下函数用于生成SMOTE（Synthetic Minority Over-sampling Technique）图像\n",
    "\n",
    "def biased_get_class(c):\n",
    "    xbeg = dec_x[dec_y == c]  # 从全局训练图像dec_x中选择标签等于c的所有样本\n",
    "    ybeg = dec_y[dec_y == c]  # 从全局标签dec_y中选择标签等于c的所有样本\n",
    "    return xbeg, ybeg  # 返回该类别的图像和标签\n",
    "    # return xclass, yclass  # 注释掉的另一种返回方式\n",
    "\n",
    "def G_SM(X, y, n_to_sample, cl):\n",
    "    # 此函数根据SMOTE思想生成新的样本\n",
    "    # determining the number of samples to generate\n",
    "    # n_to_sample = 10  # 示例：生成10个样本\n",
    "\n",
    "    # fitting the model\n",
    "    n_neigh = 5 + 1  # 设置最近邻数为6（包括自身），实际选取邻居时会跳过自身\n",
    "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)  # 初始化最近邻模型，n_jobs=1指定使用单线程\n",
    "    nn.fit(X)  # 使用数据X拟合最近邻模型\n",
    "    dist, ind = nn.kneighbors(X)  # 对每个样本找到最近邻样本的距离和索引\n",
    "\n",
    "    # generating samples\n",
    "    base_indices = np.random.choice(list(range(len(X))), n_to_sample)  \n",
    "    # 随机选择n_to_sample个样本作为基样本\n",
    "    neighbor_indices = np.random.choice(list(range(1, n_neigh)), n_to_sample)  \n",
    "    # 为每个基样本随机选择一个邻居索引（范围从1到n_neigh-1，排除自身索引0）\n",
    "\n",
    "    X_base = X[base_indices]  # 选取基样本\n",
    "    X_neighbor = X[ind[base_indices, neighbor_indices]]  # 根据邻居索引选取对应的邻居样本\n",
    "\n",
    "    samples = X_base + np.multiply(np.random.rand(n_to_sample, 1),\n",
    "                                   X_neighbor - X_base)  \n",
    "    # 在基样本和邻居样本之间随机插值，生成新的合成样本\n",
    "\n",
    "    # use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
    "    return samples, [cl] * n_to_sample  \n",
    "    # 返回生成的样本以及对应的标签列表（所有样本标签均为cl）\n",
    "\n",
    "# xsamp, ysamp = SM(xclass, yclass)  # 注释：可用此行测试SMOTE函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=300, bias=True)\n",
      ")\n",
      "Decoder(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=25088, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "train image shape: (6161, 784)\n",
      "train label shape: (6161,)\n",
      "Counter({np.int64(1): 6131, np.int64(0): 30})\n",
      "train image shape: (6161, 1, 28, 28)\n",
      "(Features)Tensor Dec_X: torch.Size([6161, 1, 28, 28])\n",
      "(Labels)Tensor Dec_y: torch.Size([6161])\n",
      "train_loader: <torch.utils.data.dataloader.DataLoader object at 0x15ae1a940>\n",
      "Epoch: 0 \tTrain Loss: 0.217597 \tmse loss: 0.117562 \tmse2 loss: 0.100035\n",
      "Saving..\n",
      "Epoch: 1 \tTrain Loss: 0.050956 \tmse loss: 0.033207 \tmse2 loss: 0.017748\n",
      "Saving..\n",
      "Epoch: 2 \tTrain Loss: 0.026497 \tmse loss: 0.020646 \tmse2 loss: 0.005851\n",
      "Saving..\n",
      "Epoch: 3 \tTrain Loss: 0.018683 \tmse loss: 0.015579 \tmse2 loss: 0.003104\n",
      "Saving..\n",
      "Epoch: 4 \tTrain Loss: 0.015448 \tmse loss: 0.013103 \tmse2 loss: 0.002345\n",
      "Saving..\n",
      "Epoch: 5 \tTrain Loss: 0.012924 \tmse loss: 0.011173 \tmse2 loss: 0.001751\n",
      "Saving..\n",
      "Epoch: 6 \tTrain Loss: 0.011389 \tmse loss: 0.009890 \tmse2 loss: 0.001500\n",
      "Saving..\n",
      "Epoch: 7 \tTrain Loss: 0.010209 \tmse loss: 0.008914 \tmse2 loss: 0.001295\n",
      "Saving..\n",
      "Epoch: 8 \tTrain Loss: 0.009425 \tmse loss: 0.008249 \tmse2 loss: 0.001176\n",
      "Saving..\n",
      "Epoch: 9 \tTrain Loss: 0.008690 \tmse loss: 0.007622 \tmse2 loss: 0.001068\n",
      "Saving..\n",
      "Epoch: 10 \tTrain Loss: 0.008040 \tmse loss: 0.007080 \tmse2 loss: 0.000959\n",
      "Saving..\n",
      "Epoch: 11 \tTrain Loss: 0.007557 \tmse loss: 0.006683 \tmse2 loss: 0.000874\n",
      "Saving..\n",
      "Epoch: 12 \tTrain Loss: 0.007017 \tmse loss: 0.006235 \tmse2 loss: 0.000782\n",
      "Saving..\n",
      "Epoch: 13 \tTrain Loss: 0.006763 \tmse loss: 0.005967 \tmse2 loss: 0.000796\n",
      "Saving..\n",
      "Epoch: 14 \tTrain Loss: 0.006421 \tmse loss: 0.005710 \tmse2 loss: 0.000710\n",
      "Saving..\n",
      "Epoch: 15 \tTrain Loss: 0.005845 \tmse loss: 0.005253 \tmse2 loss: 0.000592\n",
      "Saving..\n",
      "Epoch: 16 \tTrain Loss: 0.005686 \tmse loss: 0.005081 \tmse2 loss: 0.000606\n",
      "Saving..\n",
      "Epoch: 17 \tTrain Loss: 0.005456 \tmse loss: 0.004878 \tmse2 loss: 0.000578\n",
      "Saving..\n",
      "Epoch: 18 \tTrain Loss: 0.005318 \tmse loss: 0.004747 \tmse2 loss: 0.000571\n",
      "Saving..\n",
      "Epoch: 19 \tTrain Loss: 0.005078 \tmse loss: 0.004543 \tmse2 loss: 0.000535\n",
      "Saving..\n",
      "Epoch: 20 \tTrain Loss: 0.004814 \tmse loss: 0.004329 \tmse2 loss: 0.000485\n",
      "Saving..\n",
      "Epoch: 21 \tTrain Loss: 0.004727 \tmse loss: 0.004221 \tmse2 loss: 0.000506\n",
      "Saving..\n",
      "Epoch: 22 \tTrain Loss: 0.004573 \tmse loss: 0.004108 \tmse2 loss: 0.000464\n",
      "Saving..\n",
      "Epoch: 23 \tTrain Loss: 0.004340 \tmse loss: 0.003901 \tmse2 loss: 0.000439\n",
      "Saving..\n",
      "Epoch: 24 \tTrain Loss: 0.004389 \tmse loss: 0.003913 \tmse2 loss: 0.000476\n",
      "Epoch: 25 \tTrain Loss: 0.004311 \tmse loss: 0.003838 \tmse2 loss: 0.000473\n",
      "Saving..\n",
      "Epoch: 26 \tTrain Loss: 0.004121 \tmse loss: 0.003697 \tmse2 loss: 0.000424\n",
      "Saving..\n",
      "Epoch: 27 \tTrain Loss: 0.003942 \tmse loss: 0.003545 \tmse2 loss: 0.000396\n",
      "Saving..\n",
      "Epoch: 28 \tTrain Loss: 0.003868 \tmse loss: 0.003474 \tmse2 loss: 0.000394\n",
      "Saving..\n",
      "Epoch: 29 \tTrain Loss: 0.003713 \tmse loss: 0.003345 \tmse2 loss: 0.000368\n",
      "Saving..\n",
      "Epoch: 30 \tTrain Loss: 0.003698 \tmse loss: 0.003323 \tmse2 loss: 0.000375\n",
      "Saving..\n",
      "Epoch: 31 \tTrain Loss: 0.003532 \tmse loss: 0.003195 \tmse2 loss: 0.000338\n",
      "Saving..\n",
      "Epoch: 32 \tTrain Loss: 0.003547 \tmse loss: 0.003170 \tmse2 loss: 0.000377\n",
      "Epoch: 33 \tTrain Loss: 0.003538 \tmse loss: 0.003133 \tmse2 loss: 0.000405\n",
      "Epoch: 34 \tTrain Loss: 0.003331 \tmse loss: 0.002994 \tmse2 loss: 0.000337\n",
      "Saving..\n",
      "Epoch: 35 \tTrain Loss: 0.003295 \tmse loss: 0.002960 \tmse2 loss: 0.000335\n",
      "Saving..\n",
      "Epoch: 36 \tTrain Loss: 0.003204 \tmse loss: 0.002889 \tmse2 loss: 0.000315\n",
      "Saving..\n",
      "Epoch: 37 \tTrain Loss: 0.003086 \tmse loss: 0.002785 \tmse2 loss: 0.000301\n",
      "Saving..\n",
      "Epoch: 38 \tTrain Loss: 0.003117 \tmse loss: 0.002802 \tmse2 loss: 0.000315\n",
      "Epoch: 39 \tTrain Loss: 0.003003 \tmse loss: 0.002706 \tmse2 loss: 0.000296\n",
      "Saving..\n",
      "Epoch: 40 \tTrain Loss: 0.002947 \tmse loss: 0.002640 \tmse2 loss: 0.000306\n",
      "Saving..\n",
      "Epoch: 41 \tTrain Loss: 0.002982 \tmse loss: 0.002647 \tmse2 loss: 0.000335\n",
      "Epoch: 42 \tTrain Loss: 0.002820 \tmse loss: 0.002551 \tmse2 loss: 0.000270\n",
      "Saving..\n",
      "Epoch: 43 \tTrain Loss: 0.002780 \tmse loss: 0.002504 \tmse2 loss: 0.000276\n",
      "Saving..\n",
      "Epoch: 44 \tTrain Loss: 0.002624 \tmse loss: 0.002394 \tmse2 loss: 0.000230\n",
      "Saving..\n",
      "Epoch: 45 \tTrain Loss: 0.002607 \tmse loss: 0.002370 \tmse2 loss: 0.000237\n",
      "Saving..\n",
      "Epoch: 46 \tTrain Loss: 0.002665 \tmse loss: 0.002391 \tmse2 loss: 0.000274\n",
      "Epoch: 47 \tTrain Loss: 0.002550 \tmse loss: 0.002288 \tmse2 loss: 0.000262\n",
      "Saving..\n",
      "Epoch: 48 \tTrain Loss: 0.002699 \tmse loss: 0.002399 \tmse2 loss: 0.000299\n",
      "Epoch: 49 \tTrain Loss: 0.002534 \tmse loss: 0.002291 \tmse2 loss: 0.000243\n",
      "Saving..\n",
      "DS_0.005_final_enc.pth\n",
      "DS_0.005_final_dec.pth\n",
      "\n",
      "total time(min): 206.12\n",
      "final time(min): 206.14\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(args)  # 创建编码器模型\n",
    "decoder = Decoder(args)  # 创建解码器模型\n",
    "print(encoder)\n",
    "print(decoder)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 检测GPU是否可用\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)  # 将模型移动到GPU上\n",
    "train_on_gpu = torch.cuda.is_available()  # 检测GPU是否可用\n",
    "#Deconder loss function\n",
    "criterion = nn.MSELoss()  # 定义均方误差损失函数\n",
    "criterion = criterion.to(device)  # 将损失函数移动到GPU上\n",
    "\n",
    "dec_x = X_train  # 获取训练数据\n",
    "dec_y = y_train  # 获取训练标签\n",
    "print('train image shape:', dec_x.shape)  # 打印训练数据形状\n",
    "print('train label shape:', dec_y.shape)  # 打印训练标签形状\n",
    "#print('train image:', dec_x)  # 打印训练数据\n",
    "#print('train label:', dec_y)  # 打印训练标签\n",
    "print(collections.Counter(dec_y))  # 使用Counter统计每个类别的样本数量\n",
    "dec_x = dec_x.reshape(-1, 1, 28, 28)  # 将训练数据重塑为合适的形状\n",
    "print('train image shape:', dec_x.shape)  # 打印重塑后的训练数据形状\n",
    "batch_size = args['batch_size']  # 获取批次大小\n",
    "num_workers = 0  # 设置数据加载器的线程数\n",
    "tensor_x = torch.Tensor(dec_x)  # 将NumPy数组转换为PyTorch张量\n",
    "tensor_y = torch.tensor(dec_y, dtype = torch.long)  # 将NumPy数组转换为PyTorch张量\n",
    "print('(Features)Tensor Dec_X:',tensor_x.shape)\n",
    "print('(Labels)Tensor Dec_y:',tensor_y.shape)\n",
    "\n",
    "mnist_train  =  TensorDataset(tensor_x, tensor_y)  # 将特征和标签打包为数据集\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True)  # 创建数据加载器\n",
    "print('train_loader:',train_loader)\n",
    "classes = ('0','1') # binary classification\n",
    "best_loss = np.inf  # 初始化最佳损失为无穷大\n",
    "\n",
    "t0 = time.time()  # 记录当前时间，用于计算训练时间\n",
    "if args['train']:\n",
    "    fraction = args['fraction']  # 获取数据集子集比例\n",
    "    encoder_optim = torch.optim.Adam(encoder.parameters(), lr=args['lr'])  # 创建编码器的Adam优化器\n",
    "    decoder_optim = torch.optim.Adam(decoder.parameters(), lr=args['lr'])  # 创建解码器的Adam优化器\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        train_loss = 0.0  # 初始化训练损失为0\n",
    "        tmse_loss = 0.0 # 初始化均方误差损失为0\n",
    "        tdiscr_loss = 0.0 # 初始化判别器损失为0\n",
    "        encoder.train()  # 设置编码器为训练模式\n",
    "        decoder.train()\n",
    "        for images, labels in train_loader: # 从数据加载器中加载数据\n",
    "            encoder_optim.zero_grad()\n",
    "            decoder_optim.zero_grad()\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labsn = labels.detach().cpu().numpy()  # 将标签转换为NumPy数组\n",
    "            #print('labsn:',labsn.shape, labsn)\n",
    "            z_hat = encoder(images) # 通过编码器生成潜在向量\n",
    "            x_hat = decoder(z_hat) # 通过解码器生成重构图像\n",
    "            mse_loss = criterion(x_hat, images) # 计算重构图像与原始图像的均方误差\n",
    "            #print('mse_loss:',mse_loss)\n",
    "            resx = [] \n",
    "            resy = []\n",
    "            tc = 0 # 固定类别\n",
    "            xbeg = dec_x[dec_y == tc]  # 从全局训练图像dec_x中选择标签等于c的所有样本\n",
    "            ybeg = dec_y[dec_y == tc]  # 从全局标签dec_y中选择标签等于c的所有样本\n",
    "            xlen = len(xbeg)\n",
    "            #print('xbeg:',xbeg.shape)\n",
    "            nsample = min(100, xlen)  # 生成样本数\n",
    "            ind = np.random.choice(list(range(xlen)), nsample, replace=False)  # 随机选择nsample个样本\n",
    "            xclass = xbeg[ind]  # 选择对应的图像\n",
    "            yclass = ybeg[ind]\n",
    "            xclen = len(xclass)\n",
    "            xcminus = np.arange(1,xclen) # 1 to xclen-1\n",
    "            xcplus = np.append(xcminus, 0 ) # 0 to xclen-2\n",
    "\n",
    "            xcnew = (xclass[[xcplus], :])  \n",
    "\n",
    "            xcnew = xcnew = xcnew.reshape(xcnew.shape[1], xcnew.shape[2], xcnew.shape[3], xcnew.shape[4]) # 1 to xclen-1, 0 to xclen-2\n",
    "            #print('xcnew:',xcnew.shape)\n",
    "\n",
    "            xcnew = torch.Tensor(xcnew)\n",
    "            xcnew = xcnew.to(device)\n",
    "            xclass = torch.Tensor(xclass)\n",
    "            xclass = xclass.to(device)\n",
    "            xclass = encoder(xclass)\n",
    "            xclass = xclass.detach().cpu().numpy()\n",
    "            xc_enc = (xclass[[xcplus],:])\n",
    "            xc_enc = np.squeeze(xc_enc)\n",
    "            xc_enc = torch.Tensor(xc_enc)\n",
    "            xc_enc = xc_enc.to(device)\n",
    "            #print('xc_enc:',xc_enc.shape)\n",
    "            ximg = decoder(xc_enc)\n",
    "            mse_loss2 = criterion(ximg, xcnew)\n",
    "            #print('mse_loss2:',mse_loss2)\n",
    "            combined_loss = mse_loss + mse_loss2\n",
    "            combined_loss.backward()\n",
    "\n",
    "            encoder_optim.step()\n",
    "            decoder_optim.step()\n",
    "\n",
    "            train_loss += combined_loss.item() * images.size(0)\n",
    "            tmse_loss += mse_loss.item() * images.size(0)\n",
    "            #print('train_loss:',train_loss)\n",
    "            #print('tmse_loss:',tmse_loss)\n",
    "            tdiscr_loss += mse_loss2.item() * images.size(0)\n",
    "            #print('tdiscr_loss:',tdiscr_loss)\n",
    "\n",
    "\n",
    "        # print training statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        tmse_loss = tmse_loss / len(train_loader.dataset)\n",
    "        tdiscr_loss = tdiscr_loss / len(train_loader.dataset)\n",
    "        print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
    "                  train_loss, tmse_loss, tdiscr_loss))  \n",
    "            # 打印当前epoch的损失信息\n",
    "        # store the best encoder and decoder models\n",
    "            # here, /crs5 is a reference to 5 way cross validation, but is not\n",
    "            # necessary for illustration purposes\n",
    "        if train_loss < best_loss:  \n",
    "            # 如果当前epoch的平均损失低于历史最佳损失，则保存模型\n",
    "            print('Saving..')\n",
    "            path_enc = 'DeepSMOTE_{}_bst_enc.pth'.format(fraction)\n",
    "            # 构造保存最佳编码器模型的文件路径\n",
    "            path_dec = 'DeepSMOTE_{}_bst_dec.pth'.format(fraction)\n",
    "            # 构造保存最佳解码器模型的文件路径\n",
    "            \n",
    "            torch.save(encoder.state_dict(), path_enc)  \n",
    "            # 保存编码器当前状态字典（权重参数）\n",
    "            torch.save(decoder.state_dict(), path_dec)  \n",
    "            # 保存解码器当前状态字典\n",
    "            \n",
    "            best_loss = train_loss  # 更新历史最佳损失值\n",
    "     # in addition, store the final model (may not be the best) for\n",
    "    # informational purposes\n",
    "    \n",
    "    path_enc = 'DS_{}_final_enc.pth'.format(fraction)  \n",
    "    # 构造保存最终编码器模型（可能不是最佳）的文件路径\n",
    "    path_dec = 'DS_{}_final_dec.pth'.format(fraction)  \n",
    "    # 构造保存最终解码器模型的文件路径\n",
    "    print(path_enc)\n",
    "    print(path_dec)\n",
    "    torch.save(encoder.state_dict(), path_enc)  # 保存最终编码器状态\n",
    "    torch.save(decoder.state_dict(), path_dec)  # 保存最终解码器状态\n",
    "    print()\n",
    "t1 = time.time()  # 记录当前fold训练结束时间\n",
    "print('total time(min): {:.2f}'.format((t1 - t0) / 60))  \n",
    "# 输出当前fold训练耗时（单位：分钟）\n",
    "\n",
    "t4 = time.time()  # 记录整个程序结束时的时间\n",
    "print('final time(min): {:.2f}'.format((t4 - t3) / 60))  \n",
    "# 输出整个程序运行的总耗时（单位：分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
